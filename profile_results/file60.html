<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><link rel="stylesheet" href="file:////usr/local/MATLAB/R2013a/toolbox/matlab/codetools/matlab-report-styles.css" type="text/css" /><title>Function details for ClassificationKNN>ClassificationKNN.get.BreakTies</title><link rel="stylesheet" href="file:////usr/local/MATLAB/R2013a/toolbox/matlab/codetools/matlab-report-styles.css" type="text/css" /></head><body bgcolor="#F8F8F8"><strong>This is a static copy of a profile report</strong><p><a href="file0.html">Home</a><p><span style="font-size:14pt; background:#FFE4B0">ClassificationKNN>ClassificationKNN.get.BreakTies (1 call, 0.000 sec)</span><br/><i>Generated 02-Dec-2014 20:18:13 using cpu time.</i><br/>subfunction in file /usr/local/MATLAB/R2013a/toolbox/stats/classreg/ClassificationKNN.m<br/>Copy to new window for comparing multiple runs<div class="grayline"/><div class="grayline"/><strong>Parents</strong> (calling functions)<br/><p><table border=0 cellspacing=0 cellpadding=6><tr><td class="td-linebottomrt" bgcolor="#F0F0F0">Function Name</td><td class="td-linebottomrt" bgcolor="#F0F0F0">Function Type</td><td class="td-linebottomrt" bgcolor="#F0F0F0">Calls</td></tr><tr><td class="td-linebottomrt"><a href="file76.html">...ficationKNN>ClassificationKNN.predict</a></td><td class="td-linebottomrt">subfunction</td><td class="td-linebottomrt">1</td></tr></table><div class="grayline"/><strong>Lines where the most time was spent</strong><br/> No measurable time spent in this function<p><table border=0 cellspacing=0 cellpadding=6><tr><td class="td-linebottomrt" bgcolor="#F0F0F0">Line Number</td><td class="td-linebottomrt" bgcolor="#F0F0F0">Code</td><td class="td-linebottomrt" bgcolor="#F0F0F0">Calls</td><td class="td-linebottomrt" bgcolor="#F0F0F0">Total Time</td><td class="td-linebottomrt" bgcolor="#F0F0F0">% Time</td><td class="td-linebottomrt" bgcolor="#F0F0F0">Time Plot</td></tr><tr><td class="td-linebottomrt"><a href="#Line229">229</a></td><td class="td-linebottomrt"><pre>end</pre></td><td class="td-linebottomrt">1</td><td class="td-linebottomrt">0 s</td><td class="td-linebottomrt" class="td-linebottomrt">0%</td><td class="td-linebottomrt"><img src="file:////usr/local/MATLAB/R2013a/toolbox/matlab/codetools/private/one-pixel.gif" width=0 height=10></td></tr><tr><td class="td-linebottomrt"><a href="#Line228">228</a></td><td class="td-linebottomrt"><pre>inTies = this.ModelParams.Brea...</pre></td><td class="td-linebottomrt">1</td><td class="td-linebottomrt">0 s</td><td class="td-linebottomrt" class="td-linebottomrt">0%</td><td class="td-linebottomrt"><img src="file:////usr/local/MATLAB/R2013a/toolbox/matlab/codetools/private/one-pixel.gif" width=0 height=10></td></tr><tr><td class="td-linebottomrt">All other lines</td><td class="td-linebottomrt">&nbsp;</td><td class="td-linebottomrt">&nbsp;</td><td class="td-linebottomrt">0 s</td><td class="td-linebottomrt">0%</td><td class="td-linebottomrt"><img src="file:////usr/local/MATLAB/R2013a/toolbox/matlab/codetools/private/one-pixel.gif" width=0 height=10></td></tr><tr><td class="td-linebottomrt" bgcolor="#F0F0F0">Totals</td><td class="td-linebottomrt" bgcolor="#F0F0F0">&nbsp;</td><td class="td-linebottomrt" bgcolor="#F0F0F0">&nbsp;</td><td class="td-linebottomrt" bgcolor="#F0F0F0">0 s</td><td class="td-linebottomrt" bgcolor="#F0F0F0">0%</td><td class="td-linebottomrt" bgcolor="#F0F0F0">&nbsp;</td></tr></table><div class="grayline"/><b>Children</b> (called functions)<br/><p><table border=0 cellspacing=0 cellpadding=6><tr><td class="td-linebottomrt" bgcolor="#F0F0F0">Function Name</td><td class="td-linebottomrt" bgcolor="#F0F0F0">Function Type</td><td class="td-linebottomrt" bgcolor="#F0F0F0">Calls</td><td class="td-linebottomrt" bgcolor="#F0F0F0">Total Time</td><td class="td-linebottomrt" bgcolor="#F0F0F0">% Time</td><td class="td-linebottomrt" bgcolor="#F0F0F0">Time Plot</td></tr><tr><td class="td-linebottomrt"><a href="file61.html">...owVectorOps>DisallowVectorOps.subsref</a></td><td class="td-linebottomrt">subfunction</td><td class="td-linebottomrt">1</td><td class="td-linebottomrt">0 s</td><td class="td-linebottomrt">0%</td><td class="td-linebottomrt"><img src="file:////usr/local/MATLAB/R2013a/toolbox/matlab/codetools/private/one-pixel.gif" width=0 height=10></td></tr><tr><td class="td-linebottomrt">Self time (built-ins, overhead, etc.)</td><td class="td-linebottomrt">&nbsp;</td><td class="td-linebottomrt">&nbsp;</td><td class="td-linebottomrt">0 s</td><td class="td-linebottomrt">0%</td><td class="td-linebottomrt"><img src="file:////usr/local/MATLAB/R2013a/toolbox/matlab/codetools/private/one-pixel.gif" width=0 height=10></td></tr><tr><td class="td-linebottomrt" bgcolor="#F0F0F0">Totals</td><td class="td-linebottomrt" bgcolor="#F0F0F0">&nbsp;</td><td class="td-linebottomrt" bgcolor="#F0F0F0">&nbsp;</td><td class="td-linebottomrt" bgcolor="#F0F0F0">0 s</td><td class="td-linebottomrt" bgcolor="#F0F0F0">0%</td><td class="td-linebottomrt" bgcolor="#F0F0F0">&nbsp;</td></tr></table><div class="grayline"/><strong>Code Analyzer results</strong><br/>No Code Analyzer messages.<div class="grayline"/><strong>Coverage results</strong><br/>Show coverage for parent directory <br/><table border=0 cellspacing=0 cellpadding=6><tr><td class="td-linebottomrt" bgcolor="#F0F0F0">Total lines in function</td><td class="td-linebottomrt">1228</td></tr><tr><td class="td-linebottomrt" bgcolor="#F0F0F0">Non-code lines (comments, blank lines)</td><td class="td-linebottomrt">846</td></tr><tr><td class="td-linebottomrt" bgcolor="#F0F0F0">Code lines (lines that can run)</td><td class="td-linebottomrt">1</td></tr><tr><td class="td-linebottomrt" bgcolor="#F0F0F0">Code lines that did run</td><td class="td-linebottomrt">2</td></tr><tr><td class="td-linebottomrt" bgcolor="#F0F0F0">Code lines that did not run</td><td class="td-linebottomrt">1</td></tr><tr><td class="td-linebottomrt" bgcolor="#F0F0F0">Coverage (did run/can run)</td><td class="td-linebottomrt">200.00 %</td></tr></table><div class="grayline"/><b>Function listing</b><br/><pre> <span style="color: #FF0000; font-weight: bold; text-decoration: none">  time</span> <span style="color: #0000FF; font-weight: bold; text-decoration: none">  calls</span>  <span style="font-weight: bold; text-decoration: none">line</span><br/>               <span style="color: #A0A0A0">   1</span> <span style="color: #228B22; background: #FFFFFF;"></span><br/>               <span style="color: #A0A0A0">   2</span> <span style="color: #A0A0A0; background: #FFFFFF;">classdef ClassificationKNN &lt; ...</span><br/>               <span style="color: #A0A0A0">   3</span> <span style="color: #A0A0A0; background: #FFFFFF;">        classreg.learning.classif.FullClassificationModel</span><br/>               <span style="color: #A0A0A0">   4</span> <span style="color: #228B22; background: #FFFFFF;">%ClassificationKNN K Nearest Neighbors classification </span><br/>               <span style="color: #A0A0A0">   5</span> <span style="color: #228B22; background: #FFFFFF;">%   ClassificationKNN is a K Nearest Neighbors (KNN) classification model.</span><br/>               <span style="color: #A0A0A0">   6</span> <span style="color: #228B22; background: #FFFFFF;">%   It can predict response for new data. It also stores data used for</span><br/>               <span style="color: #A0A0A0">   7</span> <span style="color: #228B22; background: #FFFFFF;">%   training and can compute resubstitution predictions.</span><br/>               <span style="color: #A0A0A0">   8</span> <span style="color: #228B22; background: #FFFFFF;">%</span><br/>               <span style="color: #A0A0A0">   9</span> <span style="color: #228B22; background: #FFFFFF;">%   An object of this class cannot be created by calling the constructor.</span><br/>               <span style="color: #A0A0A0">  10</span> <span style="color: #228B22; background: #FFFFFF;">%   Use ClassificationKNN.fit to create a ClassificationKNN object by</span><br/>               <span style="color: #A0A0A0">  11</span> <span style="color: #228B22; background: #FFFFFF;">%   fitting the KNN classification model to training data.</span><br/>               <span style="color: #A0A0A0">  12</span> <span style="color: #228B22; background: #FFFFFF;">%</span><br/>               <span style="color: #A0A0A0">  13</span> <span style="color: #228B22; background: #FFFFFF;">%   ClassificationKNN properties:</span><br/>               <span style="color: #A0A0A0">  14</span> <span style="color: #228B22; background: #FFFFFF;">%       NObservations         - Number of observations.</span><br/>               <span style="color: #A0A0A0">  15</span> <span style="color: #228B22; background: #FFFFFF;">%       X                     - Matrix of predictors.</span><br/>               <span style="color: #A0A0A0">  16</span> <span style="color: #228B22; background: #FFFFFF;">%       Y                     - True class labels.</span><br/>               <span style="color: #A0A0A0">  17</span> <span style="color: #228B22; background: #FFFFFF;">%       W                     - Weights of observations.</span><br/>               <span style="color: #A0A0A0">  18</span> <span style="color: #228B22; background: #FFFFFF;">%       ModelParams           - KNN classification model parameters.</span><br/>               <span style="color: #A0A0A0">  19</span> <span style="color: #228B22; background: #FFFFFF;">%       PredictorNames        - Names of predictors.</span><br/>               <span style="color: #A0A0A0">  20</span> <span style="color: #228B22; background: #FFFFFF;">%       ResponseName          - Name of the response variable.</span><br/>               <span style="color: #A0A0A0">  21</span> <span style="color: #228B22; background: #FFFFFF;">%       ClassNames            - Names of classes in Y.</span><br/>               <span style="color: #A0A0A0">  22</span> <span style="color: #228B22; background: #FFFFFF;">%       Cost                  - Misclassification costs.</span><br/>               <span style="color: #A0A0A0">  23</span> <span style="color: #228B22; background: #FFFFFF;">%       Prior                 - Prior class probabilities.</span><br/>               <span style="color: #A0A0A0">  24</span> <span style="color: #228B22; background: #FFFFFF;">%       ScoreTransform        - Transformation applied to predicted</span><br/>               <span style="color: #A0A0A0">  25</span> <span style="color: #228B22; background: #FFFFFF;">%                               classification scores.</span><br/>               <span style="color: #A0A0A0">  26</span> <span style="color: #228B22; background: #FFFFFF;">%       CategoricalPredictors - Indices of categorical predictors.</span><br/>               <span style="color: #A0A0A0">  27</span> <span style="color: #228B22; background: #FFFFFF;">%       NSMethod              - Method for K nearest neighbors search.</span><br/>               <span style="color: #A0A0A0">  28</span> <span style="color: #228B22; background: #FFFFFF;">%       NumNeighbors          - Number of nearest neighbors. </span><br/>               <span style="color: #A0A0A0">  29</span> <span style="color: #228B22; background: #FFFFFF;">%       Distance              - Distance metric. </span><br/>               <span style="color: #A0A0A0">  30</span> <span style="color: #228B22; background: #FFFFFF;">%       DistParameter         - Additional distance parameters.</span><br/>               <span style="color: #A0A0A0">  31</span> <span style="color: #228B22; background: #FFFFFF;">%       IncludeTies           - Flag to include the tie neighbors.</span><br/>               <span style="color: #A0A0A0">  32</span> <span style="color: #228B22; background: #FFFFFF;">%       BreakTies             - Method of breaking ties if more than one</span><br/>               <span style="color: #A0A0A0">  33</span> <span style="color: #228B22; background: #FFFFFF;">%                               class has the same number of nearest points</span><br/>               <span style="color: #A0A0A0">  34</span> <span style="color: #228B22; background: #FFFFFF;">%                               among the K nearest neighbors.</span><br/>               <span style="color: #A0A0A0">  35</span> <span style="color: #228B22; background: #FFFFFF;">%  </span><br/>               <span style="color: #A0A0A0">  36</span> <span style="color: #228B22; background: #FFFFFF;">%   ClassificationKNN methods:</span><br/>               <span style="color: #A0A0A0">  37</span> <span style="color: #228B22; background: #FFFFFF;">%       fit (static)          - Fit a KNN classification model.</span><br/>               <span style="color: #A0A0A0">  38</span> <span style="color: #228B22; background: #FFFFFF;">%       template (static)     - KNN template for FITENSEMBLE.</span><br/>               <span style="color: #A0A0A0">  39</span> <span style="color: #228B22; background: #FFFFFF;">%       crossval              - Cross-validate this KNN classification model.</span><br/>               <span style="color: #A0A0A0">  40</span> <span style="color: #228B22; background: #FFFFFF;">%       edge                  - Classification edge.</span><br/>               <span style="color: #A0A0A0">  41</span> <span style="color: #228B22; background: #FFFFFF;">%       loss                  - Classification loss.</span><br/>               <span style="color: #A0A0A0">  42</span> <span style="color: #228B22; background: #FFFFFF;">%       margin                - Classification margins.</span><br/>               <span style="color: #A0A0A0">  43</span> <span style="color: #228B22; background: #FFFFFF;">%       predict               - Predicted response.</span><br/>               <span style="color: #A0A0A0">  44</span> <span style="color: #228B22; background: #FFFFFF;">%       resubEdge             - Resubstitution classification edge.</span><br/>               <span style="color: #A0A0A0">  45</span> <span style="color: #228B22; background: #FFFFFF;">%       resubLoss             - Resubstitution classification loss.</span><br/>               <span style="color: #A0A0A0">  46</span> <span style="color: #228B22; background: #FFFFFF;">%       resubMargin           - Resubstitution classification margins.</span><br/>               <span style="color: #A0A0A0">  47</span> <span style="color: #228B22; background: #FFFFFF;">%       resubPredict          - Resubstitution predicted response.  </span><br/>               <span style="color: #A0A0A0">  48</span> <span style="color: #228B22; background: #FFFFFF;">%</span><br/>               <span style="color: #A0A0A0">  49</span> <span style="color: #228B22; background: #FFFFFF;">%   Example: Grow a KNN classification model for Fisher's iris data.</span><br/>               <span style="color: #A0A0A0">  50</span> <span style="color: #228B22; background: #FFFFFF;">%       load fisheriris</span><br/>               <span style="color: #A0A0A0">  51</span> <span style="color: #228B22; background: #FFFFFF;">%       d = ClassificationKNN.fit(meas,species,'PredictorNames',...</span><br/>               <span style="color: #A0A0A0">  52</span> <span style="color: #228B22; background: #FFFFFF;">%                    {'SL' 'SW' 'PL' 'PW'},'NumNeighbors',5)</span><br/>               <span style="color: #A0A0A0">  53</span> <span style="color: #228B22; background: #FFFFFF;">                 </span><br/>               <span style="color: #A0A0A0">  54</span> <span style="color: #228B22; background: #FFFFFF;"></span><br/>               <span style="color: #A0A0A0">  55</span> <span style="color: #228B22; background: #FFFFFF;">%  Copyright 2011 The MathWorks, Inc.</span><br/>               <span style="color: #A0A0A0">  56</span> <span style="color: #228B22; background: #FFFFFF;"></span><br/>               <span style="color: #A0A0A0">  57</span> <span style="color: #A0A0A0; background: #FFFFFF;">    properties(GetAccess=protected,SetAccess=protected)</span><br/>               <span style="color: #A0A0A0">  58</span> <span style="color: #228B22; background: #FFFFFF;">        %NeighborSearcher object        </span><br/>               <span style="color: #A0A0A0">  59</span> <span style="color: #A0A0A0; background: #FFFFFF;">        NS = [];</span><br/>               <span style="color: #A0A0A0">  60</span> <span style="color: #228B22; background: #FFFFFF;">        %saves the weight provided by the customer or come from the default</span><br/>               <span style="color: #A0A0A0">  61</span> <span style="color: #228B22; background: #FFFFFF;">        %value. This weight is not normalized to the class prior.</span><br/>               <span style="color: #A0A0A0">  62</span> <span style="color: #228B22; background: #FFFFFF;">        %</span><br/>               <span style="color: #A0A0A0">  63</span> <span style="color: #A0A0A0; background: #FFFFFF;">        PrivW = [];</span><br/>               <span style="color: #A0A0A0">  64</span> <span style="color: #228B22; background: #FFFFFF;">        </span><br/>               <span style="color: #A0A0A0">  65</span> <span style="color: #228B22; background: #FFFFFF;">                </span><br/>               <span style="color: #A0A0A0">  66</span> <span style="color: #A0A0A0; background: #FFFFFF;">    end</span><br/>               <span style="color: #A0A0A0">  67</span> <span style="color: #228B22; background: #FFFFFF;">    </span><br/>               <span style="color: #A0A0A0">  68</span> <span style="color: #228B22; background: #FFFFFF;">    </span><br/>               <span style="color: #A0A0A0">  69</span> <span style="color: #A0A0A0; background: #FFFFFF;">    properties(GetAccess=public,SetAccess=public,Dependent=true)</span><br/>               <span style="color: #A0A0A0">  70</span> <span style="color: #228B22; background: #FFFFFF;">        %NumNeighbors Number of nearest neighbors. </span><br/>               <span style="color: #A0A0A0">  71</span> <span style="color: #228B22; background: #FFFFFF;">        %   A positive integer. The number of nearest neighbors for</span><br/>               <span style="color: #A0A0A0">  72</span> <span style="color: #228B22; background: #FFFFFF;">        %   classifying each point when predicting.</span><br/>               <span style="color: #A0A0A0">  73</span> <span style="color: #228B22; background: #FFFFFF;">        %</span><br/>               <span style="color: #A0A0A0">  74</span> <span style="color: #228B22; background: #FFFFFF;">        %   See also ClassificationKNN</span><br/>               <span style="color: #A0A0A0">  75</span> <span style="color: #A0A0A0; background: #FFFFFF;">        NumNeighbors;</span><br/>               <span style="color: #A0A0A0">  76</span> <span style="color: #228B22; background: #FFFFFF;">        </span><br/>               <span style="color: #A0A0A0">  77</span> <span style="color: #228B22; background: #FFFFFF;">        %Distance Distance metric.</span><br/>               <span style="color: #A0A0A0">  78</span> <span style="color: #228B22; background: #FFFFFF;">        %   A string specifying the built-in distance metric or a function</span><br/>               <span style="color: #A0A0A0">  79</span> <span style="color: #228B22; background: #FFFFFF;">        %   handle.</span><br/>               <span style="color: #A0A0A0">  80</span> <span style="color: #228B22; background: #FFFFFF;">        %</span><br/>               <span style="color: #A0A0A0">  81</span> <span style="color: #228B22; background: #FFFFFF;">        %   See also ClassificationKNN</span><br/>               <span style="color: #A0A0A0">  82</span> <span style="color: #A0A0A0; background: #FFFFFF;">        Distance;</span><br/>               <span style="color: #A0A0A0">  83</span> <span style="color: #228B22; background: #FFFFFF;">        </span><br/>               <span style="color: #A0A0A0">  84</span> <span style="color: #228B22; background: #FFFFFF;">        %DistParameter Additional distance parameter.</span><br/>               <span style="color: #A0A0A0">  85</span> <span style="color: #228B22; background: #FFFFFF;">        %   Value of Distance property Value</span><br/>               <span style="color: #A0A0A0">  86</span> <span style="color: #228B22; background: #FFFFFF;">        % </span><br/>               <span style="color: #A0A0A0">  87</span> <span style="color: #228B22; background: #FFFFFF;">        %   'minkowski'                  A positive scalar indicating</span><br/>               <span style="color: #A0A0A0">  88</span> <span style="color: #228B22; background: #FFFFFF;">        %                                the exponent of the minkowski     </span><br/>               <span style="color: #A0A0A0">  89</span> <span style="color: #228B22; background: #FFFFFF;">        %                                distance. </span><br/>               <span style="color: #A0A0A0">  90</span> <span style="color: #228B22; background: #FFFFFF;">        %   'mahalanobis'                A positive definite matrix        </span><br/>               <span style="color: #A0A0A0">  91</span> <span style="color: #228B22; background: #FFFFFF;">        %                                representing the covariance</span><br/>               <span style="color: #A0A0A0">  92</span> <span style="color: #228B22; background: #FFFFFF;">        %                                matrix used for computing the</span><br/>               <span style="color: #A0A0A0">  93</span> <span style="color: #228B22; background: #FFFFFF;">        %                                mahalanobis distance.</span><br/>               <span style="color: #A0A0A0">  94</span> <span style="color: #228B22; background: #FFFFFF;">        %   'seuclidean'                 A vector representing the scale</span><br/>               <span style="color: #A0A0A0">  95</span> <span style="color: #228B22; background: #FFFFFF;">        %                                value to use in computing the</span><br/>               <span style="color: #A0A0A0">  96</span> <span style="color: #228B22; background: #FFFFFF;">        %                                'seuclidean' distance.</span><br/>               <span style="color: #A0A0A0">  97</span> <span style="color: #228B22; background: #FFFFFF;">        %   otherwise                    Empty. </span><br/>               <span style="color: #A0A0A0">  98</span> <span style="color: #228B22; background: #FFFFFF;">        %</span><br/>               <span style="color: #A0A0A0">  99</span> <span style="color: #228B22; background: #FFFFFF;">        %   See also ClassificationKNN</span><br/>               <span style="color: #A0A0A0"> 100</span> <span style="color: #A0A0A0; background: #FFFFFF;">        DistParameter;</span><br/>               <span style="color: #A0A0A0"> 101</span> <span style="color: #228B22; background: #FFFFFF;">              </span><br/>               <span style="color: #A0A0A0"> 102</span> <span style="color: #228B22; background: #FFFFFF;">        %IncludeTies Whether to include the tie neighbors</span><br/>               <span style="color: #A0A0A0"> 103</span> <span style="color: #228B22; background: #FFFFFF;">        %   A logical value specifying whether to include all neighbors whose</span><br/>               <span style="color: #A0A0A0"> 104</span> <span style="color: #228B22; background: #FFFFFF;">        %   distance equal the Kth smallest distance.</span><br/>               <span style="color: #A0A0A0"> 105</span> <span style="color: #228B22; background: #FFFFFF;">        %</span><br/>               <span style="color: #A0A0A0"> 106</span> <span style="color: #228B22; background: #FFFFFF;">        %   See also ClassificationKNN</span><br/>               <span style="color: #A0A0A0"> 107</span> <span style="color: #A0A0A0; background: #FFFFFF;">        IncludeTies;</span><br/>               <span style="color: #A0A0A0"> 108</span> <span style="color: #228B22; background: #FFFFFF;">        </span><br/>               <span style="color: #A0A0A0"> 109</span> <span style="color: #228B22; background: #FFFFFF;">        %DistanceWeight Distance weighting function.</span><br/>               <span style="color: #A0A0A0"> 110</span> <span style="color: #228B22; background: #FFFFFF;">        %   A string or a function handle specifying the distance weighting</span><br/>               <span style="color: #A0A0A0"> 111</span> <span style="color: #228B22; background: #FFFFFF;">        %   function. </span><br/>               <span style="color: #A0A0A0"> 112</span> <span style="color: #228B22; background: #FFFFFF;">        %</span><br/>               <span style="color: #A0A0A0"> 113</span> <span style="color: #228B22; background: #FFFFFF;">        %   See also ClassificationKNN</span><br/>               <span style="color: #A0A0A0"> 114</span> <span style="color: #A0A0A0; background: #FFFFFF;">        DistanceWeight;</span><br/>               <span style="color: #A0A0A0"> 115</span> <span style="color: #228B22; background: #FFFFFF;">                </span><br/>               <span style="color: #A0A0A0"> 116</span> <span style="color: #228B22; background: #FFFFFF;">        %BreakTies Method of breaking ties</span><br/>               <span style="color: #A0A0A0"> 117</span> <span style="color: #228B22; background: #FFFFFF;">        %   A string 'smallest', 'random' or 'nearest', specifying method of</span><br/>               <span style="color: #A0A0A0"> 118</span> <span style="color: #228B22; background: #FFFFFF;">        %   breaking ties if more than one class has the same smallest</span><br/>               <span style="color: #A0A0A0"> 119</span> <span style="color: #228B22; background: #FFFFFF;">        %   misclassification cost.</span><br/>               <span style="color: #A0A0A0"> 120</span> <span style="color: #228B22; background: #FFFFFF;">        %</span><br/>               <span style="color: #A0A0A0"> 121</span> <span style="color: #228B22; background: #FFFFFF;">        %   See also ClassificationKNN</span><br/>               <span style="color: #A0A0A0"> 122</span> <span style="color: #A0A0A0; background: #FFFFFF;">        BreakTies;</span><br/>               <span style="color: #A0A0A0"> 123</span> <span style="color: #A0A0A0; background: #FFFFFF;">    end</span><br/>               <span style="color: #A0A0A0"> 124</span> <span style="color: #228B22; background: #FFFFFF;">    </span><br/>               <span style="color: #A0A0A0"> 125</span> <span style="color: #A0A0A0; background: #FFFFFF;">    properties(GetAccess=public,SetAccess=protected,Dependent=true)</span><br/>               <span style="color: #A0A0A0"> 126</span> <span style="color: #228B22; background: #FFFFFF;">        % NSMethod Method for K nearest neighbors search</span><br/>               <span style="color: #A0A0A0"> 127</span> <span style="color: #228B22; background: #FFFFFF;">        %    A string 'kdtree' or 'exhaustive', specifying nearest neighbors</span><br/>               <span style="color: #A0A0A0"> 128</span> <span style="color: #228B22; background: #FFFFFF;">        %    search method.</span><br/>               <span style="color: #A0A0A0"> 129</span> <span style="color: #228B22; background: #FFFFFF;">        %</span><br/>               <span style="color: #A0A0A0"> 130</span> <span style="color: #228B22; background: #FFFFFF;">        %   See also ClassificationKNN</span><br/>               <span style="color: #A0A0A0"> 131</span> <span style="color: #A0A0A0; background: #FFFFFF;">        NSMethod;</span><br/>               <span style="color: #A0A0A0"> 132</span> <span style="color: #A0A0A0; background: #FFFFFF;">    end</span><br/>               <span style="color: #A0A0A0"> 133</span> <span style="color: #228B22; background: #FFFFFF;">    </span><br/>               <span style="color: #A0A0A0"> 134</span> <span style="color: #A0A0A0; background: #FFFFFF;">    methods</span><br/>               <span style="color: #A0A0A0"> 135</span> <span style="color: #228B22; background: #FFFFFF;">               </span><br/>               <span style="color: #A0A0A0"> 136</span> <span style="color: #A0A0A0; background: #FFFFFF;">        function nsmethod = get.NSMethod(this)</span><br/>               <span style="color: #A0A0A0"> 137</span> <span style="color: #A0A0A0; background: #FFFFFF;">            nsmethod = this.ModelParams.NSMethod;</span><br/>               <span style="color: #A0A0A0"> 138</span> <span style="color: #A0A0A0; background: #FFFFFF;">        end</span><br/>               <span style="color: #A0A0A0"> 139</span> <span style="color: #228B22; background: #FFFFFF;">        </span><br/>               <span style="color: #A0A0A0"> 140</span> <span style="color: #228B22; background: #FFFFFF;">                </span><br/>               <span style="color: #A0A0A0"> 141</span> <span style="color: #A0A0A0; background: #FFFFFF;">        function dp = get.DistParameter(this)</span><br/>               <span style="color: #A0A0A0"> 142</span> <span style="color: #A0A0A0; background: #FFFFFF;">            if ~isempty(this.ModelParams.Exponent)</span><br/>               <span style="color: #A0A0A0"> 143</span> <span style="color: #A0A0A0; background: #FFFFFF;">                dp = this.ModelParams.Exponent;</span><br/>               <span style="color: #A0A0A0"> 144</span> <span style="color: #A0A0A0; background: #FFFFFF;">            elseif ~isempty(this.ModelParams.Cov)</span><br/>               <span style="color: #A0A0A0"> 145</span> <span style="color: #A0A0A0; background: #FFFFFF;">                dp = this.ModelParams.Cov;</span><br/>               <span style="color: #A0A0A0"> 146</span> <span style="color: #A0A0A0; background: #FFFFFF;">            elseif ~isempty(this.ModelParams.Scale)</span><br/>               <span style="color: #A0A0A0"> 147</span> <span style="color: #A0A0A0; background: #FFFFFF;">                dp = this.ModelParams.Scale;</span><br/>               <span style="color: #A0A0A0"> 148</span> <span style="color: #228B22; background: #FFFFFF;">            else</span><br/>               <span style="color: #A0A0A0"> 149</span> <span style="color: #A0A0A0; background: #FFFFFF;">                dp =[];</span><br/>               <span style="color: #A0A0A0"> 150</span> <span style="color: #A0A0A0; background: #FFFFFF;">            end</span><br/>               <span style="color: #A0A0A0"> 151</span> <span style="color: #A0A0A0; background: #FFFFFF;">        end</span><br/>               <span style="color: #A0A0A0"> 152</span> <span style="color: #228B22; background: #FFFFFF;">        </span><br/>               <span style="color: #A0A0A0"> 153</span> <span style="color: #A0A0A0; background: #FFFFFF;">        function dist = get.Distance(this)</span><br/>               <span style="color: #A0A0A0"> 154</span> <span style="color: #A0A0A0; background: #FFFFFF;">            dist = this.ModelParams.Distance;</span><br/>               <span style="color: #A0A0A0"> 155</span> <span style="color: #A0A0A0; background: #FFFFFF;">        end</span><br/>               <span style="color: #A0A0A0"> 156</span> <span style="color: #228B22; background: #FFFFFF;">        </span><br/>               <span style="color: #A0A0A0"> 157</span> <span style="color: #A0A0A0; background: #FFFFFF;">        function this = set.Distance(this,distMetric)</span><br/>               <span style="color: #A0A0A0"> 158</span> <span style="color: #228B22; background: #FFFFFF;">           </span><br/>               <span style="color: #A0A0A0"> 159</span> <span style="color: #A0A0A0; background: #FFFFFF;">            this.NS.Distance = distMetric;</span><br/>               <span style="color: #A0A0A0"> 160</span> <span style="color: #A0A0A0; background: #FFFFFF;">            this.ModelParams.Distance = this.NS.Distance;</span><br/>               <span style="color: #A0A0A0"> 161</span> <span style="color: #228B22; background: #FFFFFF;">            %need to change the distance parameters</span><br/>               <span style="color: #A0A0A0"> 162</span> <span style="color: #A0A0A0; background: #FFFFFF;">            i = find(strncmpi(this.ModelParams.Distance, ...</span><br/>               <span style="color: #A0A0A0"> 163</span> <span style="color: #A0A0A0; background: #FFFFFF;">                {'minkowski','mahalanobis','seuclidean'},3));</span><br/>               <span style="color: #A0A0A0"> 164</span> <span style="color: #A0A0A0; background: #FFFFFF;">            if isempty(i)</span><br/>               <span style="color: #A0A0A0"> 165</span> <span style="color: #A0A0A0; background: #FFFFFF;">                 this.ModelParams.Exponent = [];</span><br/>               <span style="color: #A0A0A0"> 166</span> <span style="color: #A0A0A0; background: #FFFFFF;">                 this.ModelParams.Cov =[];</span><br/>               <span style="color: #A0A0A0"> 167</span> <span style="color: #A0A0A0; background: #FFFFFF;">                 this.ModelParams.Scale =[];</span><br/>               <span style="color: #A0A0A0"> 168</span> <span style="color: #A0A0A0; background: #FFFFFF;">            elseif i == 1 %'min'</span><br/>               <span style="color: #A0A0A0"> 169</span> <span style="color: #A0A0A0; background: #FFFFFF;">                 this.ModelParams.Exponent = this.NS.DistParameter;</span><br/>               <span style="color: #A0A0A0"> 170</span> <span style="color: #A0A0A0; background: #FFFFFF;">                 this.ModelParams.Cov =[];</span><br/>               <span style="color: #A0A0A0"> 171</span> <span style="color: #A0A0A0; background: #FFFFFF;">                 this.ModelParams.Scale =[];</span><br/>               <span style="color: #A0A0A0"> 172</span> <span style="color: #A0A0A0; background: #FFFFFF;">            elseif i==2  %mah</span><br/>               <span style="color: #A0A0A0"> 173</span> <span style="color: #A0A0A0; background: #FFFFFF;">                this.ModelParams.Cov= this.NS.DistParameter;</span><br/>               <span style="color: #A0A0A0"> 174</span> <span style="color: #A0A0A0; background: #FFFFFF;">                this.ModelParams.Exponent = [];</span><br/>               <span style="color: #A0A0A0"> 175</span> <span style="color: #A0A0A0; background: #FFFFFF;">                this.ModelParams.Scale = [];</span><br/>               <span style="color: #A0A0A0"> 176</span> <span style="color: #228B22; background: #FFFFFF;">            else %secu</span><br/>               <span style="color: #A0A0A0"> 177</span> <span style="color: #A0A0A0; background: #FFFFFF;">                this.ModelParams.Scale= this.NS.DistParameter;</span><br/>               <span style="color: #A0A0A0"> 178</span> <span style="color: #A0A0A0; background: #FFFFFF;">                this.ModelParams.Cov= [];</span><br/>               <span style="color: #A0A0A0"> 179</span> <span style="color: #A0A0A0; background: #FFFFFF;">                this.ModelParams.Exponent = [];</span><br/>               <span style="color: #A0A0A0"> 180</span> <span style="color: #A0A0A0; background: #FFFFFF;">            end</span><br/>               <span style="color: #A0A0A0"> 181</span> <span style="color: #A0A0A0; background: #FFFFFF;">        end</span><br/>               <span style="color: #A0A0A0"> 182</span> <span style="color: #228B22; background: #FFFFFF;">           </span><br/>               <span style="color: #A0A0A0"> 183</span> <span style="color: #A0A0A0; background: #FFFFFF;">        function this = set.DistParameter(this, para)</span><br/>               <span style="color: #A0A0A0"> 184</span> <span style="color: #A0A0A0; background: #FFFFFF;">            this.NS.DistParameter = para;</span><br/>               <span style="color: #A0A0A0"> 185</span> <span style="color: #A0A0A0; background: #FFFFFF;">            i = find(strncmpi(this.ModelParams.Distance, {'minkowski','mahalanobis','seuclidean'},3));</span><br/>               <span style="color: #A0A0A0"> 186</span> <span style="color: #A0A0A0; background: #FFFFFF;">            if isempty(i)</span><br/>               <span style="color: #A0A0A0"> 187</span> <span style="color: #A0A0A0; background: #FFFFFF;">                 error(message('stats:ClassificationKNN:set:DistParameter:InvalidDistanceParam'));</span><br/>               <span style="color: #A0A0A0"> 188</span> <span style="color: #A0A0A0; background: #FFFFFF;">            elseif i == 1 %'min'</span><br/>               <span style="color: #A0A0A0"> 189</span> <span style="color: #A0A0A0; background: #FFFFFF;">                 this.ModelParams.Exponent = para;</span><br/>               <span style="color: #A0A0A0"> 190</span> <span style="color: #A0A0A0; background: #FFFFFF;">                 this.ModelParams.Cov =[];</span><br/>               <span style="color: #A0A0A0"> 191</span> <span style="color: #A0A0A0; background: #FFFFFF;">                 this.ModelParams.Scale =[];</span><br/>               <span style="color: #A0A0A0"> 192</span> <span style="color: #A0A0A0; background: #FFFFFF;">            elseif i == 2  %mah</span><br/>               <span style="color: #A0A0A0"> 193</span> <span style="color: #A0A0A0; background: #FFFFFF;">                this.ModelParams.Cov= para;</span><br/>               <span style="color: #A0A0A0"> 194</span> <span style="color: #A0A0A0; background: #FFFFFF;">                this.ModelParams.Exponent = [];</span><br/>               <span style="color: #A0A0A0"> 195</span> <span style="color: #A0A0A0; background: #FFFFFF;">                this.ModelParams.Scale = [];</span><br/>               <span style="color: #A0A0A0"> 196</span> <span style="color: #228B22; background: #FFFFFF;">            else %secu</span><br/>               <span style="color: #A0A0A0"> 197</span> <span style="color: #A0A0A0; background: #FFFFFF;">                this.ModelParams.Scale= para;</span><br/>               <span style="color: #A0A0A0"> 198</span> <span style="color: #A0A0A0; background: #FFFFFF;">                this.ModelParams.Cov= [];</span><br/>               <span style="color: #A0A0A0"> 199</span> <span style="color: #A0A0A0; background: #FFFFFF;">                this.ModelParams.Exponent = [];</span><br/>               <span style="color: #A0A0A0"> 200</span> <span style="color: #A0A0A0; background: #FFFFFF;">            end</span><br/>               <span style="color: #A0A0A0"> 201</span> <span style="color: #A0A0A0; background: #FFFFFF;">         end</span><br/>               <span style="color: #A0A0A0"> 202</span> <span style="color: #228B22; background: #FFFFFF;"></span><br/>               <span style="color: #A0A0A0"> 203</span> <span style="color: #A0A0A0; background: #FFFFFF;">        function K = get.NumNeighbors(this)</span><br/>               <span style="color: #A0A0A0"> 204</span> <span style="color: #A0A0A0; background: #FFFFFF;">            K = this.ModelParams.NumNeighbors;</span><br/>               <span style="color: #A0A0A0"> 205</span> <span style="color: #A0A0A0; background: #FFFFFF;">        end</span><br/>               <span style="color: #A0A0A0"> 206</span> <span style="color: #228B22; background: #FFFFFF;">        </span><br/>               <span style="color: #A0A0A0"> 207</span> <span style="color: #A0A0A0; background: #FFFFFF;">        function this = set.NumNeighbors(this,K)</span><br/>               <span style="color: #A0A0A0"> 208</span> <span style="color: #A0A0A0; background: #FFFFFF;">            if ~isscalar(K) || ~isnumeric(K) ||  ...</span><br/>               <span style="color: #A0A0A0"> 209</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    K &lt;1 || K~=round(K)</span><br/>               <span style="color: #A0A0A0"> 210</span> <span style="color: #A0A0A0; background: #FFFFFF;">                error(message('stats:ClassificationKNN:set:NumNeighbors:BadK'));</span><br/>               <span style="color: #A0A0A0"> 211</span> <span style="color: #A0A0A0; background: #FFFFFF;">            end</span><br/>               <span style="color: #A0A0A0"> 212</span> <span style="color: #A0A0A0; background: #FFFFFF;">            nx= size(this.X,1);</span><br/>               <span style="color: #A0A0A0"> 213</span> <span style="color: #A0A0A0; background: #FFFFFF;">            this.ModelParams.NumNeighbors = min(K,nx);</span><br/>               <span style="color: #A0A0A0"> 214</span> <span style="color: #A0A0A0; background: #FFFFFF;">        end</span><br/>               <span style="color: #A0A0A0"> 215</span> <span style="color: #228B22; background: #FFFFFF;">        </span><br/>               <span style="color: #A0A0A0"> 216</span> <span style="color: #A0A0A0; background: #FFFFFF;">        function inTies = get.IncludeTies(this)</span><br/>               <span style="color: #A0A0A0"> 217</span> <span style="color: #A0A0A0; background: #FFFFFF;">            inTies = this.ModelParams.IncludeTies;</span><br/>               <span style="color: #A0A0A0"> 218</span> <span style="color: #A0A0A0; background: #FFFFFF;">        end</span><br/>               <span style="color: #A0A0A0"> 219</span> <span style="color: #228B22; background: #FFFFFF;">        </span><br/>               <span style="color: #A0A0A0"> 220</span> <span style="color: #A0A0A0; background: #FFFFFF;">        function this = set.IncludeTies(this,tf)</span><br/>               <span style="color: #A0A0A0"> 221</span> <span style="color: #A0A0A0; background: #FFFFFF;">            if ~islogical(tf) || ~isscalar(tf)</span><br/>               <span style="color: #A0A0A0"> 222</span> <span style="color: #A0A0A0; background: #FFFFFF;">                error(message('stats:ClassificationKNN:set:IncludeTies:BadIncludeTies'));</span><br/>               <span style="color: #A0A0A0"> 223</span> <span style="color: #A0A0A0; background: #FFFFFF;">            end</span><br/>               <span style="color: #A0A0A0"> 224</span> <span style="color: #A0A0A0; background: #FFFFFF;">            this.ModelParams.IncludeTies = tf;</span><br/>               <span style="color: #A0A0A0"> 225</span> <span style="color: #A0A0A0; background: #FFFFFF;">        end</span><br/>               <span style="color: #A0A0A0"> 226</span> <span style="color: #228B22; background: #FFFFFF;">        </span><br/>               <span style="color: #A0A0A0"> 227</span> <span style="color: #A0A0A0; background: #FFFFFF;">        function inTies = get.BreakTies(this)</span><br/>       <span style="color: #0000FF">      1 </span><span style="color: #000000; font-weight: bold"> 228</span> <a name="Line228"></a><span style="color: #000000; background: #FFFFFF;">            inTies = this.ModelParams.BreakTies; </span><br/>       <span style="color: #0000FF">      1 </span><span style="color: #000000; font-weight: bold"> 229</span> <a name="Line229"></a><span style="color: #000000; background: #FFFFFF;">        end </span><br/>               <span style="color: #A0A0A0"> 230</span> <span style="color: #228B22; background: #FFFFFF;">        </span><br/>               <span style="color: #A0A0A0"> 231</span> <span style="color: #A0A0A0; background: #FFFFFF;">        function this = set.BreakTies(this,breakties)</span><br/>               <span style="color: #A0A0A0"> 232</span> <span style="color: #A0A0A0; background: #FFFFFF;">            if ~ischar(breakties)</span><br/>               <span style="color: #A0A0A0"> 233</span> <span style="color: #A0A0A0; background: #FFFFFF;">                error(message('stats:ClassificationKNN:set:BreakTies:BadBreakTies'));</span><br/>               <span style="color: #A0A0A0"> 234</span> <span style="color: #228B22; background: #FFFFFF;">                   </span><br/>               <span style="color: #A0A0A0"> 235</span> <span style="color: #228B22; background: #FFFFFF;">            else</span><br/>               <span style="color: #A0A0A0"> 236</span> <span style="color: #A0A0A0; background: #FFFFFF;">                breaktieList = {'smallest' 'nearest','random'};</span><br/>               <span style="color: #A0A0A0"> 237</span> <span style="color: #A0A0A0; background: #FFFFFF;">                i = find(strncmpi(breakties,breaktieList,length(breakties)));</span><br/>               <span style="color: #A0A0A0"> 238</span> <span style="color: #A0A0A0; background: #FFFFFF;">                if isempty(i)</span><br/>               <span style="color: #A0A0A0"> 239</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    error(message('stats:ClassificationKNN:set:BreakTies:BadBreakTies'));</span><br/>               <span style="color: #A0A0A0"> 240</span> <span style="color: #228B22; background: #FFFFFF;">                else</span><br/>               <span style="color: #A0A0A0"> 241</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    this.ModelParams.BreakTies = breaktieList{i};</span><br/>               <span style="color: #A0A0A0"> 242</span> <span style="color: #A0A0A0; background: #FFFFFF;">                end</span><br/>               <span style="color: #A0A0A0"> 243</span> <span style="color: #A0A0A0; background: #FFFFFF;">            end</span><br/>               <span style="color: #A0A0A0"> 244</span> <span style="color: #A0A0A0; background: #FFFFFF;">        end</span><br/>               <span style="color: #A0A0A0"> 245</span> <span style="color: #228B22; background: #FFFFFF;">        </span><br/>               <span style="color: #A0A0A0"> 246</span> <span style="color: #A0A0A0; background: #FFFFFF;">        function distWgt = get.DistanceWeight(this)</span><br/>               <span style="color: #A0A0A0"> 247</span> <span style="color: #A0A0A0; background: #FFFFFF;">            distWgt = this.ModelParams.DistanceWeight;</span><br/>               <span style="color: #A0A0A0"> 248</span> <span style="color: #A0A0A0; background: #FFFFFF;">        end</span><br/>               <span style="color: #A0A0A0"> 249</span> <span style="color: #228B22; background: #FFFFFF;">        </span><br/>               <span style="color: #A0A0A0"> 250</span> <span style="color: #A0A0A0; background: #FFFFFF;">        function this = set.DistanceWeight(this,wgt)</span><br/>               <span style="color: #A0A0A0"> 251</span> <span style="color: #A0A0A0; background: #FFFFFF;">            if ischar(wgt)</span><br/>               <span style="color: #A0A0A0"> 252</span> <span style="color: #A0A0A0; background: #FFFFFF;">                wgtList = {'equal','inverse','squaredinverse'};</span><br/>               <span style="color: #A0A0A0"> 253</span> <span style="color: #A0A0A0; background: #FFFFFF;">                i = find(strncmpi(wgt, wgtList,length(wgt)));</span><br/>               <span style="color: #A0A0A0"> 254</span> <span style="color: #A0A0A0; background: #FFFFFF;">                if isempty(i)</span><br/>               <span style="color: #A0A0A0"> 255</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    error(message('stats:ClassificationKNN:set:DistanceWeight:BadDistanceWeight'));</span><br/>               <span style="color: #A0A0A0"> 256</span> <span style="color: #228B22; background: #FFFFFF;">                else</span><br/>               <span style="color: #A0A0A0"> 257</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    this.ModelParams.DistanceWeight = wgtList{i};</span><br/>               <span style="color: #A0A0A0"> 258</span> <span style="color: #A0A0A0; background: #FFFFFF;">                end</span><br/>               <span style="color: #A0A0A0"> 259</span> <span style="color: #228B22; background: #FFFFFF;">              </span><br/>               <span style="color: #A0A0A0"> 260</span> <span style="color: #A0A0A0; background: #FFFFFF;">            elseif isa (wgt,  'function_handle')</span><br/>               <span style="color: #A0A0A0"> 261</span> <span style="color: #A0A0A0; background: #FFFFFF;">                this.ModelParams.DistanceWeight = wgt;</span><br/>               <span style="color: #A0A0A0"> 262</span> <span style="color: #228B22; background: #FFFFFF;">            else</span><br/>               <span style="color: #A0A0A0"> 263</span> <span style="color: #A0A0A0; background: #FFFFFF;">                error(message('stats:ClassificationKNN:set:DistanceWeight:BadDistanceWeight'));           </span><br/>               <span style="color: #A0A0A0"> 264</span> <span style="color: #A0A0A0; background: #FFFFFF;">            end          </span><br/>               <span style="color: #A0A0A0"> 265</span> <span style="color: #A0A0A0; background: #FFFFFF;">        end</span><br/>               <span style="color: #A0A0A0"> 266</span> <span style="color: #228B22; background: #FFFFFF;">      </span><br/>               <span style="color: #A0A0A0"> 267</span> <span style="color: #A0A0A0; background: #FFFFFF;">    end</span><br/>               <span style="color: #A0A0A0"> 268</span> <span style="color: #228B22; background: #FFFFFF;">    </span><br/>               <span style="color: #A0A0A0"> 269</span> <span style="color: #A0A0A0; background: #FFFFFF;">    methods(Access=protected)</span><br/>               <span style="color: #A0A0A0"> 270</span> <span style="color: #A0A0A0; background: #FFFFFF;">        function x = getX(this)</span><br/>               <span style="color: #A0A0A0"> 271</span> <span style="color: #A0A0A0; background: #FFFFFF;">            x = this.NS.X;</span><br/>               <span style="color: #A0A0A0"> 272</span> <span style="color: #A0A0A0; background: #FFFFFF;">        end</span><br/>               <span style="color: #A0A0A0"> 273</span> <span style="color: #228B22; background: #FFFFFF;">        </span><br/>               <span style="color: #A0A0A0"> 274</span> <span style="color: #228B22; background: #FFFFFF;">       %This function normalzied observation weights to be consistent with the class priors</span><br/>               <span style="color: #A0A0A0"> 275</span> <span style="color: #228B22; background: #FFFFFF;">       %i.e., the summation of observation weights in each class will equal</span><br/>               <span style="color: #A0A0A0"> 276</span> <span style="color: #228B22; background: #FFFFFF;">       %to the class prior</span><br/>               <span style="color: #A0A0A0"> 277</span> <span style="color: #A0A0A0; background: #FFFFFF;">       function this = normalizeWeights(this)</span><br/>               <span style="color: #A0A0A0"> 278</span> <span style="color: #A0A0A0; background: #FFFFFF;">            C = classreg.learning.internal.classCount(...</span><br/>               <span style="color: #A0A0A0"> 279</span> <span style="color: #A0A0A0; background: #FFFFFF;">                this.ClassSummary.NonzeroProbClasses,this.PrivY);</span><br/>               <span style="color: #A0A0A0"> 280</span> <span style="color: #228B22; background: #FFFFFF;">         </span><br/>               <span style="color: #A0A0A0"> 281</span> <span style="color: #A0A0A0; background: #FFFFFF;">            WC = bsxfun(@times,C,this.PrivW);</span><br/>               <span style="color: #A0A0A0"> 282</span> <span style="color: #A0A0A0; background: #FFFFFF;">            Wj = sum(WC,1);</span><br/>               <span style="color: #A0A0A0"> 283</span> <span style="color: #A0A0A0; background: #FFFFFF;">            this.W = sum(bsxfun(@times,WC,this.ClassSummary.Prior./Wj),2);</span><br/>               <span style="color: #A0A0A0"> 284</span> <span style="color: #A0A0A0; background: #FFFFFF;">       end</span><br/>               <span style="color: #A0A0A0"> 285</span> <span style="color: #228B22; background: #FFFFFF;">         </span><br/>               <span style="color: #A0A0A0"> 286</span> <span style="color: #A0A0A0; background: #FFFFFF;">       function this = setPrior(this,prior)</span><br/>               <span style="color: #A0A0A0"> 287</span> <span style="color: #228B22; background: #FFFFFF;">             % call setPrivatePrior in </span><br/>               <span style="color: #A0A0A0"> 288</span> <span style="color: #228B22; background: #FFFFFF;">             % +classreg\+learning\+classif\ClassificationModel.m</span><br/>               <span style="color: #A0A0A0"> 289</span> <span style="color: #A0A0A0; background: #FFFFFF;">            this = setPrivatePrior(this,prior);  </span><br/>               <span style="color: #A0A0A0"> 290</span> <span style="color: #228B22; background: #FFFFFF;">%             Each time when the prior is set, we need to normalized the</span><br/>               <span style="color: #A0A0A0"> 291</span> <span style="color: #228B22; background: #FFFFFF;">%             observation weights using the new prior</span><br/>               <span style="color: #A0A0A0"> 292</span> <span style="color: #A0A0A0; background: #FFFFFF;">            this = normalizeWeights(this);</span><br/>               <span style="color: #A0A0A0"> 293</span> <span style="color: #A0A0A0; background: #FFFFFF;">        end</span><br/>               <span style="color: #A0A0A0"> 294</span> <span style="color: #228B22; background: #FFFFFF;">         </span><br/>               <span style="color: #A0A0A0"> 295</span> <span style="color: #A0A0A0; background: #FFFFFF;">         function this = setCost(this,cost)</span><br/>               <span style="color: #A0A0A0"> 296</span> <span style="color: #228B22; background: #FFFFFF;">             % call setPrivateCost in </span><br/>               <span style="color: #A0A0A0"> 297</span> <span style="color: #228B22; background: #FFFFFF;">             % +classreg\+learning\+classif\ClassificationModel.m</span><br/>               <span style="color: #A0A0A0"> 298</span> <span style="color: #A0A0A0; background: #FFFFFF;">             this = setPrivateCost(this,cost);       </span><br/>               <span style="color: #A0A0A0"> 299</span> <span style="color: #A0A0A0; background: #FFFFFF;">        end</span><br/>               <span style="color: #A0A0A0"> 300</span> <span style="color: #228B22; background: #FFFFFF;"></span><br/>               <span style="color: #A0A0A0"> 301</span> <span style="color: #228B22; background: #FFFFFF;">       %add properties for display</span><br/>               <span style="color: #A0A0A0"> 302</span> <span style="color: #A0A0A0; background: #FFFFFF;">        function s = propsForDisp(this,s)</span><br/>               <span style="color: #A0A0A0"> 303</span> <span style="color: #A0A0A0; background: #FFFFFF;">            s = propsForDisp@classreg.learning.classif.FullClassificationModel(this,s);</span><br/>               <span style="color: #A0A0A0"> 304</span> <span style="color: #A0A0A0; background: #FFFFFF;">            s.Distance = this.Distance;</span><br/>               <span style="color: #A0A0A0"> 305</span> <span style="color: #A0A0A0; background: #FFFFFF;">            s.NumNeighbors = this.NumNeighbors;  </span><br/>               <span style="color: #A0A0A0"> 306</span> <span style="color: #A0A0A0; background: #FFFFFF;">        end</span><br/>               <span style="color: #A0A0A0"> 307</span> <span style="color: #228B22; background: #FFFFFF;">        </span><br/>               <span style="color: #A0A0A0"> 308</span> <span style="color: #228B22; background: #FFFFFF;">        %must return a N by K(#of classes) matrix for N observation and</span><br/>               <span style="color: #A0A0A0"> 309</span> <span style="color: #228B22; background: #FFFFFF;">        %K classess</span><br/>               <span style="color: #A0A0A0"> 310</span> <span style="color: #A0A0A0; background: #FFFFFF;">        function [s,gindex,CIDX]=score(this,X,varargin)</span><br/>               <span style="color: #A0A0A0"> 311</span> <span style="color: #228B22; background: #FFFFFF;">                   </span><br/>               <span style="color: #A0A0A0"> 312</span> <span style="color: #228B22; background: #FFFFFF;"> </span><br/>               <span style="color: #A0A0A0"> 313</span> <span style="color: #A0A0A0; background: #FFFFFF;">            W = this.W;</span><br/>               <span style="color: #A0A0A0"> 314</span> <span style="color: #A0A0A0; background: #FFFFFF;">            NG = length(this.ClassSummary.ClassNames);</span><br/>               <span style="color: #A0A0A0"> 315</span> <span style="color: #228B22; background: #FFFFFF;">           </span><br/>               <span style="color: #A0A0A0"> 316</span> <span style="color: #A0A0A0; background: #FFFFFF;">            includeTies = this.ModelParams.IncludeTies;</span><br/>               <span style="color: #A0A0A0"> 317</span> <span style="color: #A0A0A0; background: #FFFFFF;">            gindex = grp2idx(this.PrivY,this.ClassSummary.ClassNames); </span><br/>               <span style="color: #A0A0A0"> 318</span> <span style="color: #A0A0A0; background: #FFFFFF;">            distWgtList ={'equal','inverse','squaredinverse'};</span><br/>               <span style="color: #A0A0A0"> 319</span> <span style="color: #A0A0A0; background: #FFFFFF;">            distanceWeightFun = this.ModelParams.DistanceWeight;</span><br/>               <span style="color: #A0A0A0"> 320</span> <span style="color: #A0A0A0; background: #FFFFFF;">            distWgtIdx = find(strncmpi(distanceWeightFun,distWgtList,3));</span><br/>               <span style="color: #A0A0A0"> 321</span> <span style="color: #228B22; background: #FFFFFF;">           </span><br/>               <span style="color: #A0A0A0"> 322</span> <span style="color: #A0A0A0; background: #FFFFFF;">            [CIDX,dist] = knnsearch(this.NS, X,'k',this.ModelParams.NumNeighbors,...</span><br/>               <span style="color: #A0A0A0"> 323</span> <span style="color: #A0A0A0; background: #FFFFFF;">                       'includeTies', includeTies);</span><br/>               <span style="color: #A0A0A0"> 324</span> <span style="color: #228B22; background: #FFFFFF;">            </span><br/>               <span style="color: #A0A0A0"> 325</span> <span style="color: #A0A0A0; background: #FFFFFF;">            NX= size(X,1);</span><br/>               <span style="color: #A0A0A0"> 326</span> <span style="color: #228B22; background: #FFFFFF;">          </span><br/>               <span style="color: #A0A0A0"> 327</span> <span style="color: #228B22; background: #FFFFFF;">            % Returns scores for all classes but compute the scores only</span><br/>               <span style="color: #A0A0A0"> 328</span> <span style="color: #228B22; background: #FFFFFF;">            % for classes with observations in the training data</span><br/>               <span style="color: #A0A0A0"> 329</span> <span style="color: #228B22; background: #FFFFFF;">          </span><br/>               <span style="color: #A0A0A0"> 330</span> <span style="color: #228B22; background: #FFFFFF;">            %  count is a NX-by-NG matrix saving the count of the neighbors</span><br/>               <span style="color: #A0A0A0"> 331</span> <span style="color: #228B22; background: #FFFFFF;">            %  in each class for each query point, NY is the number of points</span><br/>               <span style="color: #A0A0A0"> 332</span> <span style="color: #228B22; background: #FFFFFF;">            %  in test and NG is number of groups</span><br/>               <span style="color: #A0A0A0"> 333</span> <span style="color: #A0A0A0; background: #FFFFFF;">            count =zeros(NX,NG);</span><br/>               <span style="color: #A0A0A0"> 334</span> <span style="color: #A0A0A0; background: #FFFFFF;">            if (includeTies)</span><br/>               <span style="color: #A0A0A0"> 335</span> <span style="color: #A0A0A0; background: #FFFFFF;">                count = zeros(NG,NX);</span><br/>               <span style="color: #A0A0A0"> 336</span> <span style="color: #A0A0A0; background: #FFFFFF;">                if isa(distanceWeightFun,'function_handle')</span><br/>               <span style="color: #A0A0A0"> 337</span> <span style="color: #228B22; background: #FFFFFF;">                    </span><br/>               <span style="color: #A0A0A0"> 338</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    try</span><br/>               <span style="color: #A0A0A0"> 339</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        distWgt = feval(this.ModelParams.DistanceWeight,...</span><br/>               <span style="color: #A0A0A0"> 340</span> <span style="color: #A0A0A0; background: #FFFFFF;">                            dist{1});</span><br/>               <span style="color: #A0A0A0"> 341</span> <span style="color: #228B22; background: #FFFFFF;">                        </span><br/>               <span style="color: #A0A0A0"> 342</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    catch ME</span><br/>               <span style="color: #A0A0A0"> 343</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        if strcmp('MATLAB:UndefinedFunction', ME.identifier) ...</span><br/>               <span style="color: #A0A0A0"> 344</span> <span style="color: #A0A0A0; background: #FFFFFF;">                                &amp;&amp; ~isempty(strfind(ME.message, func2str(distanceWeightFun)))</span><br/>               <span style="color: #A0A0A0"> 345</span> <span style="color: #A0A0A0; background: #FFFFFF;">                            error(message('stats:ClassificationKNN:Score:DistanceFunctionNotFound', func2str( distanceWeightFun )));</span><br/>               <span style="color: #A0A0A0"> 346</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        end</span><br/>               <span style="color: #A0A0A0"> 347</span> <span style="color: #228B22; background: #FFFFFF;">                        </span><br/>               <span style="color: #A0A0A0"> 348</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    end</span><br/>               <span style="color: #A0A0A0"> 349</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    if ~isnumeric(distWgt)</span><br/>               <span style="color: #A0A0A0"> 350</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        error(message('stats:ClassificationKNN:Score:OutputBadType'));</span><br/>               <span style="color: #A0A0A0"> 351</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    end</span><br/>               <span style="color: #A0A0A0"> 352</span> <span style="color: #228B22; background: #FFFFFF;">                   </span><br/>               <span style="color: #A0A0A0"> 353</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    for outer =1:NX</span><br/>               <span style="color: #A0A0A0"> 354</span> <span style="color: #228B22; background: #FFFFFF;">                        %nan values in the dist will be ignored</span><br/>               <span style="color: #A0A0A0"> 355</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        numNeighbors = sum(~isnan(dist{outer}));</span><br/>               <span style="color: #A0A0A0"> 356</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        tempCIDX =CIDX{outer}(1:numNeighbors);</span><br/>               <span style="color: #A0A0A0"> 357</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        tempIDX =gindex(tempCIDX);</span><br/>               <span style="color: #A0A0A0"> 358</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        tempDist = dist{outer}(1:numNeighbors);</span><br/>               <span style="color: #A0A0A0"> 359</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        obsWgt = W(tempCIDX);              </span><br/>               <span style="color: #A0A0A0"> 360</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        distWgt = feval(this.ModelParams.DistanceWeight,tempDist );</span><br/>               <span style="color: #A0A0A0"> 361</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        if (any(distWgt&lt;0))</span><br/>               <span style="color: #A0A0A0"> 362</span> <span style="color: #A0A0A0; background: #FFFFFF;">                             error(message('stats:ClassificationKNN:Score:NegativeDistanceWgt'));</span><br/>               <span style="color: #A0A0A0"> 363</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        end</span><br/>               <span style="color: #A0A0A0"> 364</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        wgt = obsWgt .* distWgt';</span><br/>               <span style="color: #A0A0A0"> 365</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        wgt(isnan(wgt)) = 0; %don't consider neighbors with NaN weights</span><br/>               <span style="color: #A0A0A0"> 366</span> <span style="color: #228B22; background: #FFFFFF;">                        %Both tempIDX and wgt are numneighbor-by-one vectors </span><br/>               <span style="color: #A0A0A0"> 367</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        count(:,outer) = ...</span><br/>               <span style="color: #A0A0A0"> 368</span> <span style="color: #A0A0A0; background: #FFFFFF;">                                accumarray(tempIDX,wgt,[NG,1]);              </span><br/>               <span style="color: #A0A0A0"> 369</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    end</span><br/>               <span style="color: #A0A0A0"> 370</span> <span style="color: #228B22; background: #FFFFFF;">         </span><br/>               <span style="color: #A0A0A0"> 371</span> <span style="color: #A0A0A0; background: #FFFFFF;">                elseif distWgtIdx == 1 %equal weight</span><br/>               <span style="color: #A0A0A0"> 372</span> <span style="color: #228B22; background: #FFFFFF;">                    </span><br/>               <span style="color: #A0A0A0"> 373</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    for outer =1:NX</span><br/>               <span style="color: #A0A0A0"> 374</span> <span style="color: #228B22; background: #FFFFFF;">                        %nan values in the dist will be ignored</span><br/>               <span style="color: #A0A0A0"> 375</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        numNeighbors = sum(~isnan(dist{outer}));</span><br/>               <span style="color: #A0A0A0"> 376</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        tempCIDX =CIDX{outer}(1:numNeighbors);</span><br/>               <span style="color: #A0A0A0"> 377</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        tempIDX =gindex(tempCIDX);</span><br/>               <span style="color: #A0A0A0"> 378</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        wgt = W(tempCIDX);</span><br/>               <span style="color: #A0A0A0"> 379</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        count(:,outer) = ...</span><br/>               <span style="color: #A0A0A0"> 380</span> <span style="color: #A0A0A0; background: #FFFFFF;">                                accumarray(tempIDX,wgt,[NG,1]);                         </span><br/>               <span style="color: #A0A0A0"> 381</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    end</span><br/>               <span style="color: #A0A0A0"> 382</span> <span style="color: #228B22; background: #FFFFFF;">                       </span><br/>               <span style="color: #A0A0A0"> 383</span> <span style="color: #228B22; background: #FFFFFF;">                else % inverse weight or squared inverse weight</span><br/>               <span style="color: #A0A0A0"> 384</span> <span style="color: #228B22; background: #FFFFFF;">                   </span><br/>               <span style="color: #A0A0A0"> 385</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    if distWgtIdx==2 %'inverse'</span><br/>               <span style="color: #A0A0A0"> 386</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        e = 1;</span><br/>               <span style="color: #A0A0A0"> 387</span> <span style="color: #228B22; background: #FFFFFF;">                    else</span><br/>               <span style="color: #A0A0A0"> 388</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        e = 2;</span><br/>               <span style="color: #A0A0A0"> 389</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    end</span><br/>               <span style="color: #A0A0A0"> 390</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    for outer =1:NX</span><br/>               <span style="color: #A0A0A0"> 391</span> <span style="color: #228B22; background: #FFFFFF;">                        %nan values in the dist will be ignored</span><br/>               <span style="color: #A0A0A0"> 392</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        numNeighbors = sum(~isnan(dist{outer}));</span><br/>               <span style="color: #A0A0A0"> 393</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        tempCIDX =CIDX{outer}(1:numNeighbors);</span><br/>               <span style="color: #A0A0A0"> 394</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        tempIDX =gindex(tempCIDX);</span><br/>               <span style="color: #A0A0A0"> 395</span> <span style="color: #228B22; background: #FFFFFF;">                        </span><br/>               <span style="color: #A0A0A0"> 396</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        obsWgt = W(tempCIDX);</span><br/>               <span style="color: #A0A0A0"> 397</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        tempDist = dist{outer}(1:numNeighbors);</span><br/>               <span style="color: #A0A0A0"> 398</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        distWgt = wgtFunc(tempDist,e);</span><br/>               <span style="color: #A0A0A0"> 399</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        wgt = obsWgt .* distWgt';</span><br/>               <span style="color: #A0A0A0"> 400</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        count(:,outer) = ...</span><br/>               <span style="color: #A0A0A0"> 401</span> <span style="color: #A0A0A0; background: #FFFFFF;">                                accumarray(tempIDX,wgt,[NG,1]);</span><br/>               <span style="color: #A0A0A0"> 402</span> <span style="color: #228B22; background: #FFFFFF;"></span><br/>               <span style="color: #A0A0A0"> 403</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    end  </span><br/>               <span style="color: #A0A0A0"> 404</span> <span style="color: #228B22; background: #FFFFFF;">                   </span><br/>               <span style="color: #A0A0A0"> 405</span> <span style="color: #A0A0A0; background: #FFFFFF;">                end</span><br/>               <span style="color: #A0A0A0"> 406</span> <span style="color: #A0A0A0; background: #FFFFFF;">                count = count';            </span><br/>               <span style="color: #A0A0A0"> 407</span> <span style="color: #228B22; background: #FFFFFF;">            else % includeTie is false</span><br/>               <span style="color: #A0A0A0"> 408</span> <span style="color: #228B22; background: #FFFFFF;">                                   </span><br/>               <span style="color: #A0A0A0"> 409</span> <span style="color: #228B22; background: #FFFFFF;">                %Find the number of valid neighbors</span><br/>               <span style="color: #A0A0A0"> 410</span> <span style="color: #228B22; background: #FFFFFF;">                %The columns in matrix dist with nan values in the whole column</span><br/>               <span style="color: #A0A0A0"> 411</span> <span style="color: #228B22; background: #FFFFFF;">                %will be ignored. </span><br/>               <span style="color: #A0A0A0"> 412</span> <span style="color: #228B22; background: #FFFFFF;">                %note that some distance, (e.g., cosine) may have NaN</span><br/>               <span style="color: #A0A0A0"> 413</span> <span style="color: #228B22; background: #FFFFFF;">                %values even the data doesn't have NaNs. Therefor the</span><br/>               <span style="color: #A0A0A0"> 414</span> <span style="color: #228B22; background: #FFFFFF;">                %following step is needed even we remove the observations</span><br/>               <span style="color: #A0A0A0"> 415</span> <span style="color: #228B22; background: #FFFFFF;">                %with NaN values in the training data.</span><br/>               <span style="color: #A0A0A0"> 416</span> <span style="color: #A0A0A0; background: #FFFFFF;">                numNeighbors = sum((~all(isnan(dist),1)));</span><br/>               <span style="color: #A0A0A0"> 417</span> <span style="color: #A0A0A0; background: #FFFFFF;">                if numNeighbors &gt; 0</span><br/>               <span style="color: #A0A0A0"> 418</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    dist(:,numNeighbors+1:end)=[]; %don't consider invalid neighbors</span><br/>               <span style="color: #A0A0A0"> 419</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    CIDX(:,numNeighbors+1:end)=[];</span><br/>               <span style="color: #A0A0A0"> 420</span> <span style="color: #228B22; background: #FFFFFF;">                    </span><br/>               <span style="color: #A0A0A0"> 421</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    if isa(distanceWeightFun,'function_handle')</span><br/>               <span style="color: #A0A0A0"> 422</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        try</span><br/>               <span style="color: #A0A0A0"> 423</span> <span style="color: #A0A0A0; background: #FFFFFF;">                            distWgt = feval(this.ModelParams.DistanceWeight,dist(1,:));</span><br/>               <span style="color: #A0A0A0"> 424</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        catch ME</span><br/>               <span style="color: #A0A0A0"> 425</span> <span style="color: #A0A0A0; background: #FFFFFF;">                            if strcmp('MATLAB:UndefinedFunction', ME.identifier) ...</span><br/>               <span style="color: #A0A0A0"> 426</span> <span style="color: #A0A0A0; background: #FFFFFF;">                                    &amp;&amp; ~isempty(strfind(ME.message, func2str(distanceWeightFun)))</span><br/>               <span style="color: #A0A0A0"> 427</span> <span style="color: #A0A0A0; background: #FFFFFF;">                                error(message('stats:ClassificationKNN:Score:DistanceFunctionNotFound',...</span><br/>               <span style="color: #A0A0A0"> 428</span> <span style="color: #A0A0A0; background: #FFFFFF;">                                    func2str( distanceWeightFun )));</span><br/>               <span style="color: #A0A0A0"> 429</span> <span style="color: #A0A0A0; background: #FFFFFF;">                            end</span><br/>               <span style="color: #A0A0A0"> 430</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        end</span><br/>               <span style="color: #A0A0A0"> 431</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        if ~isnumeric(distWgt)</span><br/>               <span style="color: #A0A0A0"> 432</span> <span style="color: #A0A0A0; background: #FFFFFF;">                            error(message('stats:ClassificationKNN:Score:OutputBadType'));</span><br/>               <span style="color: #A0A0A0"> 433</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        end</span><br/>               <span style="color: #A0A0A0"> 434</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        distWgt = feval(this.ModelParams.DistanceWeight,dist );</span><br/>               <span style="color: #A0A0A0"> 435</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        if any(distWgt(:)&lt; 0)</span><br/>               <span style="color: #A0A0A0"> 436</span> <span style="color: #A0A0A0; background: #FFFFFF;">                             error(message('stats:ClassificationKNN:Score:NegativeDistanceWgt'));</span><br/>               <span style="color: #A0A0A0"> 437</span> <span style="color: #A0A0A0; background: #FFFFFF;">                       end</span><br/>               <span style="color: #A0A0A0"> 438</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    elseif distWgtIdx==1 %equal weight</span><br/>               <span style="color: #A0A0A0"> 439</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        distWgt = ones(NX,numNeighbors);</span><br/>               <span style="color: #A0A0A0"> 440</span> <span style="color: #228B22; background: #FFFFFF;">                        %weights for neighbors which has NaN distance to</span><br/>               <span style="color: #A0A0A0"> 441</span> <span style="color: #228B22; background: #FFFFFF;">                        %the test point is set to zero,so that this</span><br/>               <span style="color: #A0A0A0"> 442</span> <span style="color: #228B22; background: #FFFFFF;">                        %neighbr will be ingored.</span><br/>               <span style="color: #A0A0A0"> 443</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        distWgt(isnan(dist)) = 0;</span><br/>               <span style="color: #A0A0A0"> 444</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    elseif distWgtIdx==2 %inverse</span><br/>               <span style="color: #A0A0A0"> 445</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        distWgt = wgtFunc(dist,1);</span><br/>               <span style="color: #A0A0A0"> 446</span> <span style="color: #228B22; background: #FFFFFF;">                    else</span><br/>               <span style="color: #A0A0A0"> 447</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        distWgt = wgtFunc(dist,2);</span><br/>               <span style="color: #A0A0A0"> 448</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    end</span><br/>               <span style="color: #A0A0A0"> 449</span> <span style="color: #228B22; background: #FFFFFF;">                    </span><br/>               <span style="color: #A0A0A0"> 450</span> <span style="color: #228B22; background: #FFFFFF;">                    %CNeighbor is a matrix with size NX by numNeighbors</span><br/>               <span style="color: #A0A0A0"> 451</span> <span style="color: #228B22; background: #FFFFFF;">                    %representing the class labels for nearest neighbors             </span><br/>               <span style="color: #A0A0A0"> 452</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    CNeighbor = gindex(CIDX);</span><br/>               <span style="color: #A0A0A0"> 453</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    obsWgt= W(CIDX);</span><br/>               <span style="color: #A0A0A0"> 454</span> <span style="color: #228B22; background: #FFFFFF;">                    </span><br/>               <span style="color: #A0A0A0"> 455</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    if (NX==1) &amp;&amp; numNeighbors &gt; 1</span><br/>               <span style="color: #A0A0A0"> 456</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        CNeighbor = CNeighbor';</span><br/>               <span style="color: #A0A0A0"> 457</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        obsWgt = obsWgt';</span><br/>               <span style="color: #A0A0A0"> 458</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    end</span><br/>               <span style="color: #A0A0A0"> 459</span> <span style="color: #228B22; background: #FFFFFF;">                    </span><br/>               <span style="color: #A0A0A0"> 460</span> <span style="color: #228B22; background: #FFFFFF;">                    %wgt is a matrix with size NX by numNeighbors</span><br/>               <span style="color: #A0A0A0"> 461</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    wgt = distWgt .* obsWgt;</span><br/>               <span style="color: #A0A0A0"> 462</span> <span style="color: #228B22; background: #FFFFFF;">                    %don't consider neighbors with NaN weights</span><br/>               <span style="color: #A0A0A0"> 463</span> <span style="color: #228B22; background: #FFFFFF;">                    %This NaN values may happen, for example, if the number</span><br/>               <span style="color: #A0A0A0"> 464</span> <span style="color: #228B22; background: #FFFFFF;">                    %of valid training points is less than the number of</span><br/>               <span style="color: #A0A0A0"> 465</span> <span style="color: #228B22; background: #FFFFFF;">                    %requsted neighbors.</span><br/>               <span style="color: #A0A0A0"> 466</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    wgt(isnan(wgt)) = 0; </span><br/>               <span style="color: #A0A0A0"> 467</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    if numNeighbors &gt; 5</span><br/>               <span style="color: #A0A0A0"> 468</span> <span style="color: #228B22; background: #FFFFFF;">                        %when the number of neighbors is bigger than 5,</span><br/>               <span style="color: #A0A0A0"> 469</span> <span style="color: #228B22; background: #FFFFFF;">                        %using accumarray is faster than using the loop</span><br/>               <span style="color: #A0A0A0"> 470</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        count =zeros(NG,NX);</span><br/>               <span style="color: #A0A0A0"> 471</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        wgt=wgt';</span><br/>               <span style="color: #A0A0A0"> 472</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        CNeighbor = CNeighbor';</span><br/>               <span style="color: #A0A0A0"> 473</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        for i = 1:NX</span><br/>               <span style="color: #A0A0A0"> 474</span> <span style="color: #A0A0A0; background: #FFFFFF;">                            count(:,i) = ...</span><br/>               <span style="color: #A0A0A0"> 475</span> <span style="color: #A0A0A0; background: #FFFFFF;">                                accumarray(CNeighbor(:,i),wgt(:,i),[NG,1]);</span><br/>               <span style="color: #A0A0A0"> 476</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        end</span><br/>               <span style="color: #A0A0A0"> 477</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        count = count';</span><br/>               <span style="color: #A0A0A0"> 478</span> <span style="color: #228B22; background: #FFFFFF;">                    else %</span><br/>               <span style="color: #A0A0A0"> 479</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        count = zeros(NX,NG);</span><br/>               <span style="color: #A0A0A0"> 480</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        for outer = 1:NX</span><br/>               <span style="color: #A0A0A0"> 481</span> <span style="color: #A0A0A0; background: #FFFFFF;">                            for inner = 1:numNeighbors</span><br/>               <span style="color: #A0A0A0"> 482</span> <span style="color: #A0A0A0; background: #FFFFFF;">                                count(outer,CNeighbor(outer,inner))=...</span><br/>               <span style="color: #A0A0A0"> 483</span> <span style="color: #A0A0A0; background: #FFFFFF;">                                    count(outer,CNeighbor(outer,inner))+wgt(outer,inner);</span><br/>               <span style="color: #A0A0A0"> 484</span> <span style="color: #A0A0A0; background: #FFFFFF;">                            end</span><br/>               <span style="color: #A0A0A0"> 485</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        end</span><br/>               <span style="color: #A0A0A0"> 486</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    end</span><br/>               <span style="color: #A0A0A0"> 487</span> <span style="color: #A0A0A0; background: #FFFFFF;">                end</span><br/>               <span style="color: #A0A0A0"> 488</span> <span style="color: #A0A0A0; background: #FFFFFF;">            end</span><br/>               <span style="color: #A0A0A0"> 489</span> <span style="color: #228B22; background: #FFFFFF;">         </span><br/>               <span style="color: #A0A0A0"> 490</span> <span style="color: #A0A0A0; background: #FFFFFF;">            if isa(distanceWeightFun,'function_handle')</span><br/>               <span style="color: #A0A0A0"> 491</span> <span style="color: #228B22; background: #FFFFFF;">                %deal with inf weight values when distance weight</span><br/>               <span style="color: #A0A0A0"> 492</span> <span style="color: #228B22; background: #FFFFFF;">                %function is function handle</span><br/>               <span style="color: #A0A0A0"> 493</span> <span style="color: #A0A0A0; background: #FFFFFF;">                infCountRow = any(isinf(count),2);</span><br/>               <span style="color: #A0A0A0"> 494</span> <span style="color: #A0A0A0; background: #FFFFFF;">                s = count;</span><br/>               <span style="color: #A0A0A0"> 495</span> <span style="color: #A0A0A0; background: #FFFFFF;">                s(infCountRow,:) = 0;</span><br/>               <span style="color: #A0A0A0"> 496</span> <span style="color: #A0A0A0; background: #FFFFFF;">                s(isinf(count)) = 1;</span><br/>               <span style="color: #A0A0A0"> 497</span> <span style="color: #228B22; background: #FFFFFF;">                %to deal with the case that one point has two</span><br/>               <span style="color: #A0A0A0"> 498</span> <span style="color: #228B22; background: #FFFFFF;">                %points with infinite weight but coming from</span><br/>               <span style="color: #A0A0A0"> 499</span> <span style="color: #228B22; background: #FFFFFF;">                %different classes.</span><br/>               <span style="color: #A0A0A0"> 500</span> <span style="color: #A0A0A0; background: #FFFFFF;">                s=bsxfun(@rdivide, s, sum(s,2));</span><br/>               <span style="color: #A0A0A0"> 501</span> <span style="color: #228B22; background: #FFFFFF;">            else</span><br/>               <span style="color: #A0A0A0"> 502</span> <span style="color: #A0A0A0; background: #FFFFFF;">                s=bsxfun(@rdivide, count, sum(count,2));</span><br/>               <span style="color: #A0A0A0"> 503</span> <span style="color: #A0A0A0; background: #FFFFFF;">            end</span><br/>               <span style="color: #A0A0A0"> 504</span> <span style="color: #228B22; background: #FFFFFF;">         </span><br/>               <span style="color: #A0A0A0"> 505</span> <span style="color: #A0A0A0; background: #FFFFFF;">        end      </span><br/>               <span style="color: #A0A0A0"> 506</span> <span style="color: #228B22; background: #FFFFFF;">        </span><br/>               <span style="color: #A0A0A0"> 507</span> <span style="color: #A0A0A0; background: #FFFFFF;">    end</span><br/>               <span style="color: #A0A0A0"> 508</span> <span style="color: #228B22; background: #FFFFFF;">    </span><br/>               <span style="color: #A0A0A0"> 509</span> <span style="color: #A0A0A0; background: #FFFFFF;">    methods</span><br/>               <span style="color: #A0A0A0"> 510</span> <span style="color: #A0A0A0; background: #FFFFFF;">        function partModel = crossval(this,varargin)</span><br/>               <span style="color: #A0A0A0"> 511</span> <span style="color: #228B22; background: #FFFFFF;">        %CROSSVAL Cross-validate this model.</span><br/>               <span style="color: #A0A0A0"> 512</span> <span style="color: #228B22; background: #FFFFFF;">        %   CVMODEL=CROSSVAL(MODEL) builds a partitioned model CVMODEL from model</span><br/>               <span style="color: #A0A0A0"> 513</span> <span style="color: #228B22; background: #FFFFFF;">        %   MODEL represented by a full object for classification. You can then</span><br/>               <span style="color: #A0A0A0"> 514</span> <span style="color: #228B22; background: #FFFFFF;">        %   assess the predictive performance of this model on cross-validated data</span><br/>               <span style="color: #A0A0A0"> 515</span> <span style="color: #228B22; background: #FFFFFF;">        %   using methods and properties of CVMODEL. By default, CVMODEL is built</span><br/>               <span style="color: #A0A0A0"> 516</span> <span style="color: #228B22; background: #FFFFFF;">        %   using 10-fold cross-validation on the training data. CVMODEL is of</span><br/>               <span style="color: #A0A0A0"> 517</span> <span style="color: #228B22; background: #FFFFFF;">        %   class ClassificationPartitionedModel.</span><br/>               <span style="color: #A0A0A0"> 518</span> <span style="color: #228B22; background: #FFFFFF;">        %</span><br/>               <span style="color: #A0A0A0"> 519</span> <span style="color: #228B22; background: #FFFFFF;">        %   CVMODEL=CROSSVAL(MODEL,'PARAM1',val1,'PARAM2',val2,...) specifies</span><br/>               <span style="color: #A0A0A0"> 520</span> <span style="color: #228B22; background: #FFFFFF;">        %   optional parameter name/value pairs:</span><br/>               <span style="color: #A0A0A0"> 521</span> <span style="color: #228B22; background: #FFFFFF;">        %      'kfold'      - Number of folds for cross-validation, a numeric</span><br/>               <span style="color: #A0A0A0"> 522</span> <span style="color: #228B22; background: #FFFFFF;">        %                     positive scalar; 10 by default.</span><br/>               <span style="color: #A0A0A0"> 523</span> <span style="color: #228B22; background: #FFFFFF;">        %      'holdout'    - Holdout validation uses the specified</span><br/>               <span style="color: #A0A0A0"> 524</span> <span style="color: #228B22; background: #FFFFFF;">        %                     fraction of the data for test, and uses the rest of</span><br/>               <span style="color: #A0A0A0"> 525</span> <span style="color: #228B22; background: #FFFFFF;">        %                     the data for training. Specify a numeric scalar</span><br/>               <span style="color: #A0A0A0"> 526</span> <span style="color: #228B22; background: #FFFFFF;">        %                     between 0 and 1.</span><br/>               <span style="color: #A0A0A0"> 527</span> <span style="color: #228B22; background: #FFFFFF;">        %      'leaveout'   - If 'on', use leave-one-out cross-validation.</span><br/>               <span style="color: #A0A0A0"> 528</span> <span style="color: #228B22; background: #FFFFFF;">        %      'cvpartition' - An object of class CVPARTITION; empty by default. If</span><br/>               <span style="color: #A0A0A0"> 529</span> <span style="color: #228B22; background: #FFFFFF;">        %                      a CVPARTITION object is supplied, it is used for</span><br/>               <span style="color: #A0A0A0"> 530</span> <span style="color: #228B22; background: #FFFFFF;">        %                      splitting the data into subsets.</span><br/>               <span style="color: #A0A0A0"> 531</span> <span style="color: #228B22; background: #FFFFFF;">        %</span><br/>               <span style="color: #A0A0A0"> 532</span> <span style="color: #228B22; background: #FFFFFF;">        %   See also classreg.learning.classif.FullClassificationModel,</span><br/>               <span style="color: #A0A0A0"> 533</span> <span style="color: #228B22; background: #FFFFFF;">        %   cvpartition,</span><br/>               <span style="color: #A0A0A0"> 534</span> <span style="color: #228B22; background: #FFFFFF;">        %   classreg.learning.partition.ClassificationPartitionedModel.</span><br/>               <span style="color: #A0A0A0"> 535</span> <span style="color: #228B22; background: #FFFFFF;"></span><br/>               <span style="color: #A0A0A0"> 536</span> <span style="color: #228B22; background: #FFFFFF;">     </span><br/>               <span style="color: #A0A0A0"> 537</span> <span style="color: #A0A0A0; background: #FFFFFF;">            idxBaseArg = find(ismember(lower(varargin(1:2:end)),...</span><br/>               <span style="color: #A0A0A0"> 538</span> <span style="color: #A0A0A0; background: #FFFFFF;">                classreg.learning.FitTemplate.AllowedBaseFitObjectArgs));</span><br/>               <span style="color: #A0A0A0"> 539</span> <span style="color: #A0A0A0; background: #FFFFFF;">            if ~isempty(idxBaseArg)</span><br/>               <span style="color: #A0A0A0"> 540</span> <span style="color: #A0A0A0; background: #FFFFFF;">                error(message('stats:classreg:learning:classif:FullClassificationModel:crossval:NoBaseArgs', varargin{ 2*idxBaseArg - 1 }));</span><br/>               <span style="color: #A0A0A0"> 541</span> <span style="color: #A0A0A0; background: #FFFFFF;">            end</span><br/>               <span style="color: #A0A0A0"> 542</span> <span style="color: #A0A0A0; background: #FFFFFF;">            temp = classreg.learning.FitTemplate.make(this.ModelParams.Method,...</span><br/>               <span style="color: #A0A0A0"> 543</span> <span style="color: #A0A0A0; background: #FFFFFF;">                'type','classification','scoretransform',this.PrivScoreTransform,...</span><br/>               <span style="color: #A0A0A0"> 544</span> <span style="color: #A0A0A0; background: #FFFFFF;">                'modelparams',this.ModelParams,'crossval','on',varargin{:});</span><br/>               <span style="color: #A0A0A0"> 545</span> <span style="color: #228B22; background: #FFFFFF;">          %  ClassificationKNN/crossval must pass prior but not cost o the</span><br/>               <span style="color: #A0A0A0"> 546</span> <span style="color: #228B22; background: #FFFFFF;">          %  constructor of the partitioned model. It must assign cost</span><br/>               <span style="color: #A0A0A0"> 547</span> <span style="color: #228B22; background: #FFFFFF;">          %  after the partitioned model is constructed. </span><br/>               <span style="color: #A0A0A0"> 548</span> <span style="color: #A0A0A0; background: #FFFFFF;">            partModel = fit(temp,this.X,this.Y,'weights',this.W,...</span><br/>               <span style="color: #A0A0A0"> 549</span> <span style="color: #A0A0A0; background: #FFFFFF;">                'predictornames',this.DataSummary.PredictorNames,...</span><br/>               <span style="color: #A0A0A0"> 550</span> <span style="color: #A0A0A0; background: #FFFFFF;">                'categoricalpredictors',this.CategoricalPredictors,...</span><br/>               <span style="color: #A0A0A0"> 551</span> <span style="color: #A0A0A0; background: #FFFFFF;">                'responsename',this.ResponseName,...</span><br/>               <span style="color: #A0A0A0"> 552</span> <span style="color: #A0A0A0; background: #FFFFFF;">                'classnames',this.ClassNames,'prior',this.Prior);</span><br/>               <span style="color: #A0A0A0"> 553</span> <span style="color: #A0A0A0; background: #FFFFFF;">            partModel.Cost = this.Cost;</span><br/>               <span style="color: #A0A0A0"> 554</span> <span style="color: #A0A0A0; background: #FFFFFF;">        end</span><br/>               <span style="color: #A0A0A0"> 555</span> <span style="color: #228B22; background: #FFFFFF;">        </span><br/>               <span style="color: #A0A0A0"> 556</span> <span style="color: #A0A0A0; background: #FFFFFF;">        function [label,posteriors,cost] = predict(this,X)</span><br/>               <span style="color: #A0A0A0"> 557</span> <span style="color: #228B22; background: #FFFFFF;">        %PREDICT Predict response of KNN classification model.</span><br/>               <span style="color: #A0A0A0"> 558</span> <span style="color: #228B22; background: #FFFFFF;">            %   [LABEL,POSTERIOR,COST]=PREDICT(KNN,X) returns predicted</span><br/>               <span style="color: #A0A0A0"> 559</span> <span style="color: #228B22; background: #FFFFFF;">            %   class labels LABEL, posterior probabilities POSTERIOR and</span><br/>               <span style="color: #A0A0A0"> 560</span> <span style="color: #228B22; background: #FFFFFF;">            %   misclassification costs COST for KNN and a matrix of</span><br/>               <span style="color: #A0A0A0"> 561</span> <span style="color: #228B22; background: #FFFFFF;">            %   predictors X. X must be a numeric matrix of size N-by-P,</span><br/>               <span style="color: #A0A0A0"> 562</span> <span style="color: #228B22; background: #FFFFFF;">            %   where P is the number of predictors used for training this</span><br/>               <span style="color: #A0A0A0"> 563</span> <span style="color: #228B22; background: #FFFFFF;">            %   model. Classification labels LABEL have the same type as Y</span><br/>               <span style="color: #A0A0A0"> 564</span> <span style="color: #228B22; background: #FFFFFF;">            %   used for training. Posterior probabilities POSTERIOR are an</span><br/>               <span style="color: #A0A0A0"> 565</span> <span style="color: #228B22; background: #FFFFFF;">            %   N-by-K numeric matrix for N observations and K classes.</span><br/>               <span style="color: #A0A0A0"> 566</span> <span style="color: #228B22; background: #FFFFFF;">            %   COST is an N-by-K matrix with predicted misclassification</span><br/>               <span style="color: #A0A0A0"> 567</span> <span style="color: #228B22; background: #FFFFFF;">            %   costs per class. The predicted label is assigned to the</span><br/>               <span style="color: #A0A0A0"> 568</span> <span style="color: #228B22; background: #FFFFFF;">            %   class with the minimal misclassification cost.</span><br/>               <span style="color: #A0A0A0"> 569</span> <span style="color: #228B22; background: #FFFFFF;">            %</span><br/>               <span style="color: #A0A0A0"> 570</span> <span style="color: #228B22; background: #FFFFFF;">            %   See also ClassificationKNN</span><br/>               <span style="color: #A0A0A0"> 571</span> <span style="color: #228B22; background: #FFFFFF;">            </span><br/>               <span style="color: #A0A0A0"> 572</span> <span style="color: #228B22; background: #FFFFFF;">            %override the predict method in ClassificationModel to add the</span><br/>               <span style="color: #A0A0A0"> 573</span> <span style="color: #228B22; background: #FFFFFF;">            %third output COST</span><br/>               <span style="color: #A0A0A0"> 574</span> <span style="color: #228B22; background: #FFFFFF;">            % Empty data</span><br/>               <span style="color: #A0A0A0"> 575</span> <span style="color: #A0A0A0; background: #FFFFFF;">            if isempty(X)</span><br/>               <span style="color: #A0A0A0"> 576</span> <span style="color: #A0A0A0; background: #FFFFFF;">                [label,posteriors] = predictEmptyX(this,X);</span><br/>               <span style="color: #A0A0A0"> 577</span> <span style="color: #A0A0A0; background: #FFFFFF;">                cost = NaN(0,numel(this.ClassSummary.ClassNames));</span><br/>               <span style="color: #A0A0A0"> 578</span> <span style="color: #A0A0A0; background: #FFFFFF;">                return;</span><br/>               <span style="color: #A0A0A0"> 579</span> <span style="color: #A0A0A0; background: #FFFFFF;">            end</span><br/>               <span style="color: #A0A0A0"> 580</span> <span style="color: #228B22; background: #FFFFFF;">            </span><br/>               <span style="color: #A0A0A0"> 581</span> <span style="color: #228B22; background: #FFFFFF;">            % Get posterior probabilities(P(x|k)) from score() method</span><br/>               <span style="color: #A0A0A0"> 582</span> <span style="color: #A0A0A0; background: #FFFFFF;">             breakTieFlag= find(strncmpi(this.BreakTies,{'random','nearest'},3));</span><br/>               <span style="color: #A0A0A0"> 583</span> <span style="color: #228B22; background: #FFFFFF;">              %if 'BreakTies' is 'smallest' or 'random' or only 1 nearest</span><br/>               <span style="color: #A0A0A0"> 584</span> <span style="color: #228B22; background: #FFFFFF;">              %neighbor is used</span><br/>               <span style="color: #A0A0A0"> 585</span> <span style="color: #A0A0A0; background: #FFFFFF;">              if isempty(breakTieFlag) || breakTieFlag == 1 ||...</span><br/>               <span style="color: #A0A0A0"> 586</span> <span style="color: #A0A0A0; background: #FFFFFF;">                      this.NumNeighbors ==  1</span><br/>               <span style="color: #A0A0A0"> 587</span> <span style="color: #A0A0A0; background: #FFFFFF;">                 posteriors = score(this,X);</span><br/>               <span style="color: #A0A0A0"> 588</span> <span style="color: #228B22; background: #FFFFFF;">              else</span><br/>               <span style="color: #A0A0A0"> 589</span> <span style="color: #A0A0A0; background: #FFFFFF;">                 [posteriors,gindex,CIDX] = score(this,X);</span><br/>               <span style="color: #A0A0A0"> 590</span> <span style="color: #A0A0A0; background: #FFFFFF;">              end</span><br/>               <span style="color: #A0A0A0"> 591</span> <span style="color: #228B22; background: #FFFFFF;">             % Transform posterior, compute expected cost and find the class</span><br/>               <span style="color: #A0A0A0"> 592</span> <span style="color: #228B22; background: #FFFFFF;">             % with minimal predicted cost</span><br/>               <span style="color: #A0A0A0"> 593</span> <span style="color: #228B22; background: #FFFFFF;">%             [label,posterior,cost] = this.LabelPredictor(this.ClassNames,...</span><br/>               <span style="color: #A0A0A0"> 594</span> <span style="color: #228B22; background: #FFFFFF;">%                 this.Prior,this.Cost,posterior,this.PrivScoreTransform);</span><br/>               <span style="color: #A0A0A0"> 595</span> <span style="color: #A0A0A0; background: #FFFFFF;">            cost = posteriors*this.Cost;</span><br/>               <span style="color: #A0A0A0"> 596</span> <span style="color: #A0A0A0; background: #FFFFFF;">            N = size(posteriors,1);</span><br/>               <span style="color: #A0A0A0"> 597</span> <span style="color: #A0A0A0; background: #FFFFFF;">            notNaN = ~all(isnan(cost),2);</span><br/>               <span style="color: #A0A0A0"> 598</span> <span style="color: #A0A0A0; background: #FFFFFF;">            [~,cls] = max(this.Prior);</span><br/>               <span style="color: #A0A0A0"> 599</span> <span style="color: #A0A0A0; background: #FFFFFF;">            label = repmat(this.ClassNames(cls,:),N,1);</span><br/>               <span style="color: #A0A0A0"> 600</span> <span style="color: #A0A0A0; background: #FFFFFF;">            minCost = nan(N,1);</span><br/>               <span style="color: #A0A0A0"> 601</span> <span style="color: #A0A0A0; background: #FFFFFF;">            [minCost(notNaN),classNum] = min(cost(notNaN,:),[],2);</span><br/>               <span style="color: #A0A0A0"> 602</span> <span style="color: #A0A0A0; background: #FFFFFF;">            label(notNaN,:) = this.ClassNames(classNum,:);</span><br/>               <span style="color: #A0A0A0"> 603</span> <span style="color: #A0A0A0; background: #FFFFFF;">            posteriors = this.PrivScoreTransform(posteriors);</span><br/>               <span style="color: #A0A0A0"> 604</span> <span style="color: #228B22; background: #FFFFFF;">            </span><br/>               <span style="color: #A0A0A0"> 605</span> <span style="color: #228B22; background: #FFFFFF;">            %deal with BreakTies</span><br/>               <span style="color: #A0A0A0"> 606</span> <span style="color: #A0A0A0; background: #FFFFFF;">            if ~isempty(breakTieFlag) &amp;&amp; this.NumNeighbors &gt; 1</span><br/>               <span style="color: #A0A0A0"> 607</span> <span style="color: #228B22; background: #FFFFFF;">                </span><br/>               <span style="color: #A0A0A0"> 608</span> <span style="color: #A0A0A0; background: #FFFFFF;">                notNanRows = find(notNaN);</span><br/>               <span style="color: #A0A0A0"> 609</span> <span style="color: #A0A0A0; background: #FFFFFF;">                if breakTieFlag==1 % BreakTies is 'random'</span><br/>               <span style="color: #A0A0A0"> 610</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    for i =1:numel(notNanRows)</span><br/>               <span style="color: #A0A0A0"> 611</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        ties = cost(notNanRows(i),:) == minCost(notNanRows(i));</span><br/>               <span style="color: #A0A0A0"> 612</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        numTies = sum(ties);</span><br/>               <span style="color: #A0A0A0"> 613</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        if  numTies &gt; 1 % there existed ties</span><br/>               <span style="color: #A0A0A0"> 614</span> <span style="color: #A0A0A0; background: #FFFFFF;">                            choice = find(ties);</span><br/>               <span style="color: #A0A0A0"> 615</span> <span style="color: #A0A0A0; background: #FFFFFF;">                            tb = randsample(numTies,1);</span><br/>               <span style="color: #A0A0A0"> 616</span> <span style="color: #A0A0A0; background: #FFFFFF;">                            label(notNanRows(i)) = choice(tb);</span><br/>               <span style="color: #A0A0A0"> 617</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        end</span><br/>               <span style="color: #A0A0A0"> 618</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    end</span><br/>               <span style="color: #A0A0A0"> 619</span> <span style="color: #228B22; background: #FFFFFF;">                else % BreakTies is 'nearest'</span><br/>               <span style="color: #A0A0A0"> 620</span> <span style="color: #228B22; background: #FFFFFF;">                    </span><br/>               <span style="color: #A0A0A0"> 621</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    if ~this.IncludeTies  %this.IncludeTies is false</span><br/>               <span style="color: #A0A0A0"> 622</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        CNeighbor = gindex(CIDX);</span><br/>               <span style="color: #A0A0A0"> 623</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        for i =1:numel(notNanRows)</span><br/>               <span style="color: #A0A0A0"> 624</span> <span style="color: #A0A0A0; background: #FFFFFF;">                            ties = cost(notNanRows(i),:) == minCost(notNanRows(i));</span><br/>               <span style="color: #A0A0A0"> 625</span> <span style="color: #A0A0A0; background: #FFFFFF;">                            numTies = sum(ties);</span><br/>               <span style="color: #A0A0A0"> 626</span> <span style="color: #A0A0A0; background: #FFFFFF;">                            if  numTies &gt; 1 % there existed ties</span><br/>               <span style="color: #A0A0A0"> 627</span> <span style="color: #A0A0A0; background: #FFFFFF;">                                choice = find(ties);</span><br/>               <span style="color: #A0A0A0"> 628</span> <span style="color: #A0A0A0; background: #FFFFFF;">                                for inner = 1:this.NumNeighbors</span><br/>               <span style="color: #A0A0A0"> 629</span> <span style="color: #A0A0A0; background: #FFFFFF;">                                    if ismember(CNeighbor(notNanRows(i),inner),choice)</span><br/>               <span style="color: #A0A0A0"> 630</span> <span style="color: #A0A0A0; background: #FFFFFF;">                                        label(notNanRows(i)) = CNeighbor(notNanRows(i),inner);</span><br/>               <span style="color: #A0A0A0"> 631</span> <span style="color: #A0A0A0; background: #FFFFFF;">                                        break</span><br/>               <span style="color: #A0A0A0"> 632</span> <span style="color: #228B22; background: #FFFFFF;">                                        </span><br/>               <span style="color: #A0A0A0"> 633</span> <span style="color: #A0A0A0; background: #FFFFFF;">                                    end</span><br/>               <span style="color: #A0A0A0"> 634</span> <span style="color: #A0A0A0; background: #FFFFFF;">                                end</span><br/>               <span style="color: #A0A0A0"> 635</span> <span style="color: #A0A0A0; background: #FFFFFF;">                            end</span><br/>               <span style="color: #A0A0A0"> 636</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        end %</span><br/>               <span style="color: #A0A0A0"> 637</span> <span style="color: #228B22; background: #FFFFFF;">                    else %this.IncludeTies is true</span><br/>               <span style="color: #A0A0A0"> 638</span> <span style="color: #228B22; background: #FFFFFF;">                        </span><br/>               <span style="color: #A0A0A0"> 639</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        for i =1:numel(notNanRows)</span><br/>               <span style="color: #A0A0A0"> 640</span> <span style="color: #A0A0A0; background: #FFFFFF;">                            ties = cost(notNanRows(i),:) == minCost(notNanRows(i));</span><br/>               <span style="color: #A0A0A0"> 641</span> <span style="color: #A0A0A0; background: #FFFFFF;">                            numTies = sum(ties);</span><br/>               <span style="color: #A0A0A0"> 642</span> <span style="color: #A0A0A0; background: #FFFFFF;">                            if  numTies &gt; 1 % there existed ties</span><br/>               <span style="color: #A0A0A0"> 643</span> <span style="color: #A0A0A0; background: #FFFFFF;">                                choice = find(ties);</span><br/>               <span style="color: #A0A0A0"> 644</span> <span style="color: #A0A0A0; background: #FFFFFF;">                                for inner = 1:this.NumNeighbors</span><br/>               <span style="color: #A0A0A0"> 645</span> <span style="color: #A0A0A0; background: #FFFFFF;">                                    tempCNeighbor =gindex(CIDX{notNanRows(i)});</span><br/>               <span style="color: #A0A0A0"> 646</span> <span style="color: #A0A0A0; background: #FFFFFF;">                                    if ismember(tempCNeighbor(inner),choice)</span><br/>               <span style="color: #A0A0A0"> 647</span> <span style="color: #A0A0A0; background: #FFFFFF;">                                        label(notNanRows(i)) = tempCNeighbor(inner);</span><br/>               <span style="color: #A0A0A0"> 648</span> <span style="color: #A0A0A0; background: #FFFFFF;">                                        break</span><br/>               <span style="color: #A0A0A0"> 649</span> <span style="color: #228B22; background: #FFFFFF;">                                        </span><br/>               <span style="color: #A0A0A0"> 650</span> <span style="color: #A0A0A0; background: #FFFFFF;">                                    end</span><br/>               <span style="color: #A0A0A0"> 651</span> <span style="color: #A0A0A0; background: #FFFFFF;">                                end</span><br/>               <span style="color: #A0A0A0"> 652</span> <span style="color: #A0A0A0; background: #FFFFFF;">                            end</span><br/>               <span style="color: #A0A0A0"> 653</span> <span style="color: #A0A0A0; background: #FFFFFF;">                        end %if i==1</span><br/>               <span style="color: #A0A0A0"> 654</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    end</span><br/>               <span style="color: #A0A0A0"> 655</span> <span style="color: #A0A0A0; background: #FFFFFF;">                end</span><br/>               <span style="color: #A0A0A0"> 656</span> <span style="color: #A0A0A0; background: #FFFFFF;">            end</span><br/>               <span style="color: #A0A0A0"> 657</span> <span style="color: #A0A0A0; background: #FFFFFF;">        end %~isempty(i)</span><br/>               <span style="color: #A0A0A0"> 658</span> <span style="color: #228B22; background: #FFFFFF;">                           </span><br/>               <span style="color: #A0A0A0"> 659</span> <span style="color: #A0A0A0; background: #FFFFFF;">    end</span><br/>               <span style="color: #A0A0A0"> 660</span> <span style="color: #228B22; background: #FFFFFF;">    </span><br/>               <span style="color: #A0A0A0"> 661</span> <span style="color: #A0A0A0; background: #FFFFFF;">    methods(Hidden)</span><br/>               <span style="color: #A0A0A0"> 662</span> <span style="color: #228B22; background: #FFFFFF;">        %constructor</span><br/>               <span style="color: #A0A0A0"> 663</span> <span style="color: #A0A0A0; background: #FFFFFF;">        function this = ClassificationKNN(X,Y,W,modelParams,...</span><br/>               <span style="color: #A0A0A0"> 664</span> <span style="color: #A0A0A0; background: #FFFFFF;">                dataSummary,classSummary,scoreTransform)</span><br/>               <span style="color: #A0A0A0"> 665</span> <span style="color: #228B22; background: #FFFFFF;">            % Protect against being called by the user</span><br/>               <span style="color: #A0A0A0"> 666</span> <span style="color: #A0A0A0; background: #FFFFFF;">            if nargin~=7 || ischar(W)</span><br/>               <span style="color: #A0A0A0"> 667</span> <span style="color: #A0A0A0; background: #FFFFFF;">                error(message('stats:ClassificationKNN:ClassificationKNN:DoNotUseConstructor'));</span><br/>               <span style="color: #A0A0A0"> 668</span> <span style="color: #A0A0A0; background: #FFFFFF;">            end</span><br/>               <span style="color: #A0A0A0"> 669</span> <span style="color: #228B22; background: #FFFFFF;">            </span><br/>               <span style="color: #A0A0A0"> 670</span> <span style="color: #A0A0A0; background: #FFFFFF;">            [nx,nDims] = size(X);</span><br/>               <span style="color: #A0A0A0"> 671</span> <span style="color: #A0A0A0; background: #FFFFFF;">            if (modelParams.NumNeighbors &gt; nx)</span><br/>               <span style="color: #A0A0A0"> 672</span> <span style="color: #A0A0A0; background: #FFFFFF;">                modelParams.NumNeighbors = nx;</span><br/>               <span style="color: #A0A0A0"> 673</span> <span style="color: #A0A0A0; background: #FFFFFF;">            end          </span><br/>               <span style="color: #A0A0A0"> 674</span> <span style="color: #A0A0A0; background: #FFFFFF;">            if ~ (isempty(dataSummary.CategoricalPredictors) || ...</span><br/>               <span style="color: #A0A0A0"> 675</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    (length(dataSummary.CategoricalPredictors) == nDims ...</span><br/>               <span style="color: #A0A0A0"> 676</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    &amp;&amp; all(dataSummary.CategoricalPredictors==(1: nDims))))</span><br/>               <span style="color: #A0A0A0"> 677</span> <span style="color: #A0A0A0; background: #FFFFFF;">                error(message('stats:ClassificationKNN:ClassificationKNN:BadCategoricalPre')); </span><br/>               <span style="color: #A0A0A0"> 678</span> <span style="color: #A0A0A0; background: #FFFFFF;">            end</span><br/>               <span style="color: #A0A0A0"> 679</span> <span style="color: #228B22; background: #FFFFFF;">            </span><br/>               <span style="color: #A0A0A0"> 680</span> <span style="color: #228B22; background: #FFFFFF;">            % Base constructor</span><br/>               <span style="color: #A0A0A0"> 681</span> <span style="color: #A0A0A0; background: #FFFFFF;">            this =this@classreg.learning.classif.FullClassificationModel(...</span><br/>               <span style="color: #A0A0A0"> 682</span> <span style="color: #A0A0A0; background: #FFFFFF;">                X,Y,W,modelParams,dataSummary,classSummary,scoreTransform);</span><br/>               <span style="color: #A0A0A0"> 683</span> <span style="color: #228B22; background: #FFFFFF;">            %we don't have class CompactClassificationDiscriminant</span><br/>               <span style="color: #A0A0A0"> 684</span> <span style="color: #228B22; background: #FFFFFF;">            %             this = this@classreg.learning.classif.CompactClassificationDiscriminant(...</span><br/>               <span style="color: #A0A0A0"> 685</span> <span style="color: #228B22; background: #FFFFFF;">            %                 dataSummary,classSummary,scoreTransform,[]);</span><br/>               <span style="color: #A0A0A0"> 686</span> <span style="color: #228B22; background: #FFFFFF;">            %this.LabelPredictor = @classreg.learning.classif.ClassificationModel.minCost;</span><br/>               <span style="color: #A0A0A0"> 687</span> <span style="color: #228B22; background: #FFFFFF;">            %Train the model on this.X, this.Y</span><br/>               <span style="color: #A0A0A0"> 688</span> <span style="color: #228B22; background: #FFFFFF;">           </span><br/>               <span style="color: #A0A0A0"> 689</span> <span style="color: #A0A0A0; background: #FFFFFF;">            nsmethod= this.ModelParams.NSMethod;</span><br/>               <span style="color: #A0A0A0"> 690</span> <span style="color: #A0A0A0; background: #FFFFFF;">            distance = this.ModelParams.Distance;</span><br/>               <span style="color: #A0A0A0"> 691</span> <span style="color: #A0A0A0; background: #FFFFFF;">            p = this.ModelParams.Exponent;</span><br/>               <span style="color: #A0A0A0"> 692</span> <span style="color: #A0A0A0; background: #FFFFFF;">            cov = this.ModelParams.Cov;</span><br/>               <span style="color: #A0A0A0"> 693</span> <span style="color: #A0A0A0; background: #FFFFFF;">            scale = this.ModelParams.Scale;</span><br/>               <span style="color: #A0A0A0"> 694</span> <span style="color: #A0A0A0; background: #FFFFFF;">            bucket = this.ModelParams.BucketSize;</span><br/>               <span style="color: #A0A0A0"> 695</span> <span style="color: #A0A0A0; background: #FFFFFF;">            if strncmpi(nsmethod,'kdtree',length(nsmethod))</span><br/>               <span style="color: #A0A0A0"> 696</span> <span style="color: #A0A0A0; background: #FFFFFF;">                this.NS = KDTreeSearcher(this.PrivX, ...</span><br/>               <span style="color: #A0A0A0"> 697</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    'distance',distance, 'p',p,'BucketSize',bucket);</span><br/>               <span style="color: #A0A0A0"> 698</span> <span style="color: #A0A0A0; background: #FFFFFF;">                this.ModelParams.NSMethod = 'kdtree';</span><br/>               <span style="color: #A0A0A0"> 699</span> <span style="color: #A0A0A0; background: #FFFFFF;">                this.ModelParams.Scale = [];</span><br/>               <span style="color: #A0A0A0"> 700</span> <span style="color: #A0A0A0; background: #FFFFFF;">                this.ModelParams.Cov = [];</span><br/>               <span style="color: #A0A0A0"> 701</span> <span style="color: #A0A0A0; background: #FFFFFF;">                this.ModelParams.Exponent = this.NS.DistParameter;</span><br/>               <span style="color: #A0A0A0"> 702</span> <span style="color: #228B22; background: #FFFFFF;">            else</span><br/>               <span style="color: #A0A0A0"> 703</span> <span style="color: #228B22; background: #FFFFFF;">                %checkNegativeDistance is set to true to disallow negative distance</span><br/>               <span style="color: #A0A0A0"> 704</span> <span style="color: #228B22; background: #FFFFFF;">                %values.</span><br/>               <span style="color: #A0A0A0"> 705</span> <span style="color: #A0A0A0; background: #FFFFFF;">                this.NS = ExhaustiveSearcher(this.PrivX,...</span><br/>               <span style="color: #A0A0A0"> 706</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    'distance',distance, 'p',p,'cov',cov,...</span><br/>               <span style="color: #A0A0A0"> 707</span> <span style="color: #A0A0A0; background: #FFFFFF;">                    'scale',scale,'checkNegativeDistance',true);</span><br/>               <span style="color: #A0A0A0"> 708</span> <span style="color: #A0A0A0; background: #FFFFFF;">                this.ModelParams.NSMethod = 'exhaustive';</span><br/>               <span style="color: #A0A0A0"> 709</span> <span style="color: #A0A0A0; background: #FFFFFF;">                this.ModelParams.BucketSize = [];</span><br/>               <span style="color: #A0A0A0"> 710</span> <span style="color: #A0A0A0; background: #FFFFFF;">            end</span><br/>               <span style="color: #A0A0A0"> 711</span> <span style="color: #228B22; background: #FFFFFF;">            </span><br/>               <span style="color: #A0A0A0"> 712</span> <span style="color: #228B22; background: #FFFFFF;">            % Clear X property to free memory</span><br/>               <span style="color: #A0A0A0"> 713</span> <span style="color: #A0A0A0; background: #FFFFFF;">            this.PrivX = [];</span><br/>               <span style="color: #A0A0A0"> 714</span> <span style="color: #228B22; background: #FFFFFF;">            </span><br/>               <span style="color: #A0A0A0"> 715</span> <span style="color: #A0A0A0; background: #FFFFFF;">            this.ModelParams.Distance = this.NS.Distance;</span><br/>               <span style="color: #A0A0A0"> 716</span> <span style="color: #228B22; background: #FFFFFF;">            </span><br/>               <span style="color: #A0A0A0"> 717</span> <span style="color: #228B22; background: #FFFFFF;">            %saves the observation weights that comes from the input,</span><br/>               <span style="color: #A0A0A0"> 718</span> <span style="color: #228B22; background: #FFFFFF;">            %This PrivW is not normalized to be consistent with class priors.</span><br/>               <span style="color: #A0A0A0"> 719</span> <span style="color: #228B22; background: #FFFFFF;">            %This is to prevent losing some observation weights when some class</span><br/>               <span style="color: #A0A0A0"> 720</span> <span style="color: #228B22; background: #FFFFFF;">            %priors are setting to zero.</span><br/>               <span style="color: #A0A0A0"> 721</span> <span style="color: #A0A0A0; background: #FFFFFF;">            this.PrivW = this.W; </span><br/>               <span style="color: #A0A0A0"> 722</span> <span style="color: #228B22; background: #FFFFFF;"></span><br/>               <span style="color: #A0A0A0"> 723</span> <span style="color: #A0A0A0; background: #FFFFFF;">        end</span><br/>               <span style="color: #A0A0A0"> 724</span> <span style="color: #228B22; background: #FFFFFF;">        </span><br/>               <span style="color: #A0A0A0"> 725</span> <span style="color: #A0A0A0; background: #FFFFFF;">    end</span><br/>               <span style="color: #A0A0A0"> 726</span> <span style="color: #228B22; background: #FFFFFF;">    </span><br/>               <span style="color: #A0A0A0"> 727</span> <span style="color: #A0A0A0; background: #FFFFFF;">    methods(Static)</span><br/>               <span style="color: #A0A0A0"> 728</span> <span style="color: #A0A0A0; background: #FFFFFF;">        function this = fit(X,Y,varargin)</span><br/>               <span style="color: #A0A0A0"> 729</span> <span style="color: #228B22; background: #FFFFFF;">% FIT fit KNN classification model</span><br/>               <span style="color: #A0A0A0"> 730</span> <span style="color: #228B22; background: #FFFFFF;">%   KNN = CLASSIFICATIONKNN.FIT(X,Y) returns a KNN classification  model</span><br/>               <span style="color: #A0A0A0"> 731</span> <span style="color: #228B22; background: #FFFFFF;">%   for predictors X and class labels Y.</span><br/>               <span style="color: #A0A0A0"> 732</span> <span style="color: #228B22; background: #FFFFFF;">%</span><br/>               <span style="color: #A0A0A0"> 733</span> <span style="color: #228B22; background: #FFFFFF;">% X must be an N-by-P matrix of predictors with one row per observation and</span><br/>               <span style="color: #A0A0A0"> 734</span> <span style="color: #228B22; background: #FFFFFF;">% one column per predictor. Y must be an array of N class labels. Y can be</span><br/>               <span style="color: #A0A0A0"> 735</span> <span style="color: #228B22; background: #FFFFFF;">% a categorical array (nominal or ordinal), character array, logical</span><br/>               <span style="color: #A0A0A0"> 736</span> <span style="color: #228B22; background: #FFFFFF;">% vector, numeric vector, or cell array of strings. If Y is a character</span><br/>               <span style="color: #A0A0A0"> 737</span> <span style="color: #228B22; background: #FFFFFF;">% array, it must have one class label per row.</span><br/>               <span style="color: #A0A0A0"> 738</span> <span style="color: #228B22; background: #FFFFFF;">%</span><br/>               <span style="color: #A0A0A0"> 739</span> <span style="color: #228B22; background: #FFFFFF;">% KNN is a KNN classification model. If you use one of the following five</span><br/>               <span style="color: #A0A0A0"> 740</span> <span style="color: #228B22; background: #FFFFFF;">% options, KNN is of class ClassificationPartitionedModel: 'crossval',</span><br/>               <span style="color: #A0A0A0"> 741</span> <span style="color: #228B22; background: #FFFFFF;">% 'kfold', 'holdout', 'leaveout' or 'cvpartition'. Otherwise, KNN is of</span><br/>               <span style="color: #A0A0A0"> 742</span> <span style="color: #228B22; background: #FFFFFF;">% class ClassificationKNN.</span><br/>               <span style="color: #A0A0A0"> 743</span> <span style="color: #228B22; background: #FFFFFF;">%</span><br/>               <span style="color: #A0A0A0"> 744</span> <span style="color: #228B22; background: #FFFFFF;">%   KNN=CLASSIFICATIONKNN.FIT(X,Y,'PARAM1',val1,'PARAM2',val2,...)</span><br/>               <span style="color: #A0A0A0"> 745</span> <span style="color: #228B22; background: #FFFFFF;">%   specifies optional parameter name/value pairs:</span><br/>               <span style="color: #A0A0A0"> 746</span> <span style="color: #228B22; background: #FFFFFF;">%       'CategoricalPredictors' - List of categorical predictors. Pass</span><br/>               <span style="color: #A0A0A0"> 747</span> <span style="color: #228B22; background: #FFFFFF;">%                                 'CategoricalPredictors' as [] or 'all'.</span><br/>               <span style="color: #A0A0A0"> 748</span> <span style="color: #228B22; background: #FFFFFF;">%                                 Use [] to indicate none of predictors are</span><br/>               <span style="color: #A0A0A0"> 749</span> <span style="color: #228B22; background: #FFFFFF;">%                                 categorical. Use 'all' to indicate all</span><br/>               <span style="color: #A0A0A0"> 750</span> <span style="color: #228B22; background: #FFFFFF;">%                                 the predictors are categorical.</span><br/>               <span style="color: #A0A0A0"> 751</span> <span style="color: #228B22; background: #FFFFFF;">%                                 Default: []</span><br/>               <span style="color: #A0A0A0"> 752</span> <span style="color: #228B22; background: #FFFFFF;">%       'ClassNames'            - Array of class names. Use the</span><br/>               <span style="color: #A0A0A0"> 753</span> <span style="color: #228B22; background: #FFFFFF;">%                                 data type that exists in Y. You can use</span><br/>               <span style="color: #A0A0A0"> 754</span> <span style="color: #228B22; background: #FFFFFF;">%                                 this argument to order the classes or</span><br/>               <span style="color: #A0A0A0"> 755</span> <span style="color: #228B22; background: #FFFFFF;">%                                 select a subset of classes for training.</span><br/>               <span style="color: #A0A0A0"> 756</span> <span style="color: #228B22; background: #FFFFFF;">%                                 Default: The class names that exist in Y.</span><br/>               <span style="color: #A0A0A0"> 757</span> <span style="color: #228B22; background: #FFFFFF;">%       'Cost'                  - Square matrix, where COST(I,J) is the</span><br/>               <span style="color: #A0A0A0"> 758</span> <span style="color: #228B22; background: #FFFFFF;">%                                 cost of classifying a point into class J</span><br/>               <span style="color: #A0A0A0"> 759</span> <span style="color: #228B22; background: #FFFFFF;">%                                 if its true class is I.</span><br/>               <span style="color: #A0A0A0"> 760</span> <span style="color: #228B22; background: #FFFFFF;">%                                 Alternatively, COST can be a structure S</span><br/>               <span style="color: #A0A0A0"> 761</span> <span style="color: #228B22; background: #FFFFFF;">%                                 having two fields: S.ClassificationCosts</span><br/>               <span style="color: #A0A0A0"> 762</span> <span style="color: #228B22; background: #FFFFFF;">%                                 containing the cost matrix C, and</span><br/>               <span style="color: #A0A0A0"> 763</span> <span style="color: #228B22; background: #FFFFFF;">%                                 S.ClassNames containing the class names</span><br/>               <span style="color: #A0A0A0"> 764</span> <span style="color: #228B22; background: #FFFFFF;">%                                 and defining the ordering of classes used</span><br/>               <span style="color: #A0A0A0"> 765</span> <span style="color: #228B22; background: #FFFFFF;">%                                 for the rows and columns of the cost</span><br/>               <span style="color: #A0A0A0"> 766</span> <span style="color: #228B22; background: #FFFFFF;">%                                 matrix. For S.ClassNames use the data</span><br/>               <span style="color: #A0A0A0"> 767</span> <span style="color: #228B22; background: #FFFFFF;">%                                 type that exists in Y. As an alternative,</span><br/>               <span style="color: #A0A0A0"> 768</span> <span style="color: #228B22; background: #FFFFFF;">%                                 you can assign to the Cost property of</span><br/>               <span style="color: #A0A0A0"> 769</span> <span style="color: #228B22; background: #FFFFFF;">%                                 KNN. Default: COST(I,J)=1 if I~=J, and</span><br/>               <span style="color: #A0A0A0"> 770</span> <span style="color: #228B22; background: #FFFFFF;">%                                 COST(I,J)=0 if I=J.</span><br/>               <span style="color: #A0A0A0"> 771</span> <span style="color: #228B22; background: #FFFFFF;">%       'CrossVal'              - If 'on', creates a cross-validated KNN</span><br/>               <span style="color: #A0A0A0"> 772</span> <span style="color: #228B22; background: #FFFFFF;">%                                 with 10 folds. You can use 'kfold',</span><br/>               <span style="color: #A0A0A0"> 773</span> <span style="color: #228B22; background: #FFFFFF;">%                                 'holdout', 'leaveout' and 'cvpartition'</span><br/>               <span style="color: #A0A0A0"> 774</span> <span style="color: #228B22; background: #FFFFFF;">%                                 parameters to override this</span><br/>               <span style="color: #A0A0A0"> 775</span> <span style="color: #228B22; background: #FFFFFF;">%                                 cross-validation setting. You can only</span><br/>               <span style="color: #A0A0A0"> 776</span> <span style="color: #228B22; background: #FFFFFF;">%                                 use one of these four options ('kfold',</span><br/>               <span style="color: #A0A0A0"> 777</span> <span style="color: #228B22; background: #FFFFFF;">%                                 'holdout', 'leaveout' and 'cvpartition')</span><br/>               <span style="color: #A0A0A0"> 778</span> <span style="color: #228B22; background: #FFFFFF;">%                                 at a time when creating a cross-validated</span><br/>               <span style="color: #A0A0A0"> 779</span> <span style="color: #228B22; background: #FFFFFF;">%                                 model. As an alternative, you can</span><br/>               <span style="color: #A0A0A0"> 780</span> <span style="color: #228B22; background: #FFFFFF;">%                                 cross-validate later using CROSSVAL</span><br/>               <span style="color: #A0A0A0"> 781</span> <span style="color: #228B22; background: #FFFFFF;">%                                 method for ClassificationKNN. Default:</span><br/>               <span style="color: #A0A0A0"> 782</span> <span style="color: #228B22; background: #FFFFFF;">%                                 'off'</span><br/>               <span style="color: #A0A0A0"> 783</span> <span style="color: #228B22; background: #FFFFFF;">%       'CVPartition'           - A partition created with  CVPARTITION to</span><br/>               <span style="color: #A0A0A0"> 784</span> <span style="color: #228B22; background: #FFFFFF;">%                                 use in cross-validated KNN model.</span><br/>               <span style="color: #A0A0A0"> 785</span> <span style="color: #228B22; background: #FFFFFF;">%       'Holdout'               - Holdout validation uses the specified</span><br/>               <span style="color: #A0A0A0"> 786</span> <span style="color: #228B22; background: #FFFFFF;">%                                 fraction of the data for test, and uses</span><br/>               <span style="color: #A0A0A0"> 787</span> <span style="color: #228B22; background: #FFFFFF;">%                                 the rest of the data for training.</span><br/>               <span style="color: #A0A0A0"> 788</span> <span style="color: #228B22; background: #FFFFFF;">%                                 Specify a numeric scalar between 0 and 1.</span><br/>               <span style="color: #A0A0A0"> 789</span> <span style="color: #228B22; background: #FFFFFF;">%       'KFold'                 - Number of folds to use in cross-validated</span><br/>               <span style="color: #A0A0A0"> 790</span> <span style="color: #228B22; background: #FFFFFF;">%                                 KNN classification model, a positive</span><br/>               <span style="color: #A0A0A0"> 791</span> <span style="color: #228B22; background: #FFFFFF;">%                                 integer. Default: 10</span><br/>               <span style="color: #A0A0A0"> 792</span> <span style="color: #228B22; background: #FFFFFF;">%       'Leaveout'              - Use leave-one-out cross-validation by</span><br/>               <span style="color: #A0A0A0"> 793</span> <span style="color: #228B22; background: #FFFFFF;">%                                 setting to 'on'.</span><br/>               <span style="color: #A0A0A0"> 794</span> <span style="color: #228B22; background: #FFFFFF;">%       'Prior'                 - Prior probabilities for each class.</span><br/>               <span style="color: #A0A0A0"> 795</span> <span style="color: #228B22; background: #FFFFFF;">%                                 Specify as one of:</span><br/>               <span style="color: #A0A0A0"> 796</span> <span style="color: #228B22; background: #FFFFFF;">%                                   * A string:</span><br/>               <span style="color: #A0A0A0"> 797</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - 'empirical' determines class</span><br/>               <span style="color: #A0A0A0"> 798</span> <span style="color: #228B22; background: #FFFFFF;">%                                       probabilities from class</span><br/>               <span style="color: #A0A0A0"> 799</span> <span style="color: #228B22; background: #FFFFFF;">%                                       frequencies in Y</span><br/>               <span style="color: #A0A0A0"> 800</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - 'uniform' sets all class</span><br/>               <span style="color: #A0A0A0"> 801</span> <span style="color: #228B22; background: #FFFFFF;">%                                       probabilities equal</span><br/>               <span style="color: #A0A0A0"> 802</span> <span style="color: #228B22; background: #FFFFFF;">%                                   * A vector (one scalar value for each</span><br/>               <span style="color: #A0A0A0"> 803</span> <span style="color: #228B22; background: #FFFFFF;">%                                     class)</span><br/>               <span style="color: #A0A0A0"> 804</span> <span style="color: #228B22; background: #FFFFFF;">%                                   * A structure S with two fields:</span><br/>               <span style="color: #A0A0A0"> 805</span> <span style="color: #228B22; background: #FFFFFF;">%                                     S.ClassProbs containing a vector of</span><br/>               <span style="color: #A0A0A0"> 806</span> <span style="color: #228B22; background: #FFFFFF;">%                                     class probabilities, and S.ClassNames</span><br/>               <span style="color: #A0A0A0"> 807</span> <span style="color: #228B22; background: #FFFFFF;">%                                     containing the class names and</span><br/>               <span style="color: #A0A0A0"> 808</span> <span style="color: #228B22; background: #FFFFFF;">%                                     defining the ordering of classes used</span><br/>               <span style="color: #A0A0A0"> 809</span> <span style="color: #228B22; background: #FFFFFF;">%                                     for the elements of this vector.</span><br/>               <span style="color: #A0A0A0"> 810</span> <span style="color: #228B22; background: #FFFFFF;">%                                 If you pass numeric values,</span><br/>               <span style="color: #A0A0A0"> 811</span> <span style="color: #228B22; background: #FFFFFF;">%                                 ClassificationKNN.fit normalizes</span><br/>               <span style="color: #A0A0A0"> 812</span> <span style="color: #228B22; background: #FFFFFF;">%                                 them to add up to one. As an</span><br/>               <span style="color: #A0A0A0"> 813</span> <span style="color: #228B22; background: #FFFFFF;">%                                 alternative, you can assign to</span><br/>               <span style="color: #A0A0A0"> 814</span> <span style="color: #228B22; background: #FFFFFF;">%                                 the Prior property. Default:</span><br/>               <span style="color: #A0A0A0"> 815</span> <span style="color: #228B22; background: #FFFFFF;">%                                 'empirical'</span><br/>               <span style="color: #A0A0A0"> 816</span> <span style="color: #228B22; background: #FFFFFF;">%       'ResponseName'          - Name of the response variable Y, a</span><br/>               <span style="color: #A0A0A0"> 817</span> <span style="color: #228B22; background: #FFFFFF;">%                                 string. Default: 'Y'</span><br/>               <span style="color: #A0A0A0"> 818</span> <span style="color: #228B22; background: #FFFFFF;">%       'ScoreTransform'        - Function handle for transforming scores,</span><br/>               <span style="color: #A0A0A0"> 819</span> <span style="color: #228B22; background: #FFFFFF;">%                                 or string representing a built-in</span><br/>               <span style="color: #A0A0A0"> 820</span> <span style="color: #228B22; background: #FFFFFF;">%                                 transformation function. Available</span><br/>               <span style="color: #A0A0A0"> 821</span> <span style="color: #228B22; background: #FFFFFF;">%                                 functions: 'symmetric', 'invlogit',</span><br/>               <span style="color: #A0A0A0"> 822</span> <span style="color: #228B22; background: #FFFFFF;">%                                 'ismax', 'symmetricismax', 'none',</span><br/>               <span style="color: #A0A0A0"> 823</span> <span style="color: #228B22; background: #FFFFFF;">%                                 'logit', 'doublelogit', 'symmetriclogit',</span><br/>               <span style="color: #A0A0A0"> 824</span> <span style="color: #228B22; background: #FFFFFF;">%                                 and 'sign'.</span><br/>               <span style="color: #A0A0A0"> 825</span> <span style="color: #228B22; background: #FFFFFF;">%                                 Default: 'none'</span><br/>               <span style="color: #A0A0A0"> 826</span> <span style="color: #228B22; background: #FFFFFF;">%       'Weights'               - Vector of observation weights, one weight</span><br/>               <span style="color: #A0A0A0"> 827</span> <span style="color: #228B22; background: #FFFFFF;">%                                 per observation. Default:</span><br/>               <span style="color: #A0A0A0"> 828</span> <span style="color: #228B22; background: #FFFFFF;">%                                 ones(size(X,1),1)</span><br/>               <span style="color: #A0A0A0"> 829</span> <span style="color: #228B22; background: #FFFFFF;">%       'NumNeighbors'          - A positive integer specifying the number</span><br/>               <span style="color: #A0A0A0"> 830</span> <span style="color: #228B22; background: #FFFFFF;">%                                 of nearest neighbors in X for classifying</span><br/>               <span style="color: #A0A0A0"> 831</span> <span style="color: #228B22; background: #FFFFFF;">%                                 each point when predicting. Default: 1.</span><br/>               <span style="color: #A0A0A0"> 832</span> <span style="color: #228B22; background: #FFFFFF;">%       'NSMethod'              - Nearest neighbors search method.</span><br/>               <span style="color: #A0A0A0"> 833</span> <span style="color: #228B22; background: #FFFFFF;">%                                 Value is either:</span><br/>               <span style="color: #A0A0A0"> 834</span> <span style="color: #228B22; background: #FFFFFF;">%                                   - 'kdtree' uses a kd-tree to find</span><br/>               <span style="color: #A0A0A0"> 835</span> <span style="color: #228B22; background: #FFFFFF;">%                                     nearest neighbors. 'kdtree' is only</span><br/>               <span style="color: #A0A0A0"> 836</span> <span style="color: #228B22; background: #FFFFFF;">%                                     valid when the distance metric</span><br/>               <span style="color: #A0A0A0"> 837</span> <span style="color: #228B22; background: #FFFFFF;">%                                     is one of the following metrics:</span><br/>               <span style="color: #A0A0A0"> 838</span> <span style="color: #228B22; background: #FFFFFF;">%                                       - 'euclidean'</span><br/>               <span style="color: #A0A0A0"> 839</span> <span style="color: #228B22; background: #FFFFFF;">%                                       - 'cityblock'</span><br/>               <span style="color: #A0A0A0"> 840</span> <span style="color: #228B22; background: #FFFFFF;">%                                       - 'minkowski'</span><br/>               <span style="color: #A0A0A0"> 841</span> <span style="color: #228B22; background: #FFFFFF;">%                                       - 'chebyshev'</span><br/>               <span style="color: #A0A0A0"> 842</span> <span style="color: #228B22; background: #FFFFFF;">%                                   - 'exhaustive' uses the exhaustive</span><br/>               <span style="color: #A0A0A0"> 843</span> <span style="color: #228B22; background: #FFFFFF;">%                                     search algorithm. The distance values</span><br/>               <span style="color: #A0A0A0"> 844</span> <span style="color: #228B22; background: #FFFFFF;">%                                     from all the points in X to each</span><br/>               <span style="color: #A0A0A0"> 845</span> <span style="color: #228B22; background: #FFFFFF;">%                                     point in Y are computed to find</span><br/>               <span style="color: #A0A0A0"> 846</span> <span style="color: #228B22; background: #FFFFFF;">%                                     nearest neighbors.</span><br/>               <span style="color: #A0A0A0"> 847</span> <span style="color: #228B22; background: #FFFFFF;">%                                   Default is 'kdtree' when the number of</span><br/>               <span style="color: #A0A0A0"> 848</span> <span style="color: #228B22; background: #FFFFFF;">%                                   columns of X is not greater  than 10, X</span><br/>               <span style="color: #A0A0A0"> 849</span> <span style="color: #228B22; background: #FFFFFF;">%                                   is not sparse, and the distance metric</span><br/>               <span style="color: #A0A0A0"> 850</span> <span style="color: #228B22; background: #FFFFFF;">%                                   is one of the above 4 metrics;</span><br/>               <span style="color: #A0A0A0"> 851</span> <span style="color: #228B22; background: #FFFFFF;">%                                   otherwise, default is 'exhaustive'.</span><br/>               <span style="color: #A0A0A0"> 852</span> <span style="color: #228B22; background: #FFFFFF;">%       'IncludeTies'           - A logical value. Use true to include all</span><br/>               <span style="color: #A0A0A0"> 853</span> <span style="color: #228B22; background: #FFFFFF;">%                                 neighbors whose distance equal the Kth</span><br/>               <span style="color: #A0A0A0"> 854</span> <span style="color: #228B22; background: #FFFFFF;">%                                 smallest distance. Use false to include</span><br/>               <span style="color: #A0A0A0"> 855</span> <span style="color: #228B22; background: #FFFFFF;">%                                 exactly K nearest neighbors.</span><br/>               <span style="color: #A0A0A0"> 856</span> <span style="color: #228B22; background: #FFFFFF;">%       'DistanceWeight'        - A string or a function handle specifying</span><br/>               <span style="color: #A0A0A0"> 857</span> <span style="color: #228B22; background: #FFFFFF;">%                                 the distance weighting function. The</span><br/>               <span style="color: #A0A0A0"> 858</span> <span style="color: #228B22; background: #FFFFFF;">%                                 choices of the string are:</span><br/>               <span style="color: #A0A0A0"> 859</span> <span style="color: #228B22; background: #FFFFFF;">%                                   - 'equal': Each neighbor gets equal</span><br/>               <span style="color: #A0A0A0"> 860</span> <span style="color: #228B22; background: #FFFFFF;">%                                      weight (default).</span><br/>               <span style="color: #A0A0A0"> 861</span> <span style="color: #228B22; background: #FFFFFF;">%                                   - 'inverse': Each neighbor gets weight</span><br/>               <span style="color: #A0A0A0"> 862</span> <span style="color: #228B22; background: #FFFFFF;">%                                      1/d, where d is the distance between</span><br/>               <span style="color: #A0A0A0"> 863</span> <span style="color: #228B22; background: #FFFFFF;">%                                      this neighbor and the point being</span><br/>               <span style="color: #A0A0A0"> 864</span> <span style="color: #228B22; background: #FFFFFF;">%                                      classified.</span><br/>               <span style="color: #A0A0A0"> 865</span> <span style="color: #228B22; background: #FFFFFF;">%                                   - 'squaredinverse': Each neighbor gets</span><br/>               <span style="color: #A0A0A0"> 866</span> <span style="color: #228B22; background: #FFFFFF;">%                                     weight 1/d^2, where d is the distance</span><br/>               <span style="color: #A0A0A0"> 867</span> <span style="color: #228B22; background: #FFFFFF;">%                                     between this neighbor and the point</span><br/>               <span style="color: #A0A0A0"> 868</span> <span style="color: #228B22; background: #FFFFFF;">%                                     being classified.</span><br/>               <span style="color: #A0A0A0"> 869</span> <span style="color: #228B22; background: #FFFFFF;">%                                   - A distance weighting function</span><br/>               <span style="color: #A0A0A0"> 870</span> <span style="color: #228B22; background: #FFFFFF;">%                                     specified using @. A distance</span><br/>               <span style="color: #A0A0A0"> 871</span> <span style="color: #228B22; background: #FFFFFF;">%                                     weighting function must be of the</span><br/>               <span style="color: #A0A0A0"> 872</span> <span style="color: #228B22; background: #FFFFFF;">%                                     form:</span><br/>               <span style="color: #A0A0A0"> 873</span> <span style="color: #228B22; background: #FFFFFF;">%</span><br/>               <span style="color: #A0A0A0"> 874</span> <span style="color: #228B22; background: #FFFFFF;">%                                     function DW = DISTWGT(D)</span><br/>               <span style="color: #A0A0A0"> 875</span> <span style="color: #228B22; background: #FFFFFF;">%</span><br/>               <span style="color: #A0A0A0"> 876</span> <span style="color: #228B22; background: #FFFFFF;">%                                     taking as argument a matrix D and</span><br/>               <span style="color: #A0A0A0"> 877</span> <span style="color: #228B22; background: #FFFFFF;">%                                     returning a matrix of distance weight</span><br/>               <span style="color: #A0A0A0"> 878</span> <span style="color: #228B22; background: #FFFFFF;">%                                     DW. D and DW can only contains</span><br/>               <span style="color: #A0A0A0"> 879</span> <span style="color: #228B22; background: #FFFFFF;">%                                     non-negative numerical values. DW must</span><br/>               <span style="color: #A0A0A0"> 880</span> <span style="color: #228B22; background: #FFFFFF;">%                                     have the same size as D. DW(I,J) is</span><br/>               <span style="color: #A0A0A0"> 881</span> <span style="color: #228B22; background: #FFFFFF;">%                                     the weight computed based on D(I,J).</span><br/>               <span style="color: #A0A0A0"> 882</span> <span style="color: #228B22; background: #FFFFFF;">%        'BreakTies'            - Method of breaking ties if more than one</span><br/>               <span style="color: #A0A0A0"> 883</span> <span style="color: #228B22; background: #FFFFFF;">%                                 class has the same smallest cost. Choices</span><br/>               <span style="color: #A0A0A0"> 884</span> <span style="color: #228B22; background: #FFFFFF;">%                                 are:</span><br/>               <span style="color: #A0A0A0"> 885</span> <span style="color: #228B22; background: #FFFFFF;">%                                   - 'smallest': Assign the point to the</span><br/>               <span style="color: #A0A0A0"> 886</span> <span style="color: #228B22; background: #FFFFFF;">%                                     class with the smallest index. This</span><br/>               <span style="color: #A0A0A0"> 887</span> <span style="color: #228B22; background: #FFFFFF;">%                                     is default.</span><br/>               <span style="color: #A0A0A0"> 888</span> <span style="color: #228B22; background: #FFFFFF;">%                                   - 'nearest': Assign the point to the</span><br/>               <span style="color: #A0A0A0"> 889</span> <span style="color: #228B22; background: #FFFFFF;">%                                     class of its nearest neighbor.</span><br/>               <span style="color: #A0A0A0"> 890</span> <span style="color: #228B22; background: #FFFFFF;">%                                   - 'random': Randomly pick a class</span><br/>               <span style="color: #A0A0A0"> 891</span> <span style="color: #228B22; background: #FFFFFF;">%                                      out the classes with the smallest</span><br/>               <span style="color: #A0A0A0"> 892</span> <span style="color: #228B22; background: #FFFFFF;">%                                      cost.</span><br/>               <span style="color: #A0A0A0"> 893</span> <span style="color: #228B22; background: #FFFFFF;">%        'Distance'              - A string or a function handle specifying</span><br/>               <span style="color: #A0A0A0"> 894</span> <span style="color: #228B22; background: #FFFFFF;">%                                  the distance metric. The value can be</span><br/>               <span style="color: #A0A0A0"> 895</span> <span style="color: #228B22; background: #FFFFFF;">%                                  one of the following:</span><br/>               <span style="color: #A0A0A0"> 896</span> <span style="color: #228B22; background: #FFFFFF;">%                                  'euclidean'   </span><br/>               <span style="color: #A0A0A0"> 897</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - Euclidean distance. This is default</span><br/>               <span style="color: #A0A0A0"> 898</span> <span style="color: #228B22; background: #FFFFFF;">%                                       if 'CategoricalPredictors' is</span><br/>               <span style="color: #A0A0A0"> 899</span> <span style="color: #228B22; background: #FFFFFF;">%                                       empty.</span><br/>               <span style="color: #A0A0A0"> 900</span> <span style="color: #228B22; background: #FFFFFF;">%                                  'seuclidean'</span><br/>               <span style="color: #A0A0A0"> 901</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - Standardized Euclidean distance.</span><br/>               <span style="color: #A0A0A0"> 902</span> <span style="color: #228B22; background: #FFFFFF;">%                                       Each coordinate difference between</span><br/>               <span style="color: #A0A0A0"> 903</span> <span style="color: #228B22; background: #FFFFFF;">%                                       X and a query point is divided by</span><br/>               <span style="color: #A0A0A0"> 904</span> <span style="color: #228B22; background: #FFFFFF;">%                                       an element of  vector S. The</span><br/>               <span style="color: #A0A0A0"> 905</span> <span style="color: #228B22; background: #FFFFFF;">%                                       default value of is the standard</span><br/>               <span style="color: #A0A0A0"> 906</span> <span style="color: #228B22; background: #FFFFFF;">%                                       deviation computed from X,</span><br/>               <span style="color: #A0A0A0"> 907</span> <span style="color: #228B22; background: #FFFFFF;">%                                       S=NANSTD(X). To specify another</span><br/>               <span style="color: #A0A0A0"> 908</span> <span style="color: #228B22; background: #FFFFFF;">%                                       value for S, use the 'Scale'</span><br/>               <span style="color: #A0A0A0"> 909</span> <span style="color: #228B22; background: #FFFFFF;">%                                       argument.</span><br/>               <span style="color: #A0A0A0"> 910</span> <span style="color: #228B22; background: #FFFFFF;">%                                  'cityblock'  </span><br/>               <span style="color: #A0A0A0"> 911</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - City Block distance.</span><br/>               <span style="color: #A0A0A0"> 912</span> <span style="color: #228B22; background: #FFFFFF;">%                                  'chebychev'  </span><br/>               <span style="color: #A0A0A0"> 913</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - Chebychev distance (maximum</span><br/>               <span style="color: #A0A0A0"> 914</span> <span style="color: #228B22; background: #FFFFFF;">%                                       coordinate  difference).</span><br/>               <span style="color: #A0A0A0"> 915</span> <span style="color: #228B22; background: #FFFFFF;">%                                  'minkowski'  </span><br/>               <span style="color: #A0A0A0"> 916</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - Minkowski distance. The default</span><br/>               <span style="color: #A0A0A0"> 917</span> <span style="color: #228B22; background: #FFFFFF;">%                                       exponent is 2. To specify a</span><br/>               <span style="color: #A0A0A0"> 918</span> <span style="color: #228B22; background: #FFFFFF;">%                                       different exponent, use the 'P'</span><br/>               <span style="color: #A0A0A0"> 919</span> <span style="color: #228B22; background: #FFFFFF;">%                                       argument.</span><br/>               <span style="color: #A0A0A0"> 920</span> <span style="color: #228B22; background: #FFFFFF;">%                                  'mahalanobis' </span><br/>               <span style="color: #A0A0A0"> 921</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - Mahalanobis distance, computed</span><br/>               <span style="color: #A0A0A0"> 922</span> <span style="color: #228B22; background: #FFFFFF;">%                                       using a positive definite</span><br/>               <span style="color: #A0A0A0"> 923</span> <span style="color: #228B22; background: #FFFFFF;">%                                       covariance matrix C. The default</span><br/>               <span style="color: #A0A0A0"> 924</span> <span style="color: #228B22; background: #FFFFFF;">%                                       value of C is the sample covariance</span><br/>               <span style="color: #A0A0A0"> 925</span> <span style="color: #228B22; background: #FFFFFF;">%                                       matrix of X, as computed by</span><br/>               <span style="color: #A0A0A0"> 926</span> <span style="color: #228B22; background: #FFFFFF;">%                                       NANCOV(X). To specify another value</span><br/>               <span style="color: #A0A0A0"> 927</span> <span style="color: #228B22; background: #FFFFFF;">%                                       for C, use the 'Cov' argument.</span><br/>               <span style="color: #A0A0A0"> 928</span> <span style="color: #228B22; background: #FFFFFF;">%                                  'cosine' </span><br/>               <span style="color: #A0A0A0"> 929</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - One minus the cosine of the</span><br/>               <span style="color: #A0A0A0"> 930</span> <span style="color: #228B22; background: #FFFFFF;">%                                       included angle between observations</span><br/>               <span style="color: #A0A0A0"> 931</span> <span style="color: #228B22; background: #FFFFFF;">%                                       (treated as vectors).</span><br/>               <span style="color: #A0A0A0"> 932</span> <span style="color: #228B22; background: #FFFFFF;">%                                   'correlation' </span><br/>               <span style="color: #A0A0A0"> 933</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - One minus the sample linear</span><br/>               <span style="color: #A0A0A0"> 934</span> <span style="color: #228B22; background: #FFFFFF;">%                                       correlation between observations</span><br/>               <span style="color: #A0A0A0"> 935</span> <span style="color: #228B22; background: #FFFFFF;">%                                       (treated as sequences of values).</span><br/>               <span style="color: #A0A0A0"> 936</span> <span style="color: #228B22; background: #FFFFFF;">%                                   'spearman'   </span><br/>               <span style="color: #A0A0A0"> 937</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - One minus the sample Spearman's</span><br/>               <span style="color: #A0A0A0"> 938</span> <span style="color: #228B22; background: #FFFFFF;">%                                       rank correlation between</span><br/>               <span style="color: #A0A0A0"> 939</span> <span style="color: #228B22; background: #FFFFFF;">%                                       observations (treated as sequences</span><br/>               <span style="color: #A0A0A0"> 940</span> <span style="color: #228B22; background: #FFFFFF;">%                                       of values).</span><br/>               <span style="color: #A0A0A0"> 941</span> <span style="color: #228B22; background: #FFFFFF;">%                                   'hamming'     </span><br/>               <span style="color: #A0A0A0"> 942</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - Hamming distance, percentage of</span><br/>               <span style="color: #A0A0A0"> 943</span> <span style="color: #228B22; background: #FFFFFF;">%                                       coordinates that differ. This is</span><br/>               <span style="color: #A0A0A0"> 944</span> <span style="color: #228B22; background: #FFFFFF;">%                                       default if 'CategoricalPredictors'</span><br/>               <span style="color: #A0A0A0"> 945</span> <span style="color: #228B22; background: #FFFFFF;">%                                       is set to 'all'.</span><br/>               <span style="color: #A0A0A0"> 946</span> <span style="color: #228B22; background: #FFFFFF;">%                                   'jaccard'     </span><br/>               <span style="color: #A0A0A0"> 947</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - One minus the Jaccard coefficient,</span><br/>               <span style="color: #A0A0A0"> 948</span> <span style="color: #228B22; background: #FFFFFF;">%                                       the percentage of nonzero</span><br/>               <span style="color: #A0A0A0"> 949</span> <span style="color: #228B22; background: #FFFFFF;">%                                       coordinates that differ.</span><br/>               <span style="color: #A0A0A0"> 950</span> <span style="color: #228B22; background: #FFFFFF;">%                                   function     </span><br/>               <span style="color: #A0A0A0"> 951</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - A distance function specified using</span><br/>               <span style="color: #A0A0A0"> 952</span> <span style="color: #228B22; background: #FFFFFF;">%                                       @ (for example @DISTFUN). A</span><br/>               <span style="color: #A0A0A0"> 953</span> <span style="color: #228B22; background: #FFFFFF;">%                                       distance function must be of the</span><br/>               <span style="color: #A0A0A0"> 954</span> <span style="color: #228B22; background: #FFFFFF;">%                                       form</span><br/>               <span style="color: #A0A0A0"> 955</span> <span style="color: #228B22; background: #FFFFFF;">%</span><br/>               <span style="color: #A0A0A0"> 956</span> <span style="color: #228B22; background: #FFFFFF;">%                                       function D2 = DISTFUN(ZI, ZJ),</span><br/>               <span style="color: #A0A0A0"> 957</span> <span style="color: #228B22; background: #FFFFFF;">%</span><br/>               <span style="color: #A0A0A0"> 958</span> <span style="color: #228B22; background: #FFFFFF;">%                                       taking as arguments a 1-by-N vector</span><br/>               <span style="color: #A0A0A0"> 959</span> <span style="color: #228B22; background: #FFFFFF;">%                                       ZI containing a single row of X or</span><br/>               <span style="color: #A0A0A0"> 960</span> <span style="color: #228B22; background: #FFFFFF;">%                                       Y, an M2-by-N matrix ZJ containing</span><br/>               <span style="color: #A0A0A0"> 961</span> <span style="color: #228B22; background: #FFFFFF;">%                                       multiple rows of X or Y, and</span><br/>               <span style="color: #A0A0A0"> 962</span> <span style="color: #228B22; background: #FFFFFF;">%                                       returning an M2-by-1 vector of</span><br/>               <span style="color: #A0A0A0"> 963</span> <span style="color: #228B22; background: #FFFFFF;">%                                       distances D2, whose Jth element is</span><br/>               <span style="color: #A0A0A0"> 964</span> <span style="color: #228B22; background: #FFFFFF;">%                                       the distance between the</span><br/>               <span style="color: #A0A0A0"> 965</span> <span style="color: #228B22; background: #FFFFFF;">%                                       observations ZI and ZJ(J,:).</span><br/>               <span style="color: #A0A0A0"> 966</span> <span style="color: #228B22; background: #FFFFFF;">%       'Exponent'             - A positive scalar indicating the</span><br/>               <span style="color: #A0A0A0"> 967</span> <span style="color: #228B22; background: #FFFFFF;">%                                   exponent of Minkowski distance. This</span><br/>               <span style="color: #A0A0A0"> 968</span> <span style="color: #228B22; background: #FFFFFF;">%                                   argument is only valid when</span><br/>               <span style="color: #A0A0A0"> 969</span> <span style="color: #228B22; background: #FFFFFF;">%                                  'Distance' is 'minkowski'. Default: 2.</span><br/>               <span style="color: #A0A0A0"> 970</span> <span style="color: #228B22; background: #FFFFFF;">%       'Cov'                   - A positive definite matrix indicating the</span><br/>               <span style="color: #A0A0A0"> 971</span> <span style="color: #228B22; background: #FFFFFF;">%                                 covariance matrix when computing the</span><br/>               <span style="color: #A0A0A0"> 972</span> <span style="color: #228B22; background: #FFFFFF;">%                                 Mahalanobis distance. This argument is</span><br/>               <span style="color: #A0A0A0"> 973</span> <span style="color: #228B22; background: #FFFFFF;">%                                 only valid when 'Distance' is</span><br/>               <span style="color: #A0A0A0"> 974</span> <span style="color: #228B22; background: #FFFFFF;">%                                 'mahalanobis'. Default is NANCOV(X).</span><br/>               <span style="color: #A0A0A0"> 975</span> <span style="color: #228B22; background: #FFFFFF;">%       'Scale'                 - A vector S containing non-negative</span><br/>               <span style="color: #A0A0A0"> 976</span> <span style="color: #228B22; background: #FFFFFF;">%                                 values, with length equal to the number</span><br/>               <span style="color: #A0A0A0"> 977</span> <span style="color: #228B22; background: #FFFFFF;">%                                 of columns in X. Each  coordinate</span><br/>               <span style="color: #A0A0A0"> 978</span> <span style="color: #228B22; background: #FFFFFF;">%                                 difference between X and a query point is</span><br/>               <span style="color: #A0A0A0"> 979</span> <span style="color: #228B22; background: #FFFFFF;">%                                 divided by the corresponding element of</span><br/>               <span style="color: #A0A0A0"> 980</span> <span style="color: #228B22; background: #FFFFFF;">%                                 S. This argument is only valid when</span><br/>               <span style="color: #A0A0A0"> 981</span> <span style="color: #228B22; background: #FFFFFF;">%                                 'Distance' is 'seuclidean'. Default is</span><br/>               <span style="color: #A0A0A0"> 982</span> <span style="color: #228B22; background: #FFFFFF;">%                                 NANSTD(X).</span><br/>               <span style="color: #A0A0A0"> 983</span> <span style="color: #228B22; background: #FFFFFF;">%       'BucketSize'            - The maximum number of data points in the</span><br/>               <span style="color: #A0A0A0"> 984</span> <span style="color: #228B22; background: #FFFFFF;">%                                 leaf node of the kd-tree (default is 50).</span><br/>               <span style="color: #A0A0A0"> 985</span> <span style="color: #228B22; background: #FFFFFF;">%                                 This argument is only meaningful when</span><br/>               <span style="color: #A0A0A0"> 986</span> <span style="color: #228B22; background: #FFFFFF;">%                                 'NSMethod' is 'kdtree'.</span><br/>               <span style="color: #A0A0A0"> 987</span> <span style="color: #228B22; background: #FFFFFF;">%</span><br/>               <span style="color: #A0A0A0"> 988</span> <span style="color: #228B22; background: #FFFFFF;">%    See also ClassificationKNN</span><br/>               <span style="color: #A0A0A0"> 989</span> <span style="color: #228B22; background: #FFFFFF;"></span><br/>               <span style="color: #A0A0A0"> 990</span> <span style="color: #A0A0A0; background: #FFFFFF;">            Nfold = classreg.learning.generator.Partitioner.processArgs(varargin{:});</span><br/>               <span style="color: #A0A0A0"> 991</span> <span style="color: #A0A0A0; background: #FFFFFF;">            docv = ~isempty(Nfold);</span><br/>               <span style="color: #A0A0A0"> 992</span> <span style="color: #228B22; background: #FFFFFF;">            </span><br/>               <span style="color: #A0A0A0"> 993</span> <span style="color: #228B22; background: #FFFFFF;">            % Set prior to an empty array. For a single KNN classifier, it</span><br/>               <span style="color: #A0A0A0"> 994</span> <span style="color: #228B22; background: #FFFFFF;">            % can be filled with something.</span><br/>               <span style="color: #A0A0A0"> 995</span> <span style="color: #A0A0A0; background: #FFFFFF;">            prior = [];</span><br/>               <span style="color: #A0A0A0"> 996</span> <span style="color: #228B22; background: #FFFFFF;">            </span><br/>               <span style="color: #A0A0A0"> 997</span> <span style="color: #A0A0A0; background: #FFFFFF;">            if ~docv %single KNN</span><br/>               <span style="color: #A0A0A0"> 998</span> <span style="color: #228B22; background: #FFFFFF;">                % For a single KNN, exclude cost and prior from input arguments.</span><br/>               <span style="color: #A0A0A0"> 999</span> <span style="color: #228B22; background: #FFFFFF;">                % If we pass a zero prior for a class, PrivW for this class</span><br/>               <span style="color: #A0A0A0">1000</span> <span style="color: #228B22; background: #FFFFFF;">                % will be set to 0 in the ClassificationKNN constructor.</span><br/>               <span style="color: #A0A0A0">1001</span> <span style="color: #228B22; background: #FFFFFF;">                % To prevent this, we pass a default empirical prior to fit</span><br/>               <span style="color: #A0A0A0">1002</span> <span style="color: #228B22; background: #FFFFFF;">                % and reset the prior after fitting.</span><br/>               <span style="color: #A0A0A0">1003</span> <span style="color: #A0A0A0; background: #FFFFFF;">                args = {'prior' 'cost'};</span><br/>               <span style="color: #A0A0A0">1004</span> <span style="color: #A0A0A0; background: #FFFFFF;">                defs = {     []  []};</span><br/>               <span style="color: #A0A0A0">1005</span> <span style="color: #A0A0A0; background: #FFFFFF;">                [prior,cost,~,fitArgs] = internal.stats.parseArgs(args,defs,varargin{:});</span><br/>               <span style="color: #A0A0A0">1006</span> <span style="color: #228B22; background: #FFFFFF;">              </span><br/>               <span style="color: #A0A0A0">1007</span> <span style="color: #228B22; background: #FFFFFF;">            else % cross-validated KNN</span><br/>               <span style="color: #A0A0A0">1008</span> <span style="color: #228B22; background: #FFFFFF;">                % For cross-validated KNN, we pass the prior specified by</span><br/>               <span style="color: #A0A0A0">1009</span> <span style="color: #228B22; background: #FFFFFF;">                % the customer because a cross-validated KNN does not allow</span><br/>               <span style="color: #A0A0A0">1010</span> <span style="color: #228B22; background: #FFFFFF;">                % assignment to Prior property.</span><br/>               <span style="color: #A0A0A0">1011</span> <span style="color: #A0A0A0; background: #FFFFFF;">                 args = {'cost'};</span><br/>               <span style="color: #A0A0A0">1012</span> <span style="color: #A0A0A0; background: #FFFFFF;">                 defs = {    []};</span><br/>               <span style="color: #A0A0A0">1013</span> <span style="color: #A0A0A0; background: #FFFFFF;">                [cost,~,fitArgs] = internal.stats.parseArgs(args,defs,varargin{:});</span><br/>               <span style="color: #A0A0A0">1014</span> <span style="color: #A0A0A0; background: #FFFFFF;">            end</span><br/>               <span style="color: #A0A0A0">1015</span> <span style="color: #228B22; background: #FFFFFF;">            </span><br/>               <span style="color: #A0A0A0">1016</span> <span style="color: #228B22; background: #FFFFFF;">            % Fit</span><br/>               <span style="color: #A0A0A0">1017</span> <span style="color: #A0A0A0; background: #FFFFFF;">            temp = classreg.learning.FitTemplate.make(...</span><br/>               <span style="color: #A0A0A0">1018</span> <span style="color: #A0A0A0; background: #FFFFFF;">                'KNN','type','classification',fitArgs{:});</span><br/>               <span style="color: #A0A0A0">1019</span> <span style="color: #A0A0A0; background: #FFFFFF;">            this = fit(temp,X,Y);</span><br/>               <span style="color: #A0A0A0">1020</span> <span style="color: #228B22; background: #FFFFFF;">            </span><br/>               <span style="color: #A0A0A0">1021</span> <span style="color: #228B22; background: #FFFFFF;">            % Assign prior and cost</span><br/>               <span style="color: #A0A0A0">1022</span> <span style="color: #A0A0A0; background: #FFFFFF;">            if ~isempty(prior) &amp;&amp; ~strncmpi(prior,'empirical',length(prior))</span><br/>               <span style="color: #A0A0A0">1023</span> <span style="color: #228B22; background: #FFFFFF;">                %this.W will be normalized based on class priors </span><br/>               <span style="color: #A0A0A0">1024</span> <span style="color: #A0A0A0; background: #FFFFFF;">                this.Prior = prior;</span><br/>               <span style="color: #A0A0A0">1025</span> <span style="color: #A0A0A0; background: #FFFFFF;">            end</span><br/>               <span style="color: #A0A0A0">1026</span> <span style="color: #A0A0A0; background: #FFFFFF;">            if ~isempty(cost)</span><br/>               <span style="color: #A0A0A0">1027</span> <span style="color: #A0A0A0; background: #FFFFFF;">                this.Cost = cost;</span><br/>               <span style="color: #A0A0A0">1028</span> <span style="color: #A0A0A0; background: #FFFFFF;">           end</span><br/>               <span style="color: #A0A0A0">1029</span> <span style="color: #A0A0A0; background: #FFFFFF;">        end</span><br/>               <span style="color: #A0A0A0">1030</span> <span style="color: #228B22; background: #FFFFFF;">        </span><br/>               <span style="color: #A0A0A0">1031</span> <span style="color: #A0A0A0; background: #FFFFFF;">         function temp = template(varargin)</span><br/>               <span style="color: #A0A0A0">1032</span> <span style="color: #228B22; background: #FFFFFF;">%TEMPLATE Create a classification template.</span><br/>               <span style="color: #A0A0A0">1033</span> <span style="color: #228B22; background: #FFFFFF;">%   T=CLASSIFICATIONKNN.TEMPLATE() returns a KNN classification</span><br/>               <span style="color: #A0A0A0">1034</span> <span style="color: #228B22; background: #FFFFFF;">%   template suitable for use in the FITENSEMBLE function.</span><br/>               <span style="color: #A0A0A0">1035</span> <span style="color: #228B22; background: #FFFFFF;">%</span><br/>               <span style="color: #A0A0A0">1036</span> <span style="color: #228B22; background: #FFFFFF;">%   T=CLASSIFICATIONKNN.TEMPLATE('PARAM1',val1,'PARAM2',val2,...)</span><br/>               <span style="color: #A0A0A0">1037</span> <span style="color: #228B22; background: #FFFFFF;">%   specifies optional parameter name/value pairs:</span><br/>               <span style="color: #A0A0A0">1038</span> <span style="color: #228B22; background: #FFFFFF;">%       'NumNeighbors'          - A positive integer specifying the number</span><br/>               <span style="color: #A0A0A0">1039</span> <span style="color: #228B22; background: #FFFFFF;">%                                 of nearest neighbors in X for classifying</span><br/>               <span style="color: #A0A0A0">1040</span> <span style="color: #228B22; background: #FFFFFF;">%                                 each point when predicting. Default: 1.</span><br/>               <span style="color: #A0A0A0">1041</span> <span style="color: #228B22; background: #FFFFFF;">%       'NSMethod'              - Nearest neighbors search method.</span><br/>               <span style="color: #A0A0A0">1042</span> <span style="color: #228B22; background: #FFFFFF;">%                                 Value is either:</span><br/>               <span style="color: #A0A0A0">1043</span> <span style="color: #228B22; background: #FFFFFF;">%                                   - 'kdtree' uses a kd-tree to find</span><br/>               <span style="color: #A0A0A0">1044</span> <span style="color: #228B22; background: #FFFFFF;">%                                     nearest neighbors. 'kdtree' is only</span><br/>               <span style="color: #A0A0A0">1045</span> <span style="color: #228B22; background: #FFFFFF;">%                                     valid when the distance metric</span><br/>               <span style="color: #A0A0A0">1046</span> <span style="color: #228B22; background: #FFFFFF;">%                                     is one of the following metrics:</span><br/>               <span style="color: #A0A0A0">1047</span> <span style="color: #228B22; background: #FFFFFF;">%                                       - 'euclidean'</span><br/>               <span style="color: #A0A0A0">1048</span> <span style="color: #228B22; background: #FFFFFF;">%                                       - 'cityblock'</span><br/>               <span style="color: #A0A0A0">1049</span> <span style="color: #228B22; background: #FFFFFF;">%                                       - 'minkowski'</span><br/>               <span style="color: #A0A0A0">1050</span> <span style="color: #228B22; background: #FFFFFF;">%                                       - 'chebyshev'</span><br/>               <span style="color: #A0A0A0">1051</span> <span style="color: #228B22; background: #FFFFFF;">%                                   - 'exhaustive' uses the exhaustive</span><br/>               <span style="color: #A0A0A0">1052</span> <span style="color: #228B22; background: #FFFFFF;">%                                     search algorithm. The distance values</span><br/>               <span style="color: #A0A0A0">1053</span> <span style="color: #228B22; background: #FFFFFF;">%                                     from all the points in X to each</span><br/>               <span style="color: #A0A0A0">1054</span> <span style="color: #228B22; background: #FFFFFF;">%                                     point in Y are computed to find</span><br/>               <span style="color: #A0A0A0">1055</span> <span style="color: #228B22; background: #FFFFFF;">%                                     nearest neighbors.</span><br/>               <span style="color: #A0A0A0">1056</span> <span style="color: #228B22; background: #FFFFFF;">%                                   Default is 'kdtree' when the number of</span><br/>               <span style="color: #A0A0A0">1057</span> <span style="color: #228B22; background: #FFFFFF;">%                                   columns of X is not greater  than 10, X</span><br/>               <span style="color: #A0A0A0">1058</span> <span style="color: #228B22; background: #FFFFFF;">%                                   is not sparse, and the distance metric</span><br/>               <span style="color: #A0A0A0">1059</span> <span style="color: #228B22; background: #FFFFFF;">%                                   is one of the above 4 metrics;</span><br/>               <span style="color: #A0A0A0">1060</span> <span style="color: #228B22; background: #FFFFFF;">%                                   otherwise, default is 'exhaustive'.</span><br/>               <span style="color: #A0A0A0">1061</span> <span style="color: #228B22; background: #FFFFFF;">%       'IncludeTies'           - A logical value. Use true to include all</span><br/>               <span style="color: #A0A0A0">1062</span> <span style="color: #228B22; background: #FFFFFF;">%                                 neighbors whose distance equal the Kth</span><br/>               <span style="color: #A0A0A0">1063</span> <span style="color: #228B22; background: #FFFFFF;">%                                 smallest distance. Use false to include</span><br/>               <span style="color: #A0A0A0">1064</span> <span style="color: #228B22; background: #FFFFFF;">%                                 exactly K nearest neighbors.</span><br/>               <span style="color: #A0A0A0">1065</span> <span style="color: #228B22; background: #FFFFFF;">%       'DistanceWeight'        - A string or a function handle specifying</span><br/>               <span style="color: #A0A0A0">1066</span> <span style="color: #228B22; background: #FFFFFF;">%                                 the distance weighting function. The</span><br/>               <span style="color: #A0A0A0">1067</span> <span style="color: #228B22; background: #FFFFFF;">%                                 choices of the string are:</span><br/>               <span style="color: #A0A0A0">1068</span> <span style="color: #228B22; background: #FFFFFF;">%                                   - 'equal': Each neighbor gets equal</span><br/>               <span style="color: #A0A0A0">1069</span> <span style="color: #228B22; background: #FFFFFF;">%                                      weight (default).</span><br/>               <span style="color: #A0A0A0">1070</span> <span style="color: #228B22; background: #FFFFFF;">%                                   - 'inverse': Each neighbor gets weight</span><br/>               <span style="color: #A0A0A0">1071</span> <span style="color: #228B22; background: #FFFFFF;">%                                      1/d, where d is the distance between</span><br/>               <span style="color: #A0A0A0">1072</span> <span style="color: #228B22; background: #FFFFFF;">%                                      this neighbor and the point being</span><br/>               <span style="color: #A0A0A0">1073</span> <span style="color: #228B22; background: #FFFFFF;">%                                      classified.</span><br/>               <span style="color: #A0A0A0">1074</span> <span style="color: #228B22; background: #FFFFFF;">%                                   - 'squaredinverse': Each neighbor gets</span><br/>               <span style="color: #A0A0A0">1075</span> <span style="color: #228B22; background: #FFFFFF;">%                                     weight 1/d^2, where d is the distance</span><br/>               <span style="color: #A0A0A0">1076</span> <span style="color: #228B22; background: #FFFFFF;">%                                     between this neighbor and the point</span><br/>               <span style="color: #A0A0A0">1077</span> <span style="color: #228B22; background: #FFFFFF;">%                                     being classified.</span><br/>               <span style="color: #A0A0A0">1078</span> <span style="color: #228B22; background: #FFFFFF;">%                                   - A distance weighting function</span><br/>               <span style="color: #A0A0A0">1079</span> <span style="color: #228B22; background: #FFFFFF;">%                                     specified using @. A distance</span><br/>               <span style="color: #A0A0A0">1080</span> <span style="color: #228B22; background: #FFFFFF;">%                                     weighting function must be of the</span><br/>               <span style="color: #A0A0A0">1081</span> <span style="color: #228B22; background: #FFFFFF;">%                                     form:</span><br/>               <span style="color: #A0A0A0">1082</span> <span style="color: #228B22; background: #FFFFFF;">%</span><br/>               <span style="color: #A0A0A0">1083</span> <span style="color: #228B22; background: #FFFFFF;">%                                     function DW = DISTWGT(D)</span><br/>               <span style="color: #A0A0A0">1084</span> <span style="color: #228B22; background: #FFFFFF;">%</span><br/>               <span style="color: #A0A0A0">1085</span> <span style="color: #228B22; background: #FFFFFF;">%                                     taking as argument a matrix D and</span><br/>               <span style="color: #A0A0A0">1086</span> <span style="color: #228B22; background: #FFFFFF;">%                                     returning a matrix of distance weight</span><br/>               <span style="color: #A0A0A0">1087</span> <span style="color: #228B22; background: #FFFFFF;">%                                     DW. D and DW can only contain</span><br/>               <span style="color: #A0A0A0">1088</span> <span style="color: #228B22; background: #FFFFFF;">%                                     non-negative numerical values. DW must</span><br/>               <span style="color: #A0A0A0">1089</span> <span style="color: #228B22; background: #FFFFFF;">%                                     have the same size as D. DW(I,J) is</span><br/>               <span style="color: #A0A0A0">1090</span> <span style="color: #228B22; background: #FFFFFF;">%                                     the weight computed based on D(I,J).</span><br/>               <span style="color: #A0A0A0">1091</span> <span style="color: #228B22; background: #FFFFFF;">%        'BreakTies'            - Method of breaking ties if more than one</span><br/>               <span style="color: #A0A0A0">1092</span> <span style="color: #228B22; background: #FFFFFF;">%                                 class has the same smallest cost. Choices</span><br/>               <span style="color: #A0A0A0">1093</span> <span style="color: #228B22; background: #FFFFFF;">%                                 are:</span><br/>               <span style="color: #A0A0A0">1094</span> <span style="color: #228B22; background: #FFFFFF;">%                                   - 'smallest': Assign the point to the</span><br/>               <span style="color: #A0A0A0">1095</span> <span style="color: #228B22; background: #FFFFFF;">%                                     class with the smallest index. This</span><br/>               <span style="color: #A0A0A0">1096</span> <span style="color: #228B22; background: #FFFFFF;">%                                     is default.</span><br/>               <span style="color: #A0A0A0">1097</span> <span style="color: #228B22; background: #FFFFFF;">%                                   - 'nearest': Assign the point to the</span><br/>               <span style="color: #A0A0A0">1098</span> <span style="color: #228B22; background: #FFFFFF;">%                                     class of its nearest neighbor.</span><br/>               <span style="color: #A0A0A0">1099</span> <span style="color: #228B22; background: #FFFFFF;">%                                   -  'random': Randomly pick a class</span><br/>               <span style="color: #A0A0A0">1100</span> <span style="color: #228B22; background: #FFFFFF;">%                                      out the classes with the smallest</span><br/>               <span style="color: #A0A0A0">1101</span> <span style="color: #228B22; background: #FFFFFF;">%                                      cost.</span><br/>               <span style="color: #A0A0A0">1102</span> <span style="color: #228B22; background: #FFFFFF;">%        'Distance'              - A string or a function handle specifying</span><br/>               <span style="color: #A0A0A0">1103</span> <span style="color: #228B22; background: #FFFFFF;">%                                  the distance metric. The value can be</span><br/>               <span style="color: #A0A0A0">1104</span> <span style="color: #228B22; background: #FFFFFF;">%                                  one of the following:</span><br/>               <span style="color: #A0A0A0">1105</span> <span style="color: #228B22; background: #FFFFFF;">%                                  'euclidean'   </span><br/>               <span style="color: #A0A0A0">1106</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - Euclidean distance (default).</span><br/>               <span style="color: #A0A0A0">1107</span> <span style="color: #228B22; background: #FFFFFF;">%                                  'seuclidean'</span><br/>               <span style="color: #A0A0A0">1108</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - Standardized Euclidean distance.</span><br/>               <span style="color: #A0A0A0">1109</span> <span style="color: #228B22; background: #FFFFFF;">%                                       Each coordinate difference between</span><br/>               <span style="color: #A0A0A0">1110</span> <span style="color: #228B22; background: #FFFFFF;">%                                       X and a query point is divided by</span><br/>               <span style="color: #A0A0A0">1111</span> <span style="color: #228B22; background: #FFFFFF;">%                                       an element of  vector S. The</span><br/>               <span style="color: #A0A0A0">1112</span> <span style="color: #228B22; background: #FFFFFF;">%                                       default value of is the standard</span><br/>               <span style="color: #A0A0A0">1113</span> <span style="color: #228B22; background: #FFFFFF;">%                                       deviation computed from X,</span><br/>               <span style="color: #A0A0A0">1114</span> <span style="color: #228B22; background: #FFFFFF;">%                                       S=NANSTD(X). To specify another</span><br/>               <span style="color: #A0A0A0">1115</span> <span style="color: #228B22; background: #FFFFFF;">%                                       value for S, use the 'Scale'</span><br/>               <span style="color: #A0A0A0">1116</span> <span style="color: #228B22; background: #FFFFFF;">%                                       argument.</span><br/>               <span style="color: #A0A0A0">1117</span> <span style="color: #228B22; background: #FFFFFF;">%                                  'cityblock'  </span><br/>               <span style="color: #A0A0A0">1118</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - City Block distance.</span><br/>               <span style="color: #A0A0A0">1119</span> <span style="color: #228B22; background: #FFFFFF;">%                                  'chebychev'  </span><br/>               <span style="color: #A0A0A0">1120</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - Chebychev distance (maximum</span><br/>               <span style="color: #A0A0A0">1121</span> <span style="color: #228B22; background: #FFFFFF;">%                                       coordinate  difference).</span><br/>               <span style="color: #A0A0A0">1122</span> <span style="color: #228B22; background: #FFFFFF;">%                                  'minkowski'  </span><br/>               <span style="color: #A0A0A0">1123</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - Minkowski distance. The default</span><br/>               <span style="color: #A0A0A0">1124</span> <span style="color: #228B22; background: #FFFFFF;">%                                       exponent is 2. To specify a</span><br/>               <span style="color: #A0A0A0">1125</span> <span style="color: #228B22; background: #FFFFFF;">%                                       different exponent, use the 'P'</span><br/>               <span style="color: #A0A0A0">1126</span> <span style="color: #228B22; background: #FFFFFF;">%                                       argument.</span><br/>               <span style="color: #A0A0A0">1127</span> <span style="color: #228B22; background: #FFFFFF;">%                                  'mahalanobis' </span><br/>               <span style="color: #A0A0A0">1128</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - Mahalanobis distance, computed</span><br/>               <span style="color: #A0A0A0">1129</span> <span style="color: #228B22; background: #FFFFFF;">%                                       using a positive definite</span><br/>               <span style="color: #A0A0A0">1130</span> <span style="color: #228B22; background: #FFFFFF;">%                                       covariance matrix C. The default</span><br/>               <span style="color: #A0A0A0">1131</span> <span style="color: #228B22; background: #FFFFFF;">%                                       value of C is the sample covariance</span><br/>               <span style="color: #A0A0A0">1132</span> <span style="color: #228B22; background: #FFFFFF;">%                                       matrix of X, as computed by</span><br/>               <span style="color: #A0A0A0">1133</span> <span style="color: #228B22; background: #FFFFFF;">%                                       NANCOV(X). To specify another value</span><br/>               <span style="color: #A0A0A0">1134</span> <span style="color: #228B22; background: #FFFFFF;">%                                       for C, use the 'Cov' argument.</span><br/>               <span style="color: #A0A0A0">1135</span> <span style="color: #228B22; background: #FFFFFF;">%                                  'cosine' </span><br/>               <span style="color: #A0A0A0">1136</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - One minus the cosine of the</span><br/>               <span style="color: #A0A0A0">1137</span> <span style="color: #228B22; background: #FFFFFF;">%                                       included angle between observations</span><br/>               <span style="color: #A0A0A0">1138</span> <span style="color: #228B22; background: #FFFFFF;">%                                       (treated as vectors).</span><br/>               <span style="color: #A0A0A0">1139</span> <span style="color: #228B22; background: #FFFFFF;">%                                   'correlation' </span><br/>               <span style="color: #A0A0A0">1140</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - One minus the sample linear</span><br/>               <span style="color: #A0A0A0">1141</span> <span style="color: #228B22; background: #FFFFFF;">%                                       correlation between observations</span><br/>               <span style="color: #A0A0A0">1142</span> <span style="color: #228B22; background: #FFFFFF;">%                                       (treated as sequences of values).</span><br/>               <span style="color: #A0A0A0">1143</span> <span style="color: #228B22; background: #FFFFFF;">%                                   'spearman'   </span><br/>               <span style="color: #A0A0A0">1144</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - One minus the sample Spearman's</span><br/>               <span style="color: #A0A0A0">1145</span> <span style="color: #228B22; background: #FFFFFF;">%                                       rank correlation between</span><br/>               <span style="color: #A0A0A0">1146</span> <span style="color: #228B22; background: #FFFFFF;">%                                       observations (treated as sequences</span><br/>               <span style="color: #A0A0A0">1147</span> <span style="color: #228B22; background: #FFFFFF;">%                                       of values).</span><br/>               <span style="color: #A0A0A0">1148</span> <span style="color: #228B22; background: #FFFFFF;">%                                   'hamming'     </span><br/>               <span style="color: #A0A0A0">1149</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - Hamming distance, percentage of</span><br/>               <span style="color: #A0A0A0">1150</span> <span style="color: #228B22; background: #FFFFFF;">%                                       coordinates that differ.</span><br/>               <span style="color: #A0A0A0">1151</span> <span style="color: #228B22; background: #FFFFFF;">%                                   'jaccard'     </span><br/>               <span style="color: #A0A0A0">1152</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - One minus the Jaccard coefficient,</span><br/>               <span style="color: #A0A0A0">1153</span> <span style="color: #228B22; background: #FFFFFF;">%                                       the percentage of nonzero</span><br/>               <span style="color: #A0A0A0">1154</span> <span style="color: #228B22; background: #FFFFFF;">%                                       coordinates that differ.</span><br/>               <span style="color: #A0A0A0">1155</span> <span style="color: #228B22; background: #FFFFFF;">%                                   function     </span><br/>               <span style="color: #A0A0A0">1156</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - A distance function specified using</span><br/>               <span style="color: #A0A0A0">1157</span> <span style="color: #228B22; background: #FFFFFF;">%                                       @ (for example @DISTFUN). A</span><br/>               <span style="color: #A0A0A0">1158</span> <span style="color: #228B22; background: #FFFFFF;">%                                       distance function must be of the</span><br/>               <span style="color: #A0A0A0">1159</span> <span style="color: #228B22; background: #FFFFFF;">%                                       form</span><br/>               <span style="color: #A0A0A0">1160</span> <span style="color: #228B22; background: #FFFFFF;">%</span><br/>               <span style="color: #A0A0A0">1161</span> <span style="color: #228B22; background: #FFFFFF;">%                                       function D2 = DISTFUN(ZI, ZJ),</span><br/>               <span style="color: #A0A0A0">1162</span> <span style="color: #228B22; background: #FFFFFF;">%</span><br/>               <span style="color: #A0A0A0">1163</span> <span style="color: #228B22; background: #FFFFFF;">%                                       taking as arguments a 1-by-N vector</span><br/>               <span style="color: #A0A0A0">1164</span> <span style="color: #228B22; background: #FFFFFF;">%                                       ZI containing a single row of X or</span><br/>               <span style="color: #A0A0A0">1165</span> <span style="color: #228B22; background: #FFFFFF;">%                                       Y, an M2-by-N matrix ZJ containing</span><br/>               <span style="color: #A0A0A0">1166</span> <span style="color: #228B22; background: #FFFFFF;">%                                       multiple rows of X or Y, and</span><br/>               <span style="color: #A0A0A0">1167</span> <span style="color: #228B22; background: #FFFFFF;">%                                       returning an M2-by-1 vector of</span><br/>               <span style="color: #A0A0A0">1168</span> <span style="color: #228B22; background: #FFFFFF;">%                                       distances D2, whose Jth element is</span><br/>               <span style="color: #A0A0A0">1169</span> <span style="color: #228B22; background: #FFFFFF;">%                                       the distance between the</span><br/>               <span style="color: #A0A0A0">1170</span> <span style="color: #228B22; background: #FFFFFF;">%                                       observations ZI and ZJ(J,:).</span><br/>               <span style="color: #A0A0A0">1171</span> <span style="color: #228B22; background: #FFFFFF;">%        'Exponent'             - A positive scalar indicating the</span><br/>               <span style="color: #A0A0A0">1172</span> <span style="color: #228B22; background: #FFFFFF;">%                                   exponent of Minkowski distance. This</span><br/>               <span style="color: #A0A0A0">1173</span> <span style="color: #228B22; background: #FFFFFF;">%                                   argument is only valid when</span><br/>               <span style="color: #A0A0A0">1174</span> <span style="color: #228B22; background: #FFFFFF;">%                                  'Distance' is 'minkowski'. Default: 2.</span><br/>               <span style="color: #A0A0A0">1175</span> <span style="color: #228B22; background: #FFFFFF;">%        'Cov'                  - A positive definite matrix indicating the</span><br/>               <span style="color: #A0A0A0">1176</span> <span style="color: #228B22; background: #FFFFFF;">%                                 covariance matrix when computing the</span><br/>               <span style="color: #A0A0A0">1177</span> <span style="color: #228B22; background: #FFFFFF;">%                                 Mahalanobis distance. This argument is</span><br/>               <span style="color: #A0A0A0">1178</span> <span style="color: #228B22; background: #FFFFFF;">%                                 only valid when 'Distance' is</span><br/>               <span style="color: #A0A0A0">1179</span> <span style="color: #228B22; background: #FFFFFF;">%                                 'mahalanobis'. Default is NANCOV(X).</span><br/>               <span style="color: #A0A0A0">1180</span> <span style="color: #228B22; background: #FFFFFF;">%       'Scale'                 - A vector S containing non-negative</span><br/>               <span style="color: #A0A0A0">1181</span> <span style="color: #228B22; background: #FFFFFF;">%                                 values, with length equal to the number</span><br/>               <span style="color: #A0A0A0">1182</span> <span style="color: #228B22; background: #FFFFFF;">%                                 of columns in X. Each  coordinate</span><br/>               <span style="color: #A0A0A0">1183</span> <span style="color: #228B22; background: #FFFFFF;">%                                 difference between X and a query point is</span><br/>               <span style="color: #A0A0A0">1184</span> <span style="color: #228B22; background: #FFFFFF;">%                                 divided by the corresponding element of</span><br/>               <span style="color: #A0A0A0">1185</span> <span style="color: #228B22; background: #FFFFFF;">%                                 S. This argument is only valid when</span><br/>               <span style="color: #A0A0A0">1186</span> <span style="color: #228B22; background: #FFFFFF;">%                                 'Distance' is 'seuclidean'. Default is</span><br/>               <span style="color: #A0A0A0">1187</span> <span style="color: #228B22; background: #FFFFFF;">%                                 NANSTD(X).</span><br/>               <span style="color: #A0A0A0">1188</span> <span style="color: #228B22; background: #FFFFFF;">%       'BucketSize'            - The maximum number of data points in the</span><br/>               <span style="color: #A0A0A0">1189</span> <span style="color: #228B22; background: #FFFFFF;">%                                 leaf node of the kd-tree (default is 50).</span><br/>               <span style="color: #A0A0A0">1190</span> <span style="color: #228B22; background: #FFFFFF;">%                                 This argument is only meaningful when</span><br/>               <span style="color: #A0A0A0">1191</span> <span style="color: #228B22; background: #FFFFFF;">%                                 'NSMethod' is 'kdtree'.</span><br/>               <span style="color: #A0A0A0">1192</span> <span style="color: #228B22; background: #FFFFFF;">%</span><br/>               <span style="color: #A0A0A0">1193</span> <span style="color: #228B22; background: #FFFFFF;">%   See also ClassificationKNN, fitensemble, ClassificationKNN.fit.</span><br/>               <span style="color: #A0A0A0">1194</span> <span style="color: #228B22; background: #FFFFFF;"></span><br/>               <span style="color: #A0A0A0">1195</span> <span style="color: #A0A0A0; background: #FFFFFF;">            classreg.learning.FitTemplate.catchType(varargin{:});</span><br/>               <span style="color: #A0A0A0">1196</span> <span style="color: #A0A0A0; background: #FFFFFF;">            temp = classreg.learning.FitTemplate.make('KNN','type','classification',varargin{:});</span><br/>               <span style="color: #A0A0A0">1197</span> <span style="color: #A0A0A0; background: #FFFFFF;">         end</span><br/>               <span style="color: #A0A0A0">1198</span> <span style="color: #A0A0A0; background: #FFFFFF;">    end</span><br/>               <span style="color: #A0A0A0">1199</span> <span style="color: #228B22; background: #FFFFFF;">    </span><br/>               <span style="color: #A0A0A0">1200</span> <span style="color: #228B22; background: #FFFFFF;">    </span><br/>               <span style="color: #A0A0A0">1201</span> <span style="color: #A0A0A0; background: #FFFFFF;">    methods (Hidden)</span><br/>               <span style="color: #A0A0A0">1202</span> <span style="color: #228B22; background: #FFFFFF;">        %Make this method hidden because it won't be documented</span><br/>               <span style="color: #A0A0A0">1203</span> <span style="color: #A0A0A0; background: #FFFFFF;">        function cmp = compact(this)</span><br/>               <span style="color: #A0A0A0">1204</span> <span style="color: #228B22; background: #FFFFFF;">        %COMPACT Compact discriminant analysis.</span><br/>               <span style="color: #A0A0A0">1205</span> <span style="color: #228B22; background: #FFFFFF;">        %   CMP=COMPACT(KNN) returns an object of class</span><br/>               <span style="color: #A0A0A0">1206</span> <span style="color: #228B22; background: #FFFFFF;">        %   ClassificationKNN </span><br/>               <span style="color: #A0A0A0">1207</span> <span style="color: #228B22; background: #FFFFFF;">               </span><br/>               <span style="color: #A0A0A0">1208</span> <span style="color: #A0A0A0; background: #FFFFFF;">            cmp = this; %just return the class of full class</span><br/>               <span style="color: #A0A0A0">1209</span> <span style="color: #A0A0A0; background: #FFFFFF;">        end</span><br/>               <span style="color: #A0A0A0">1210</span> <span style="color: #228B22; background: #FFFFFF;">        </span><br/>               <span style="color: #A0A0A0">1211</span> <span style="color: #A0A0A0; background: #FFFFFF;">    end</span><br/>               <span style="color: #A0A0A0">1212</span> <span style="color: #A0A0A0; background: #FFFFFF;">end %classdef</span><br/>               <span style="color: #A0A0A0">1213</span> <span style="color: #228B22; background: #FFFFFF;"></span><br/>               <span style="color: #A0A0A0">1214</span> <span style="color: #A0A0A0; background: #FFFFFF;">function distWgt =wgtFunc(dist,e)</span><br/>               <span style="color: #A0A0A0">1215</span> <span style="color: #228B22; background: #FFFFFF;">% Compute scoring weights for knn given observation weights and distances.</span><br/>               <span style="color: #A0A0A0">1216</span> <span style="color: #228B22; background: #FFFFFF;">% Both are N-by-K matrices. This is for quadratic inverse distance</span><br/>               <span style="color: #A0A0A0">1217</span> <span style="color: #228B22; background: #FFFFFF;">% weights(1./dist.^e).</span><br/>               <span style="color: #A0A0A0">1218</span> <span style="color: #228B22; background: #FFFFFF;"></span><br/>               <span style="color: #A0A0A0">1219</span> <span style="color: #228B22; background: #FFFFFF;">%take the factor of minDist to avoid overflow when summing the weights in the future</span><br/>               <span style="color: #A0A0A0">1220</span> <span style="color: #228B22; background: #FFFFFF;">% the distance values has to be non-negative values.</span><br/>               <span style="color: #A0A0A0">1221</span> <span style="color: #A0A0A0; background: #FFFFFF;">minDist = min(dist,[],2); </span><br/>               <span style="color: #A0A0A0">1222</span> <span style="color: #A0A0A0; background: #FFFFFF;">distNormalized = bsxfun(@rdivide,dist,minDist);</span><br/>               <span style="color: #A0A0A0">1223</span> <span style="color: #A0A0A0; background: #FFFFFF;">distNormalized(dist==0)=1; % to deal with zero distance values </span><br/>               <span style="color: #A0A0A0">1224</span> <span style="color: #A0A0A0; background: #FFFFFF;">distWgt = 1./(distNormalized.^e);</span><br/>               <span style="color: #A0A0A0">1225</span> <span style="color: #228B22; background: #FFFFFF;"></span><br/>               <span style="color: #A0A0A0">1226</span> <span style="color: #A0A0A0; background: #FFFFFF;">end </span><br/>               <span style="color: #A0A0A0">1227</span> <span style="color: #228B22; background: #FFFFFF;"></span><br/>               <span style="color: #A0A0A0">1228</span> <span style="color: #228B22; background: #FFFFFF;"></span><br/></pre></body></html>