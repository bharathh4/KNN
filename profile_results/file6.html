<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><link rel="stylesheet" href="file:////usr/local/MATLAB/R2013a/toolbox/matlab/codetools/matlab-report-styles.css" type="text/css" /><title>Function details for ClassificationKNN>ClassificationKNN.fit</title><link rel="stylesheet" href="file:////usr/local/MATLAB/R2013a/toolbox/matlab/codetools/matlab-report-styles.css" type="text/css" /></head><body bgcolor="#F8F8F8"><strong>This is a static copy of a profile report</strong><p><a href="file0.html">Home</a><p><span style="font-size:14pt; background:#FFE4B0">ClassificationKNN>ClassificationKNN.fit (1 call, 0.349 sec)</span><br/><i>Generated 02-Dec-2014 20:17:24 using cpu time.</i><br/>subfunction in file /usr/local/MATLAB/R2013a/toolbox/stats/classreg/ClassificationKNN.m<br/>Copy to new window for comparing multiple runs<div class="grayline"/><div class="grayline"/><strong>Parents</strong> (calling functions)<br/><p><table border=0 cellspacing=0 cellpadding=6><tr><td class="td-linebottomrt" bgcolor="#F0F0F0">Function Name</td><td class="td-linebottomrt" bgcolor="#F0F0F0">Function Type</td><td class="td-linebottomrt" bgcolor="#F0F0F0">Calls</td></tr><tr><td class="td-linebottomrt"><a href="file1.html">knn_classify</a></td><td class="td-linebottomrt">function</td><td class="td-linebottomrt">1</td></tr></table><div class="grayline"/><strong>Lines where the most time was spent</strong><br/> <p><table border=0 cellspacing=0 cellpadding=6><tr><td class="td-linebottomrt" bgcolor="#F0F0F0">Line Number</td><td class="td-linebottomrt" bgcolor="#F0F0F0">Code</td><td class="td-linebottomrt" bgcolor="#F0F0F0">Calls</td><td class="td-linebottomrt" bgcolor="#F0F0F0">Total Time</td><td class="td-linebottomrt" bgcolor="#F0F0F0">% Time</td><td class="td-linebottomrt" bgcolor="#F0F0F0">Time Plot</td></tr><tr><td class="td-linebottomrt"><a href="#Line1019">1019</a></td><td class="td-linebottomrt"><pre>this = fit(temp,X,Y);</pre></td><td class="td-linebottomrt">1</td><td class="td-linebottomrt">0.189 s</td><td class="td-linebottomrt" class="td-linebottomrt">54.1%</td><td class="td-linebottomrt"><img src="file:////usr/local/MATLAB/R2013a/toolbox/matlab/codetools/private/one-pixel.gif" width=54 height=10></td></tr><tr><td class="td-linebottomrt"><a href="#Line1017">1017</a></td><td class="td-linebottomrt"><pre>temp = classreg.learning.FitTe...</pre></td><td class="td-linebottomrt">1</td><td class="td-linebottomrt">0.132 s</td><td class="td-linebottomrt" class="td-linebottomrt">37.8%</td><td class="td-linebottomrt"><img src="file:////usr/local/MATLAB/R2013a/toolbox/matlab/codetools/private/one-pixel.gif" width=38 height=10></td></tr><tr><td class="td-linebottomrt"><a href="#Line990">990</a></td><td class="td-linebottomrt"><pre>Nfold = classreg.learning.gene...</pre></td><td class="td-linebottomrt">1</td><td class="td-linebottomrt">0.028 s</td><td class="td-linebottomrt" class="td-linebottomrt">8.1%</td><td class="td-linebottomrt"><img src="file:////usr/local/MATLAB/R2013a/toolbox/matlab/codetools/private/one-pixel.gif" width=8 height=10></td></tr><tr><td class="td-linebottomrt"><a href="#Line1029">1029</a></td><td class="td-linebottomrt"><pre>end</pre></td><td class="td-linebottomrt">1</td><td class="td-linebottomrt">0 s</td><td class="td-linebottomrt" class="td-linebottomrt">0%</td><td class="td-linebottomrt"><img src="file:////usr/local/MATLAB/R2013a/toolbox/matlab/codetools/private/one-pixel.gif" width=0 height=10></td></tr><tr><td class="td-linebottomrt"><a href="#Line1026">1026</a></td><td class="td-linebottomrt"><pre>if ~isempty(cost)</pre></td><td class="td-linebottomrt">1</td><td class="td-linebottomrt">0 s</td><td class="td-linebottomrt" class="td-linebottomrt">0%</td><td class="td-linebottomrt"><img src="file:////usr/local/MATLAB/R2013a/toolbox/matlab/codetools/private/one-pixel.gif" width=0 height=10></td></tr><tr><td class="td-linebottomrt">All other lines</td><td class="td-linebottomrt">&nbsp;</td><td class="td-linebottomrt">&nbsp;</td><td class="td-linebottomrt">0 s</td><td class="td-linebottomrt">0%</td><td class="td-linebottomrt"><img src="file:////usr/local/MATLAB/R2013a/toolbox/matlab/codetools/private/one-pixel.gif" width=0 height=10></td></tr><tr><td class="td-linebottomrt" bgcolor="#F0F0F0">Totals</td><td class="td-linebottomrt" bgcolor="#F0F0F0">&nbsp;</td><td class="td-linebottomrt" bgcolor="#F0F0F0">&nbsp;</td><td class="td-linebottomrt" bgcolor="#F0F0F0">0.349 s</td><td class="td-linebottomrt" bgcolor="#F0F0F0">100%</td><td class="td-linebottomrt" bgcolor="#F0F0F0">&nbsp;</td></tr></table><div class="grayline"/><b>Children</b> (called functions)<br/><p><table border=0 cellspacing=0 cellpadding=6><tr><td class="td-linebottomrt" bgcolor="#F0F0F0">Function Name</td><td class="td-linebottomrt" bgcolor="#F0F0F0">Function Type</td><td class="td-linebottomrt" bgcolor="#F0F0F0">Calls</td><td class="td-linebottomrt" bgcolor="#F0F0F0">Total Time</td><td class="td-linebottomrt" bgcolor="#F0F0F0">% Time</td><td class="td-linebottomrt" bgcolor="#F0F0F0">Time Plot</td></tr><tr><td class="td-linebottomrt"><a href="file58.html">FitTemplate>FitTemplate.fit</a></td><td class="td-linebottomrt">subfunction</td><td class="td-linebottomrt">1</td><td class="td-linebottomrt">0.189 s</td><td class="td-linebottomrt">54.1%</td><td class="td-linebottomrt"><img src="file:////usr/local/MATLAB/R2013a/toolbox/matlab/codetools/private/one-pixel.gif" width=54 height=10></td></tr><tr><td class="td-linebottomrt"><a href="file7.html">FitTemplate>FitTemplate.make</a></td><td class="td-linebottomrt">subfunction</td><td class="td-linebottomrt">1</td><td class="td-linebottomrt">0.104 s</td><td class="td-linebottomrt">29.7%</td><td class="td-linebottomrt"><img src="file:////usr/local/MATLAB/R2013a/toolbox/matlab/codetools/private/one-pixel.gif" width=30 height=10></td></tr><tr><td class="td-linebottomrt"><a href="file5.html">Partitioner>Partitioner.processArgs</a></td><td class="td-linebottomrt">subfunction</td><td class="td-linebottomrt">1</td><td class="td-linebottomrt">0.019 s</td><td class="td-linebottomrt">5.4%</td><td class="td-linebottomrt"><img src="file:////usr/local/MATLAB/R2013a/toolbox/matlab/codetools/private/one-pixel.gif" width=5 height=10></td></tr><tr><td class="td-linebottomrt"><a href="file3.html">parseArgs</a></td><td class="td-linebottomrt">function</td><td class="td-linebottomrt">1</td><td class="td-linebottomrt">0 s</td><td class="td-linebottomrt">0%</td><td class="td-linebottomrt"><img src="file:////usr/local/MATLAB/R2013a/toolbox/matlab/codetools/private/one-pixel.gif" width=0 height=10></td></tr><tr><td class="td-linebottomrt">Self time (built-ins, overhead, etc.)</td><td class="td-linebottomrt">&nbsp;</td><td class="td-linebottomrt">&nbsp;</td><td class="td-linebottomrt">0.038 s</td><td class="td-linebottomrt">10.8%</td><td class="td-linebottomrt"><img src="file:////usr/local/MATLAB/R2013a/toolbox/matlab/codetools/private/one-pixel.gif" width=11 height=10></td></tr><tr><td class="td-linebottomrt" bgcolor="#F0F0F0">Totals</td><td class="td-linebottomrt" bgcolor="#F0F0F0">&nbsp;</td><td class="td-linebottomrt" bgcolor="#F0F0F0">&nbsp;</td><td class="td-linebottomrt" bgcolor="#F0F0F0">0.349 s</td><td class="td-linebottomrt" bgcolor="#F0F0F0">100%</td><td class="td-linebottomrt" bgcolor="#F0F0F0">&nbsp;</td></tr></table><div class="grayline"/><strong>Code Analyzer results</strong><br/>No Code Analyzer messages.<div class="grayline"/><strong>Coverage results</strong><br/>Show coverage for parent directory <br/><table border=0 cellspacing=0 cellpadding=6><tr><td class="td-linebottomrt" bgcolor="#F0F0F0">Total lines in function</td><td class="td-linebottomrt">302</td></tr><tr><td class="td-linebottomrt" bgcolor="#F0F0F0">Non-code lines (comments, blank lines)</td><td class="td-linebottomrt">281</td></tr><tr><td class="td-linebottomrt" bgcolor="#F0F0F0">Code lines (lines that can run)</td><td class="td-linebottomrt">21</td></tr><tr><td class="td-linebottomrt" bgcolor="#F0F0F0">Code lines that did run</td><td class="td-linebottomrt">12</td></tr><tr><td class="td-linebottomrt" bgcolor="#F0F0F0">Code lines that did not run</td><td class="td-linebottomrt">9</td></tr><tr><td class="td-linebottomrt" bgcolor="#F0F0F0">Coverage (did run/can run)</td><td class="td-linebottomrt">57.14 %</td></tr></table><div class="grayline"/><b>Function listing</b><br/><pre> <span style="color: #FF0000; font-weight: bold; text-decoration: none">  time</span> <span style="color: #0000FF; font-weight: bold; text-decoration: none">  calls</span>  <span style="font-weight: bold; text-decoration: none">line</span><br/>               <span style="color: #A0A0A0"> 728</span> <span style="color: #A0A0A0; background: #FFFFFF;">        function this = fit(X,Y,varargin)</span><br/>               <span style="color: #A0A0A0"> 729</span> <span style="color: #228B22; background: #FFFFFF;">% FIT fit KNN classification model</span><br/>               <span style="color: #A0A0A0"> 730</span> <span style="color: #228B22; background: #FFFFFF;">%   KNN = CLASSIFICATIONKNN.FIT(X,Y) returns a KNN classification  model</span><br/>               <span style="color: #A0A0A0"> 731</span> <span style="color: #228B22; background: #FFFFFF;">%   for predictors X and class labels Y.</span><br/>               <span style="color: #A0A0A0"> 732</span> <span style="color: #228B22; background: #FFFFFF;">%</span><br/>               <span style="color: #A0A0A0"> 733</span> <span style="color: #228B22; background: #FFFFFF;">% X must be an N-by-P matrix of predictors with one row per observation and</span><br/>               <span style="color: #A0A0A0"> 734</span> <span style="color: #228B22; background: #FFFFFF;">% one column per predictor. Y must be an array of N class labels. Y can be</span><br/>               <span style="color: #A0A0A0"> 735</span> <span style="color: #228B22; background: #FFFFFF;">% a categorical array (nominal or ordinal), character array, logical</span><br/>               <span style="color: #A0A0A0"> 736</span> <span style="color: #228B22; background: #FFFFFF;">% vector, numeric vector, or cell array of strings. If Y is a character</span><br/>               <span style="color: #A0A0A0"> 737</span> <span style="color: #228B22; background: #FFFFFF;">% array, it must have one class label per row.</span><br/>               <span style="color: #A0A0A0"> 738</span> <span style="color: #228B22; background: #FFFFFF;">%</span><br/>               <span style="color: #A0A0A0"> 739</span> <span style="color: #228B22; background: #FFFFFF;">% KNN is a KNN classification model. If you use one of the following five</span><br/>               <span style="color: #A0A0A0"> 740</span> <span style="color: #228B22; background: #FFFFFF;">% options, KNN is of class ClassificationPartitionedModel: 'crossval',</span><br/>               <span style="color: #A0A0A0"> 741</span> <span style="color: #228B22; background: #FFFFFF;">% 'kfold', 'holdout', 'leaveout' or 'cvpartition'. Otherwise, KNN is of</span><br/>               <span style="color: #A0A0A0"> 742</span> <span style="color: #228B22; background: #FFFFFF;">% class ClassificationKNN.</span><br/>               <span style="color: #A0A0A0"> 743</span> <span style="color: #228B22; background: #FFFFFF;">%</span><br/>               <span style="color: #A0A0A0"> 744</span> <span style="color: #228B22; background: #FFFFFF;">%   KNN=CLASSIFICATIONKNN.FIT(X,Y,'PARAM1',val1,'PARAM2',val2,...)</span><br/>               <span style="color: #A0A0A0"> 745</span> <span style="color: #228B22; background: #FFFFFF;">%   specifies optional parameter name/value pairs:</span><br/>               <span style="color: #A0A0A0"> 746</span> <span style="color: #228B22; background: #FFFFFF;">%       'CategoricalPredictors' - List of categorical predictors. Pass</span><br/>               <span style="color: #A0A0A0"> 747</span> <span style="color: #228B22; background: #FFFFFF;">%                                 'CategoricalPredictors' as [] or 'all'.</span><br/>               <span style="color: #A0A0A0"> 748</span> <span style="color: #228B22; background: #FFFFFF;">%                                 Use [] to indicate none of predictors are</span><br/>               <span style="color: #A0A0A0"> 749</span> <span style="color: #228B22; background: #FFFFFF;">%                                 categorical. Use 'all' to indicate all</span><br/>               <span style="color: #A0A0A0"> 750</span> <span style="color: #228B22; background: #FFFFFF;">%                                 the predictors are categorical.</span><br/>               <span style="color: #A0A0A0"> 751</span> <span style="color: #228B22; background: #FFFFFF;">%                                 Default: []</span><br/>               <span style="color: #A0A0A0"> 752</span> <span style="color: #228B22; background: #FFFFFF;">%       'ClassNames'            - Array of class names. Use the</span><br/>               <span style="color: #A0A0A0"> 753</span> <span style="color: #228B22; background: #FFFFFF;">%                                 data type that exists in Y. You can use</span><br/>               <span style="color: #A0A0A0"> 754</span> <span style="color: #228B22; background: #FFFFFF;">%                                 this argument to order the classes or</span><br/>               <span style="color: #A0A0A0"> 755</span> <span style="color: #228B22; background: #FFFFFF;">%                                 select a subset of classes for training.</span><br/>               <span style="color: #A0A0A0"> 756</span> <span style="color: #228B22; background: #FFFFFF;">%                                 Default: The class names that exist in Y.</span><br/>               <span style="color: #A0A0A0"> 757</span> <span style="color: #228B22; background: #FFFFFF;">%       'Cost'                  - Square matrix, where COST(I,J) is the</span><br/>               <span style="color: #A0A0A0"> 758</span> <span style="color: #228B22; background: #FFFFFF;">%                                 cost of classifying a point into class J</span><br/>               <span style="color: #A0A0A0"> 759</span> <span style="color: #228B22; background: #FFFFFF;">%                                 if its true class is I.</span><br/>               <span style="color: #A0A0A0"> 760</span> <span style="color: #228B22; background: #FFFFFF;">%                                 Alternatively, COST can be a structure S</span><br/>               <span style="color: #A0A0A0"> 761</span> <span style="color: #228B22; background: #FFFFFF;">%                                 having two fields: S.ClassificationCosts</span><br/>               <span style="color: #A0A0A0"> 762</span> <span style="color: #228B22; background: #FFFFFF;">%                                 containing the cost matrix C, and</span><br/>               <span style="color: #A0A0A0"> 763</span> <span style="color: #228B22; background: #FFFFFF;">%                                 S.ClassNames containing the class names</span><br/>               <span style="color: #A0A0A0"> 764</span> <span style="color: #228B22; background: #FFFFFF;">%                                 and defining the ordering of classes used</span><br/>               <span style="color: #A0A0A0"> 765</span> <span style="color: #228B22; background: #FFFFFF;">%                                 for the rows and columns of the cost</span><br/>               <span style="color: #A0A0A0"> 766</span> <span style="color: #228B22; background: #FFFFFF;">%                                 matrix. For S.ClassNames use the data</span><br/>               <span style="color: #A0A0A0"> 767</span> <span style="color: #228B22; background: #FFFFFF;">%                                 type that exists in Y. As an alternative,</span><br/>               <span style="color: #A0A0A0"> 768</span> <span style="color: #228B22; background: #FFFFFF;">%                                 you can assign to the Cost property of</span><br/>               <span style="color: #A0A0A0"> 769</span> <span style="color: #228B22; background: #FFFFFF;">%                                 KNN. Default: COST(I,J)=1 if I~=J, and</span><br/>               <span style="color: #A0A0A0"> 770</span> <span style="color: #228B22; background: #FFFFFF;">%                                 COST(I,J)=0 if I=J.</span><br/>               <span style="color: #A0A0A0"> 771</span> <span style="color: #228B22; background: #FFFFFF;">%       'CrossVal'              - If 'on', creates a cross-validated KNN</span><br/>               <span style="color: #A0A0A0"> 772</span> <span style="color: #228B22; background: #FFFFFF;">%                                 with 10 folds. You can use 'kfold',</span><br/>               <span style="color: #A0A0A0"> 773</span> <span style="color: #228B22; background: #FFFFFF;">%                                 'holdout', 'leaveout' and 'cvpartition'</span><br/>               <span style="color: #A0A0A0"> 774</span> <span style="color: #228B22; background: #FFFFFF;">%                                 parameters to override this</span><br/>               <span style="color: #A0A0A0"> 775</span> <span style="color: #228B22; background: #FFFFFF;">%                                 cross-validation setting. You can only</span><br/>               <span style="color: #A0A0A0"> 776</span> <span style="color: #228B22; background: #FFFFFF;">%                                 use one of these four options ('kfold',</span><br/>               <span style="color: #A0A0A0"> 777</span> <span style="color: #228B22; background: #FFFFFF;">%                                 'holdout', 'leaveout' and 'cvpartition')</span><br/>               <span style="color: #A0A0A0"> 778</span> <span style="color: #228B22; background: #FFFFFF;">%                                 at a time when creating a cross-validated</span><br/>               <span style="color: #A0A0A0"> 779</span> <span style="color: #228B22; background: #FFFFFF;">%                                 model. As an alternative, you can</span><br/>               <span style="color: #A0A0A0"> 780</span> <span style="color: #228B22; background: #FFFFFF;">%                                 cross-validate later using CROSSVAL</span><br/>               <span style="color: #A0A0A0"> 781</span> <span style="color: #228B22; background: #FFFFFF;">%                                 method for ClassificationKNN. Default:</span><br/>               <span style="color: #A0A0A0"> 782</span> <span style="color: #228B22; background: #FFFFFF;">%                                 'off'</span><br/>               <span style="color: #A0A0A0"> 783</span> <span style="color: #228B22; background: #FFFFFF;">%       'CVPartition'           - A partition created with  CVPARTITION to</span><br/>               <span style="color: #A0A0A0"> 784</span> <span style="color: #228B22; background: #FFFFFF;">%                                 use in cross-validated KNN model.</span><br/>               <span style="color: #A0A0A0"> 785</span> <span style="color: #228B22; background: #FFFFFF;">%       'Holdout'               - Holdout validation uses the specified</span><br/>               <span style="color: #A0A0A0"> 786</span> <span style="color: #228B22; background: #FFFFFF;">%                                 fraction of the data for test, and uses</span><br/>               <span style="color: #A0A0A0"> 787</span> <span style="color: #228B22; background: #FFFFFF;">%                                 the rest of the data for training.</span><br/>               <span style="color: #A0A0A0"> 788</span> <span style="color: #228B22; background: #FFFFFF;">%                                 Specify a numeric scalar between 0 and 1.</span><br/>               <span style="color: #A0A0A0"> 789</span> <span style="color: #228B22; background: #FFFFFF;">%       'KFold'                 - Number of folds to use in cross-validated</span><br/>               <span style="color: #A0A0A0"> 790</span> <span style="color: #228B22; background: #FFFFFF;">%                                 KNN classification model, a positive</span><br/>               <span style="color: #A0A0A0"> 791</span> <span style="color: #228B22; background: #FFFFFF;">%                                 integer. Default: 10</span><br/>               <span style="color: #A0A0A0"> 792</span> <span style="color: #228B22; background: #FFFFFF;">%       'Leaveout'              - Use leave-one-out cross-validation by</span><br/>               <span style="color: #A0A0A0"> 793</span> <span style="color: #228B22; background: #FFFFFF;">%                                 setting to 'on'.</span><br/>               <span style="color: #A0A0A0"> 794</span> <span style="color: #228B22; background: #FFFFFF;">%       'Prior'                 - Prior probabilities for each class.</span><br/>               <span style="color: #A0A0A0"> 795</span> <span style="color: #228B22; background: #FFFFFF;">%                                 Specify as one of:</span><br/>               <span style="color: #A0A0A0"> 796</span> <span style="color: #228B22; background: #FFFFFF;">%                                   * A string:</span><br/>               <span style="color: #A0A0A0"> 797</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - 'empirical' determines class</span><br/>               <span style="color: #A0A0A0"> 798</span> <span style="color: #228B22; background: #FFFFFF;">%                                       probabilities from class</span><br/>               <span style="color: #A0A0A0"> 799</span> <span style="color: #228B22; background: #FFFFFF;">%                                       frequencies in Y</span><br/>               <span style="color: #A0A0A0"> 800</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - 'uniform' sets all class</span><br/>               <span style="color: #A0A0A0"> 801</span> <span style="color: #228B22; background: #FFFFFF;">%                                       probabilities equal</span><br/>               <span style="color: #A0A0A0"> 802</span> <span style="color: #228B22; background: #FFFFFF;">%                                   * A vector (one scalar value for each</span><br/>               <span style="color: #A0A0A0"> 803</span> <span style="color: #228B22; background: #FFFFFF;">%                                     class)</span><br/>               <span style="color: #A0A0A0"> 804</span> <span style="color: #228B22; background: #FFFFFF;">%                                   * A structure S with two fields:</span><br/>               <span style="color: #A0A0A0"> 805</span> <span style="color: #228B22; background: #FFFFFF;">%                                     S.ClassProbs containing a vector of</span><br/>               <span style="color: #A0A0A0"> 806</span> <span style="color: #228B22; background: #FFFFFF;">%                                     class probabilities, and S.ClassNames</span><br/>               <span style="color: #A0A0A0"> 807</span> <span style="color: #228B22; background: #FFFFFF;">%                                     containing the class names and</span><br/>               <span style="color: #A0A0A0"> 808</span> <span style="color: #228B22; background: #FFFFFF;">%                                     defining the ordering of classes used</span><br/>               <span style="color: #A0A0A0"> 809</span> <span style="color: #228B22; background: #FFFFFF;">%                                     for the elements of this vector.</span><br/>               <span style="color: #A0A0A0"> 810</span> <span style="color: #228B22; background: #FFFFFF;">%                                 If you pass numeric values,</span><br/>               <span style="color: #A0A0A0"> 811</span> <span style="color: #228B22; background: #FFFFFF;">%                                 ClassificationKNN.fit normalizes</span><br/>               <span style="color: #A0A0A0"> 812</span> <span style="color: #228B22; background: #FFFFFF;">%                                 them to add up to one. As an</span><br/>               <span style="color: #A0A0A0"> 813</span> <span style="color: #228B22; background: #FFFFFF;">%                                 alternative, you can assign to</span><br/>               <span style="color: #A0A0A0"> 814</span> <span style="color: #228B22; background: #FFFFFF;">%                                 the Prior property. Default:</span><br/>               <span style="color: #A0A0A0"> 815</span> <span style="color: #228B22; background: #FFFFFF;">%                                 'empirical'</span><br/>               <span style="color: #A0A0A0"> 816</span> <span style="color: #228B22; background: #FFFFFF;">%       'ResponseName'          - Name of the response variable Y, a</span><br/>               <span style="color: #A0A0A0"> 817</span> <span style="color: #228B22; background: #FFFFFF;">%                                 string. Default: 'Y'</span><br/>               <span style="color: #A0A0A0"> 818</span> <span style="color: #228B22; background: #FFFFFF;">%       'ScoreTransform'        - Function handle for transforming scores,</span><br/>               <span style="color: #A0A0A0"> 819</span> <span style="color: #228B22; background: #FFFFFF;">%                                 or string representing a built-in</span><br/>               <span style="color: #A0A0A0"> 820</span> <span style="color: #228B22; background: #FFFFFF;">%                                 transformation function. Available</span><br/>               <span style="color: #A0A0A0"> 821</span> <span style="color: #228B22; background: #FFFFFF;">%                                 functions: 'symmetric', 'invlogit',</span><br/>               <span style="color: #A0A0A0"> 822</span> <span style="color: #228B22; background: #FFFFFF;">%                                 'ismax', 'symmetricismax', 'none',</span><br/>               <span style="color: #A0A0A0"> 823</span> <span style="color: #228B22; background: #FFFFFF;">%                                 'logit', 'doublelogit', 'symmetriclogit',</span><br/>               <span style="color: #A0A0A0"> 824</span> <span style="color: #228B22; background: #FFFFFF;">%                                 and 'sign'.</span><br/>               <span style="color: #A0A0A0"> 825</span> <span style="color: #228B22; background: #FFFFFF;">%                                 Default: 'none'</span><br/>               <span style="color: #A0A0A0"> 826</span> <span style="color: #228B22; background: #FFFFFF;">%       'Weights'               - Vector of observation weights, one weight</span><br/>               <span style="color: #A0A0A0"> 827</span> <span style="color: #228B22; background: #FFFFFF;">%                                 per observation. Default:</span><br/>               <span style="color: #A0A0A0"> 828</span> <span style="color: #228B22; background: #FFFFFF;">%                                 ones(size(X,1),1)</span><br/>               <span style="color: #A0A0A0"> 829</span> <span style="color: #228B22; background: #FFFFFF;">%       'NumNeighbors'          - A positive integer specifying the number</span><br/>               <span style="color: #A0A0A0"> 830</span> <span style="color: #228B22; background: #FFFFFF;">%                                 of nearest neighbors in X for classifying</span><br/>               <span style="color: #A0A0A0"> 831</span> <span style="color: #228B22; background: #FFFFFF;">%                                 each point when predicting. Default: 1.</span><br/>               <span style="color: #A0A0A0"> 832</span> <span style="color: #228B22; background: #FFFFFF;">%       'NSMethod'              - Nearest neighbors search method.</span><br/>               <span style="color: #A0A0A0"> 833</span> <span style="color: #228B22; background: #FFFFFF;">%                                 Value is either:</span><br/>               <span style="color: #A0A0A0"> 834</span> <span style="color: #228B22; background: #FFFFFF;">%                                   - 'kdtree' uses a kd-tree to find</span><br/>               <span style="color: #A0A0A0"> 835</span> <span style="color: #228B22; background: #FFFFFF;">%                                     nearest neighbors. 'kdtree' is only</span><br/>               <span style="color: #A0A0A0"> 836</span> <span style="color: #228B22; background: #FFFFFF;">%                                     valid when the distance metric</span><br/>               <span style="color: #A0A0A0"> 837</span> <span style="color: #228B22; background: #FFFFFF;">%                                     is one of the following metrics:</span><br/>               <span style="color: #A0A0A0"> 838</span> <span style="color: #228B22; background: #FFFFFF;">%                                       - 'euclidean'</span><br/>               <span style="color: #A0A0A0"> 839</span> <span style="color: #228B22; background: #FFFFFF;">%                                       - 'cityblock'</span><br/>               <span style="color: #A0A0A0"> 840</span> <span style="color: #228B22; background: #FFFFFF;">%                                       - 'minkowski'</span><br/>               <span style="color: #A0A0A0"> 841</span> <span style="color: #228B22; background: #FFFFFF;">%                                       - 'chebyshev'</span><br/>               <span style="color: #A0A0A0"> 842</span> <span style="color: #228B22; background: #FFFFFF;">%                                   - 'exhaustive' uses the exhaustive</span><br/>               <span style="color: #A0A0A0"> 843</span> <span style="color: #228B22; background: #FFFFFF;">%                                     search algorithm. The distance values</span><br/>               <span style="color: #A0A0A0"> 844</span> <span style="color: #228B22; background: #FFFFFF;">%                                     from all the points in X to each</span><br/>               <span style="color: #A0A0A0"> 845</span> <span style="color: #228B22; background: #FFFFFF;">%                                     point in Y are computed to find</span><br/>               <span style="color: #A0A0A0"> 846</span> <span style="color: #228B22; background: #FFFFFF;">%                                     nearest neighbors.</span><br/>               <span style="color: #A0A0A0"> 847</span> <span style="color: #228B22; background: #FFFFFF;">%                                   Default is 'kdtree' when the number of</span><br/>               <span style="color: #A0A0A0"> 848</span> <span style="color: #228B22; background: #FFFFFF;">%                                   columns of X is not greater  than 10, X</span><br/>               <span style="color: #A0A0A0"> 849</span> <span style="color: #228B22; background: #FFFFFF;">%                                   is not sparse, and the distance metric</span><br/>               <span style="color: #A0A0A0"> 850</span> <span style="color: #228B22; background: #FFFFFF;">%                                   is one of the above 4 metrics;</span><br/>               <span style="color: #A0A0A0"> 851</span> <span style="color: #228B22; background: #FFFFFF;">%                                   otherwise, default is 'exhaustive'.</span><br/>               <span style="color: #A0A0A0"> 852</span> <span style="color: #228B22; background: #FFFFFF;">%       'IncludeTies'           - A logical value. Use true to include all</span><br/>               <span style="color: #A0A0A0"> 853</span> <span style="color: #228B22; background: #FFFFFF;">%                                 neighbors whose distance equal the Kth</span><br/>               <span style="color: #A0A0A0"> 854</span> <span style="color: #228B22; background: #FFFFFF;">%                                 smallest distance. Use false to include</span><br/>               <span style="color: #A0A0A0"> 855</span> <span style="color: #228B22; background: #FFFFFF;">%                                 exactly K nearest neighbors.</span><br/>               <span style="color: #A0A0A0"> 856</span> <span style="color: #228B22; background: #FFFFFF;">%       'DistanceWeight'        - A string or a function handle specifying</span><br/>               <span style="color: #A0A0A0"> 857</span> <span style="color: #228B22; background: #FFFFFF;">%                                 the distance weighting function. The</span><br/>               <span style="color: #A0A0A0"> 858</span> <span style="color: #228B22; background: #FFFFFF;">%                                 choices of the string are:</span><br/>               <span style="color: #A0A0A0"> 859</span> <span style="color: #228B22; background: #FFFFFF;">%                                   - 'equal': Each neighbor gets equal</span><br/>               <span style="color: #A0A0A0"> 860</span> <span style="color: #228B22; background: #FFFFFF;">%                                      weight (default).</span><br/>               <span style="color: #A0A0A0"> 861</span> <span style="color: #228B22; background: #FFFFFF;">%                                   - 'inverse': Each neighbor gets weight</span><br/>               <span style="color: #A0A0A0"> 862</span> <span style="color: #228B22; background: #FFFFFF;">%                                      1/d, where d is the distance between</span><br/>               <span style="color: #A0A0A0"> 863</span> <span style="color: #228B22; background: #FFFFFF;">%                                      this neighbor and the point being</span><br/>               <span style="color: #A0A0A0"> 864</span> <span style="color: #228B22; background: #FFFFFF;">%                                      classified.</span><br/>               <span style="color: #A0A0A0"> 865</span> <span style="color: #228B22; background: #FFFFFF;">%                                   - 'squaredinverse': Each neighbor gets</span><br/>               <span style="color: #A0A0A0"> 866</span> <span style="color: #228B22; background: #FFFFFF;">%                                     weight 1/d^2, where d is the distance</span><br/>               <span style="color: #A0A0A0"> 867</span> <span style="color: #228B22; background: #FFFFFF;">%                                     between this neighbor and the point</span><br/>               <span style="color: #A0A0A0"> 868</span> <span style="color: #228B22; background: #FFFFFF;">%                                     being classified.</span><br/>               <span style="color: #A0A0A0"> 869</span> <span style="color: #228B22; background: #FFFFFF;">%                                   - A distance weighting function</span><br/>               <span style="color: #A0A0A0"> 870</span> <span style="color: #228B22; background: #FFFFFF;">%                                     specified using @. A distance</span><br/>               <span style="color: #A0A0A0"> 871</span> <span style="color: #228B22; background: #FFFFFF;">%                                     weighting function must be of the</span><br/>               <span style="color: #A0A0A0"> 872</span> <span style="color: #228B22; background: #FFFFFF;">%                                     form:</span><br/>               <span style="color: #A0A0A0"> 873</span> <span style="color: #228B22; background: #FFFFFF;">%</span><br/>               <span style="color: #A0A0A0"> 874</span> <span style="color: #228B22; background: #FFFFFF;">%                                     function DW = DISTWGT(D)</span><br/>               <span style="color: #A0A0A0"> 875</span> <span style="color: #228B22; background: #FFFFFF;">%</span><br/>               <span style="color: #A0A0A0"> 876</span> <span style="color: #228B22; background: #FFFFFF;">%                                     taking as argument a matrix D and</span><br/>               <span style="color: #A0A0A0"> 877</span> <span style="color: #228B22; background: #FFFFFF;">%                                     returning a matrix of distance weight</span><br/>               <span style="color: #A0A0A0"> 878</span> <span style="color: #228B22; background: #FFFFFF;">%                                     DW. D and DW can only contains</span><br/>               <span style="color: #A0A0A0"> 879</span> <span style="color: #228B22; background: #FFFFFF;">%                                     non-negative numerical values. DW must</span><br/>               <span style="color: #A0A0A0"> 880</span> <span style="color: #228B22; background: #FFFFFF;">%                                     have the same size as D. DW(I,J) is</span><br/>               <span style="color: #A0A0A0"> 881</span> <span style="color: #228B22; background: #FFFFFF;">%                                     the weight computed based on D(I,J).</span><br/>               <span style="color: #A0A0A0"> 882</span> <span style="color: #228B22; background: #FFFFFF;">%        'BreakTies'            - Method of breaking ties if more than one</span><br/>               <span style="color: #A0A0A0"> 883</span> <span style="color: #228B22; background: #FFFFFF;">%                                 class has the same smallest cost. Choices</span><br/>               <span style="color: #A0A0A0"> 884</span> <span style="color: #228B22; background: #FFFFFF;">%                                 are:</span><br/>               <span style="color: #A0A0A0"> 885</span> <span style="color: #228B22; background: #FFFFFF;">%                                   - 'smallest': Assign the point to the</span><br/>               <span style="color: #A0A0A0"> 886</span> <span style="color: #228B22; background: #FFFFFF;">%                                     class with the smallest index. This</span><br/>               <span style="color: #A0A0A0"> 887</span> <span style="color: #228B22; background: #FFFFFF;">%                                     is default.</span><br/>               <span style="color: #A0A0A0"> 888</span> <span style="color: #228B22; background: #FFFFFF;">%                                   - 'nearest': Assign the point to the</span><br/>               <span style="color: #A0A0A0"> 889</span> <span style="color: #228B22; background: #FFFFFF;">%                                     class of its nearest neighbor.</span><br/>               <span style="color: #A0A0A0"> 890</span> <span style="color: #228B22; background: #FFFFFF;">%                                   - 'random': Randomly pick a class</span><br/>               <span style="color: #A0A0A0"> 891</span> <span style="color: #228B22; background: #FFFFFF;">%                                      out the classes with the smallest</span><br/>               <span style="color: #A0A0A0"> 892</span> <span style="color: #228B22; background: #FFFFFF;">%                                      cost.</span><br/>               <span style="color: #A0A0A0"> 893</span> <span style="color: #228B22; background: #FFFFFF;">%        'Distance'              - A string or a function handle specifying</span><br/>               <span style="color: #A0A0A0"> 894</span> <span style="color: #228B22; background: #FFFFFF;">%                                  the distance metric. The value can be</span><br/>               <span style="color: #A0A0A0"> 895</span> <span style="color: #228B22; background: #FFFFFF;">%                                  one of the following:</span><br/>               <span style="color: #A0A0A0"> 896</span> <span style="color: #228B22; background: #FFFFFF;">%                                  'euclidean'   </span><br/>               <span style="color: #A0A0A0"> 897</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - Euclidean distance. This is default</span><br/>               <span style="color: #A0A0A0"> 898</span> <span style="color: #228B22; background: #FFFFFF;">%                                       if 'CategoricalPredictors' is</span><br/>               <span style="color: #A0A0A0"> 899</span> <span style="color: #228B22; background: #FFFFFF;">%                                       empty.</span><br/>               <span style="color: #A0A0A0"> 900</span> <span style="color: #228B22; background: #FFFFFF;">%                                  'seuclidean'</span><br/>               <span style="color: #A0A0A0"> 901</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - Standardized Euclidean distance.</span><br/>               <span style="color: #A0A0A0"> 902</span> <span style="color: #228B22; background: #FFFFFF;">%                                       Each coordinate difference between</span><br/>               <span style="color: #A0A0A0"> 903</span> <span style="color: #228B22; background: #FFFFFF;">%                                       X and a query point is divided by</span><br/>               <span style="color: #A0A0A0"> 904</span> <span style="color: #228B22; background: #FFFFFF;">%                                       an element of  vector S. The</span><br/>               <span style="color: #A0A0A0"> 905</span> <span style="color: #228B22; background: #FFFFFF;">%                                       default value of is the standard</span><br/>               <span style="color: #A0A0A0"> 906</span> <span style="color: #228B22; background: #FFFFFF;">%                                       deviation computed from X,</span><br/>               <span style="color: #A0A0A0"> 907</span> <span style="color: #228B22; background: #FFFFFF;">%                                       S=NANSTD(X). To specify another</span><br/>               <span style="color: #A0A0A0"> 908</span> <span style="color: #228B22; background: #FFFFFF;">%                                       value for S, use the 'Scale'</span><br/>               <span style="color: #A0A0A0"> 909</span> <span style="color: #228B22; background: #FFFFFF;">%                                       argument.</span><br/>               <span style="color: #A0A0A0"> 910</span> <span style="color: #228B22; background: #FFFFFF;">%                                  'cityblock'  </span><br/>               <span style="color: #A0A0A0"> 911</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - City Block distance.</span><br/>               <span style="color: #A0A0A0"> 912</span> <span style="color: #228B22; background: #FFFFFF;">%                                  'chebychev'  </span><br/>               <span style="color: #A0A0A0"> 913</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - Chebychev distance (maximum</span><br/>               <span style="color: #A0A0A0"> 914</span> <span style="color: #228B22; background: #FFFFFF;">%                                       coordinate  difference).</span><br/>               <span style="color: #A0A0A0"> 915</span> <span style="color: #228B22; background: #FFFFFF;">%                                  'minkowski'  </span><br/>               <span style="color: #A0A0A0"> 916</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - Minkowski distance. The default</span><br/>               <span style="color: #A0A0A0"> 917</span> <span style="color: #228B22; background: #FFFFFF;">%                                       exponent is 2. To specify a</span><br/>               <span style="color: #A0A0A0"> 918</span> <span style="color: #228B22; background: #FFFFFF;">%                                       different exponent, use the 'P'</span><br/>               <span style="color: #A0A0A0"> 919</span> <span style="color: #228B22; background: #FFFFFF;">%                                       argument.</span><br/>               <span style="color: #A0A0A0"> 920</span> <span style="color: #228B22; background: #FFFFFF;">%                                  'mahalanobis' </span><br/>               <span style="color: #A0A0A0"> 921</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - Mahalanobis distance, computed</span><br/>               <span style="color: #A0A0A0"> 922</span> <span style="color: #228B22; background: #FFFFFF;">%                                       using a positive definite</span><br/>               <span style="color: #A0A0A0"> 923</span> <span style="color: #228B22; background: #FFFFFF;">%                                       covariance matrix C. The default</span><br/>               <span style="color: #A0A0A0"> 924</span> <span style="color: #228B22; background: #FFFFFF;">%                                       value of C is the sample covariance</span><br/>               <span style="color: #A0A0A0"> 925</span> <span style="color: #228B22; background: #FFFFFF;">%                                       matrix of X, as computed by</span><br/>               <span style="color: #A0A0A0"> 926</span> <span style="color: #228B22; background: #FFFFFF;">%                                       NANCOV(X). To specify another value</span><br/>               <span style="color: #A0A0A0"> 927</span> <span style="color: #228B22; background: #FFFFFF;">%                                       for C, use the 'Cov' argument.</span><br/>               <span style="color: #A0A0A0"> 928</span> <span style="color: #228B22; background: #FFFFFF;">%                                  'cosine' </span><br/>               <span style="color: #A0A0A0"> 929</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - One minus the cosine of the</span><br/>               <span style="color: #A0A0A0"> 930</span> <span style="color: #228B22; background: #FFFFFF;">%                                       included angle between observations</span><br/>               <span style="color: #A0A0A0"> 931</span> <span style="color: #228B22; background: #FFFFFF;">%                                       (treated as vectors).</span><br/>               <span style="color: #A0A0A0"> 932</span> <span style="color: #228B22; background: #FFFFFF;">%                                   'correlation' </span><br/>               <span style="color: #A0A0A0"> 933</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - One minus the sample linear</span><br/>               <span style="color: #A0A0A0"> 934</span> <span style="color: #228B22; background: #FFFFFF;">%                                       correlation between observations</span><br/>               <span style="color: #A0A0A0"> 935</span> <span style="color: #228B22; background: #FFFFFF;">%                                       (treated as sequences of values).</span><br/>               <span style="color: #A0A0A0"> 936</span> <span style="color: #228B22; background: #FFFFFF;">%                                   'spearman'   </span><br/>               <span style="color: #A0A0A0"> 937</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - One minus the sample Spearman's</span><br/>               <span style="color: #A0A0A0"> 938</span> <span style="color: #228B22; background: #FFFFFF;">%                                       rank correlation between</span><br/>               <span style="color: #A0A0A0"> 939</span> <span style="color: #228B22; background: #FFFFFF;">%                                       observations (treated as sequences</span><br/>               <span style="color: #A0A0A0"> 940</span> <span style="color: #228B22; background: #FFFFFF;">%                                       of values).</span><br/>               <span style="color: #A0A0A0"> 941</span> <span style="color: #228B22; background: #FFFFFF;">%                                   'hamming'     </span><br/>               <span style="color: #A0A0A0"> 942</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - Hamming distance, percentage of</span><br/>               <span style="color: #A0A0A0"> 943</span> <span style="color: #228B22; background: #FFFFFF;">%                                       coordinates that differ. This is</span><br/>               <span style="color: #A0A0A0"> 944</span> <span style="color: #228B22; background: #FFFFFF;">%                                       default if 'CategoricalPredictors'</span><br/>               <span style="color: #A0A0A0"> 945</span> <span style="color: #228B22; background: #FFFFFF;">%                                       is set to 'all'.</span><br/>               <span style="color: #A0A0A0"> 946</span> <span style="color: #228B22; background: #FFFFFF;">%                                   'jaccard'     </span><br/>               <span style="color: #A0A0A0"> 947</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - One minus the Jaccard coefficient,</span><br/>               <span style="color: #A0A0A0"> 948</span> <span style="color: #228B22; background: #FFFFFF;">%                                       the percentage of nonzero</span><br/>               <span style="color: #A0A0A0"> 949</span> <span style="color: #228B22; background: #FFFFFF;">%                                       coordinates that differ.</span><br/>               <span style="color: #A0A0A0"> 950</span> <span style="color: #228B22; background: #FFFFFF;">%                                   function     </span><br/>               <span style="color: #A0A0A0"> 951</span> <span style="color: #228B22; background: #FFFFFF;">%                                     - A distance function specified using</span><br/>               <span style="color: #A0A0A0"> 952</span> <span style="color: #228B22; background: #FFFFFF;">%                                       @ (for example @DISTFUN). A</span><br/>               <span style="color: #A0A0A0"> 953</span> <span style="color: #228B22; background: #FFFFFF;">%                                       distance function must be of the</span><br/>               <span style="color: #A0A0A0"> 954</span> <span style="color: #228B22; background: #FFFFFF;">%                                       form</span><br/>               <span style="color: #A0A0A0"> 955</span> <span style="color: #228B22; background: #FFFFFF;">%</span><br/>               <span style="color: #A0A0A0"> 956</span> <span style="color: #228B22; background: #FFFFFF;">%                                       function D2 = DISTFUN(ZI, ZJ),</span><br/>               <span style="color: #A0A0A0"> 957</span> <span style="color: #228B22; background: #FFFFFF;">%</span><br/>               <span style="color: #A0A0A0"> 958</span> <span style="color: #228B22; background: #FFFFFF;">%                                       taking as arguments a 1-by-N vector</span><br/>               <span style="color: #A0A0A0"> 959</span> <span style="color: #228B22; background: #FFFFFF;">%                                       ZI containing a single row of X or</span><br/>               <span style="color: #A0A0A0"> 960</span> <span style="color: #228B22; background: #FFFFFF;">%                                       Y, an M2-by-N matrix ZJ containing</span><br/>               <span style="color: #A0A0A0"> 961</span> <span style="color: #228B22; background: #FFFFFF;">%                                       multiple rows of X or Y, and</span><br/>               <span style="color: #A0A0A0"> 962</span> <span style="color: #228B22; background: #FFFFFF;">%                                       returning an M2-by-1 vector of</span><br/>               <span style="color: #A0A0A0"> 963</span> <span style="color: #228B22; background: #FFFFFF;">%                                       distances D2, whose Jth element is</span><br/>               <span style="color: #A0A0A0"> 964</span> <span style="color: #228B22; background: #FFFFFF;">%                                       the distance between the</span><br/>               <span style="color: #A0A0A0"> 965</span> <span style="color: #228B22; background: #FFFFFF;">%                                       observations ZI and ZJ(J,:).</span><br/>               <span style="color: #A0A0A0"> 966</span> <span style="color: #228B22; background: #FFFFFF;">%       'Exponent'             - A positive scalar indicating the</span><br/>               <span style="color: #A0A0A0"> 967</span> <span style="color: #228B22; background: #FFFFFF;">%                                   exponent of Minkowski distance. This</span><br/>               <span style="color: #A0A0A0"> 968</span> <span style="color: #228B22; background: #FFFFFF;">%                                   argument is only valid when</span><br/>               <span style="color: #A0A0A0"> 969</span> <span style="color: #228B22; background: #FFFFFF;">%                                  'Distance' is 'minkowski'. Default: 2.</span><br/>               <span style="color: #A0A0A0"> 970</span> <span style="color: #228B22; background: #FFFFFF;">%       'Cov'                   - A positive definite matrix indicating the</span><br/>               <span style="color: #A0A0A0"> 971</span> <span style="color: #228B22; background: #FFFFFF;">%                                 covariance matrix when computing the</span><br/>               <span style="color: #A0A0A0"> 972</span> <span style="color: #228B22; background: #FFFFFF;">%                                 Mahalanobis distance. This argument is</span><br/>               <span style="color: #A0A0A0"> 973</span> <span style="color: #228B22; background: #FFFFFF;">%                                 only valid when 'Distance' is</span><br/>               <span style="color: #A0A0A0"> 974</span> <span style="color: #228B22; background: #FFFFFF;">%                                 'mahalanobis'. Default is NANCOV(X).</span><br/>               <span style="color: #A0A0A0"> 975</span> <span style="color: #228B22; background: #FFFFFF;">%       'Scale'                 - A vector S containing non-negative</span><br/>               <span style="color: #A0A0A0"> 976</span> <span style="color: #228B22; background: #FFFFFF;">%                                 values, with length equal to the number</span><br/>               <span style="color: #A0A0A0"> 977</span> <span style="color: #228B22; background: #FFFFFF;">%                                 of columns in X. Each  coordinate</span><br/>               <span style="color: #A0A0A0"> 978</span> <span style="color: #228B22; background: #FFFFFF;">%                                 difference between X and a query point is</span><br/>               <span style="color: #A0A0A0"> 979</span> <span style="color: #228B22; background: #FFFFFF;">%                                 divided by the corresponding element of</span><br/>               <span style="color: #A0A0A0"> 980</span> <span style="color: #228B22; background: #FFFFFF;">%                                 S. This argument is only valid when</span><br/>               <span style="color: #A0A0A0"> 981</span> <span style="color: #228B22; background: #FFFFFF;">%                                 'Distance' is 'seuclidean'. Default is</span><br/>               <span style="color: #A0A0A0"> 982</span> <span style="color: #228B22; background: #FFFFFF;">%                                 NANSTD(X).</span><br/>               <span style="color: #A0A0A0"> 983</span> <span style="color: #228B22; background: #FFFFFF;">%       'BucketSize'            - The maximum number of data points in the</span><br/>               <span style="color: #A0A0A0"> 984</span> <span style="color: #228B22; background: #FFFFFF;">%                                 leaf node of the kd-tree (default is 50).</span><br/>               <span style="color: #A0A0A0"> 985</span> <span style="color: #228B22; background: #FFFFFF;">%                                 This argument is only meaningful when</span><br/>               <span style="color: #A0A0A0"> 986</span> <span style="color: #228B22; background: #FFFFFF;">%                                 'NSMethod' is 'kdtree'.</span><br/>               <span style="color: #A0A0A0"> 987</span> <span style="color: #228B22; background: #FFFFFF;">%</span><br/>               <span style="color: #A0A0A0"> 988</span> <span style="color: #228B22; background: #FFFFFF;">%    See also ClassificationKNN</span><br/>               <span style="color: #A0A0A0"> 989</span> <span style="color: #228B22; background: #FFFFFF;"></span><br/><span style="color: #FF0000">  0.03 </span><span style="color: #0000FF">      1 </span><span style="color: #000000; font-weight: bold"> 990</span> <a name="Line990"></a><span style="color: #000000; background: #FFF0F0;">            Nfold = classreg.learning.generator.Partitioner.processArgs(varargin{:}); </span><br/>       <span style="color: #0000FF">      1 </span><span style="color: #000000; font-weight: bold"> 991</span> <span style="color: #000000; background: #FFFFFF;">            docv = ~isempty(Nfold); </span><br/>               <span style="color: #A0A0A0"> 992</span> <span style="color: #228B22; background: #FFFFFF;">            </span><br/>               <span style="color: #A0A0A0"> 993</span> <span style="color: #228B22; background: #FFFFFF;">            % Set prior to an empty array. For a single KNN classifier, it</span><br/>               <span style="color: #A0A0A0"> 994</span> <span style="color: #228B22; background: #FFFFFF;">            % can be filled with something.</span><br/>       <span style="color: #0000FF">      1 </span><span style="color: #000000; font-weight: bold"> 995</span> <span style="color: #000000; background: #FFFFFF;">            prior = []; </span><br/>               <span style="color: #A0A0A0"> 996</span> <span style="color: #228B22; background: #FFFFFF;">            </span><br/>       <span style="color: #0000FF">      1 </span><span style="color: #000000; font-weight: bold"> 997</span> <span style="color: #000000; background: #FFFFFF;">            if ~docv %single KNN </span><br/>               <span style="color: #A0A0A0"> 998</span> <span style="color: #228B22; background: #FFFFFF;">                % For a single KNN, exclude cost and prior from input arguments.</span><br/>               <span style="color: #A0A0A0"> 999</span> <span style="color: #228B22; background: #FFFFFF;">                % If we pass a zero prior for a class, PrivW for this class</span><br/>               <span style="color: #A0A0A0">1000</span> <span style="color: #228B22; background: #FFFFFF;">                % will be set to 0 in the ClassificationKNN constructor.</span><br/>               <span style="color: #A0A0A0">1001</span> <span style="color: #228B22; background: #FFFFFF;">                % To prevent this, we pass a default empirical prior to fit</span><br/>               <span style="color: #A0A0A0">1002</span> <span style="color: #228B22; background: #FFFFFF;">                % and reset the prior after fitting.</span><br/>       <span style="color: #0000FF">      1 </span><span style="color: #000000; font-weight: bold">1003</span> <span style="color: #000000; background: #FFFFFF;">                args = {'prior' 'cost'}; </span><br/>       <span style="color: #0000FF">      1 </span><span style="color: #000000; font-weight: bold">1004</span> <span style="color: #000000; background: #FFFFFF;">                defs = {     []  []}; </span><br/>       <span style="color: #0000FF">      1 </span><span style="color: #000000; font-weight: bold">1005</span> <span style="color: #000000; background: #FFFFFF;">                [prior,cost,~,fitArgs] = internal.stats.<a href="file3.html">parseArgs</a>(args,defs,varargin{:}); </span><br/>               <span style="color: #A0A0A0">1006</span> <span style="color: #228B22; background: #FFFFFF;">              </span><br/>               <span style="color: #A0A0A0">1007</span> <span style="color: #228B22; background: #FFFFFF;">            else % cross-validated KNN</span><br/>               <span style="color: #A0A0A0">1008</span> <span style="color: #228B22; background: #FFFFFF;">                % For cross-validated KNN, we pass the prior specified by</span><br/>               <span style="color: #A0A0A0">1009</span> <span style="color: #228B22; background: #FFFFFF;">                % the customer because a cross-validated KNN does not allow</span><br/>               <span style="color: #A0A0A0">1010</span> <span style="color: #228B22; background: #FFFFFF;">                % assignment to Prior property.</span><br/>               <span style="color: #A0A0A0">1011</span> <span style="color: #A0A0A0; background: #FFFFFF;">                 args = {'cost'};</span><br/>               <span style="color: #A0A0A0">1012</span> <span style="color: #A0A0A0; background: #FFFFFF;">                 defs = {    []};</span><br/>               <span style="color: #A0A0A0">1013</span> <span style="color: #A0A0A0; background: #FFFFFF;">                [cost,~,fitArgs] = internal.stats.parseArgs(args,defs,varargin{:});</span><br/>               <span style="color: #A0A0A0">1014</span> <span style="color: #A0A0A0; background: #FFFFFF;">            end</span><br/>               <span style="color: #A0A0A0">1015</span> <span style="color: #228B22; background: #FFFFFF;">            </span><br/>               <span style="color: #A0A0A0">1016</span> <span style="color: #228B22; background: #FFFFFF;">            % Fit</span><br/><span style="color: #FF0000">  0.13 </span><span style="color: #0000FF">      1 </span><span style="color: #000000; font-weight: bold">1017</span> <a name="Line1017"></a><span style="color: #000000; background: #FF9C9C;">            temp = classreg.learning.FitTemplate.make(... </span><br/>               <span style="color: #A0A0A0">1018</span> <span style="color: #000000; background: #FF9C9C;">                'KNN','type','classification',fitArgs{:});</span><br/><span style="color: #FF0000">  0.19 </span><span style="color: #0000FF">      1 </span><span style="color: #000000; font-weight: bold">1019</span> <a name="Line1019"></a><span style="color: #000000; background: #FF8080;">            this = fit(temp,X,Y); </span><br/>               <span style="color: #A0A0A0">1020</span> <span style="color: #228B22; background: #FFFFFF;">            </span><br/>               <span style="color: #A0A0A0">1021</span> <span style="color: #228B22; background: #FFFFFF;">            % Assign prior and cost</span><br/>       <span style="color: #0000FF">      1 </span><span style="color: #000000; font-weight: bold">1022</span> <span style="color: #000000; background: #FFFFFF;">            if ~isempty(prior) &amp;&amp; ~strncmpi(prior,'empirical',length(prior)) </span><br/>               <span style="color: #A0A0A0">1023</span> <span style="color: #228B22; background: #FFFFFF;">                %this.W will be normalized based on class priors </span><br/>               <span style="color: #A0A0A0">1024</span> <span style="color: #A0A0A0; background: #FFFFFF;">                this.Prior = prior;</span><br/>               <span style="color: #A0A0A0">1025</span> <span style="color: #A0A0A0; background: #FFFFFF;">            end</span><br/>       <span style="color: #0000FF">      1 </span><span style="color: #000000; font-weight: bold">1026</span> <a name="Line1026"></a><span style="color: #000000; background: #FFFFFF;">            if ~isempty(cost) </span><br/>               <span style="color: #A0A0A0">1027</span> <span style="color: #A0A0A0; background: #FFFFFF;">                this.Cost = cost;</span><br/>               <span style="color: #A0A0A0">1028</span> <span style="color: #A0A0A0; background: #FFFFFF;">           end</span><br/>       <span style="color: #0000FF">      1 </span><span style="color: #000000; font-weight: bold">1029</span> <a name="Line1029"></a><span style="color: #000000; background: #FFFFFF;">        end </span><br/></pre><p><p>Other subfunctions in this file are not included in this listing.</body></html>